---
title: "Estat√≠stica + R"
author: "Ana Paula Fernandes (DESCO/ICS/UFTM)"
date: "Atualizado em: `r format(Sys.time(), '%d/%m/%Y')`"
site: bookdown::bookdown_site
documentclass: book
bibliography: referencias.bib
biblio-style: apalike
link-citations: true
csl: "https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl"
language: "pt-BR"
---

# Bem-vindos!

<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/8e0b4579-4516-47c6-a45a-6e6744211efc/WpKBlZ2U4F.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>

</center>

Esse livro *online* tem como prop√≥sito principal ser um guia para as aulas de estat√≠stica, referente as disciplinas de **Bioestat√≠stica** para os cursos de Medicina e Educa√ß√£o F√≠sica e **Estat√≠stica Aplicada** para o curso de Psicologia da [Universidade Federal do Tri√¢ngulo Mineiro - UFTM](http://www.uftm.edu.br). E como objetivo secund√°rio, ser uma refer√™ncia de consulta para todos os discentes que passaram por essas disciplinas, bem como, para todos que est√£o interessados em realizar an√°lises de dados por meio da linguagem R e o ambiente de desenvolvimento RStudio.

Sugest√µes, corre√ß√µes ou qualquer outra forma de intera√ß√£o s√£o sempre bem-vindas! Ent√£o, por favor, n√£o hesite em me escrever ([anapaula.fernandes\@uftm.edu.br](mailto:anapaula.fernandes@uftm.edu.br){.email}).

Para mais informa√ß√µes sobre minha trajet√≥ria acad√™mica e profissional, acesse meu [Curr√≠culo Lattes](https://lattes.cnpq.br/5582801060910261).

> Esta obra, registrada sob o **ISBN 978-65-01-56980-2**, traz conte√∫dos atualizados e essenciais para estudantes e profissionais interessados no tema.


```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(magick)
img <- image_read_pdf("ficha-284399.pdf", density = 150)
image_write(img, path = "ficha.svg", format = "svg")
cat('<center><img src="ficha.svg" width="50%" heigth="10px"/></center>')

```

<!--chapter:end:index.Rmd-->

---
output:
  html_document: default
  pdf_document: default
---
# Por Que Estudar Estat√≠stica com Recursos Computacionais? 

Ao longo de algum tempo ministrando aulas de estat√≠stica, conclu√≠ que estudar estat√≠stica com aux√≠lio de recursos computacionais √© bem mais eficaz.  Quero dizer, √© mais f√°cil entender os conceitos te√≥ricos, lidar com recursos visuais (gr√°ficos) e, de fato, transformar o conte√∫do estudado na disciplina em uma ferramenta para pesquisas cient√≠ficas, quando se trata de analisar dados.

## Desconstruindo Mitos

Ministrando aulas para os cursos da √°rea de **sa√∫de**, **esporte** e **psicologia**, sempre ouvi dos discentes que "estat√≠stica √© matem√°tica", e sempre digo que **estat√≠stica √© estat√≠stica!** 

√â normal alguns discentes n√£o assimilarem, em princ√≠pio, a import√¢ncia da disciplina na grade do seu curso.  Alguns acham at√© que √© um assunto que deveria ficar restrito aos cursos das exatas.  Assim, a primeira tarefa √© sempre desconstruir essa ideia. 

### A Estat√≠stica √© MULTIDISCIPLINAR

A estat√≠stica est√° em tudo na verdade... e para dizer uma coisa "bem chique":  **a estat√≠stica √© a base da Intelig√™ncia Artificial**. 

Advinha quem est√° por tr√°s de: 

- ü§ñ Os famosos algoritmos das redes sociais

- üé¨ As sugest√µes de filmes e m√∫sicas que aparecem no seu *streaming* favorito

- üîç O ranqueamento de busca realizado por meio do *Google*?

- üí¨ O *ChatGPT*

---

## Aplica√ß√µes Pr√°ticas da Estat√≠stica

E sendo um pouco mais "acad√™mica", dentro do nosso prop√≥sito:

### üèÉ No Esporte

Qualquer competi√ß√£o ou treinamento esportivo est√° recheado de estat√≠stica.  Como medir o desempenho de um time ou atleta? 

**Exemplo:**

> **Uso de suplementos alimentares e acompanhamento nutricional por frequentadores de academias**  
> üìÑ <https://www.rbne.com.br/index.php/rbne/article/view/2440>

### üè• Na Medicina

Estudos epidemiol√≥gicos e, claro, da medicina baseada em evid√™ncias t√™m o suporte da estat√≠stica. 

**Exemplo:**

> **S√≠ndrome Coronariana Aguda no Brasil: Registro dos Fatores Predisponentes e Perfil Populacional em um Instituto Cardiol√≥gico P√∫blico de Refer√™ncia Nacional**  
> üìÑ <https://www.scielo.br/j/abc/a/gPrBrwLpGxWgzjFCgLkJJLN/?format=html&lang=pt>

### üß† Na Psicologia

Na psicologia, a estat√≠stica √© a ferramenta utilizada na psicometria. 

**Exemplo:**

> **Avalia√ß√£o do sofrimento ps√≠quico em estudantes do internato m√©dico**  
> üìÑ <https://acervomais.com.br/index.php/cientifico/article/view/21295>

---

## üí° Desafio para Voc√™

Basta realizar uma busca com os termos **"estat√≠stica"** + **um campo do seu curso que voc√™ se interessa**, que voc√™ encontrar√° um artigo cient√≠fico. 

> **E se voc√™ n√£o encontrar, comece a escrever sobre o tema! ** üöÄ

---

### üìö Peri√≥dicos Recomendados por √Årea

Para facilitar sua pesquisa, aqui est√£o alguns peri√≥dicos cient√≠ficos organizados por √°rea de conhecimento:

#### üèÉ‚Äç‚ôÇÔ∏è Ci√™ncia dos Esportes

| Peri√≥dico | Link |
|-----------|------|
| **RBFF** - Revista Brasileira de Futsal e Futebol | <http://www.rbff.com.br> |
| **RBME** - Revista Brasileira de Medicina do Esporte | <https://www.scielo.br/j/rbme> |
| **RBPE** - Revista Brasileira de Psicologia do Esporte | <http://pepsic.bvsalud.org> |

#### üè• Medicina e Sa√∫de

| Peri√≥dico | Link |
|-----------|------|
| **RBC** - Revista Brasileira de Cancerologia | <https://rbc.inca.gov.br/index.php/revista> |
| **RBCMS** - Revista Brasileira de Ci√™ncias M√©dicas e da Sa√∫de | <http://www.rbcms.com.br> |
| **ABRASCO** - Revista da Associa√ß√£o Brasileira de Sa√∫de Coletiva | <https://cienciaesaudecoletiva.com.br> |

#### üß† Psicologia

| Peri√≥dico | Link |
|-----------|------|
| **Psicologia Argumento** | <https://periodicos.pucpr.br/psicologiaargumento> |
| **Estudos de Psicologia** (Campinas) | <https://www.scielo.br/j/estpsi/> |
| **Psicologia em Foco** | <https://revistas.fw.uri.br/index.php/psicologiaemfoco> |

---

### üîé Outras Ferramentas de Busca Acad√™mica

Expanda sua pesquisa utilizando estas bases de dados e ferramentas especializadas:

- üìö **[Mendeley](https://www.mendeley.com)** - Gerenciador de refer√™ncias e descoberta de artigos cient√≠ficos
- üåé **[SciELO](https://scielo.org)** - Scientific Electronic Library Online (foco em Am√©rica Latina)
- üîç **[Google Scholar](https://scholar.google.com)** - Busca abrangente em literatura acad√™mica
- üè• **[PubMed](https://pubmed.ncbi.nlm.nih.gov)** - Especializada em ci√™ncias biom√©dicas e da sa√∫de

**üí° Dica de busca avan√ßada:**
- Use `"aspas"` para termos exatos: `"an√°lise estat√≠stica"`
- Combine com operadores:  `estat√≠stica AND psicologia`
- Filtre por per√≠odo: adicione ano nas op√ß√µes de busca

---

## üìä Tipos de An√°lise Estat√≠stica

Quando olhamos os artigos acima, podemos ver que todos eles t√™m resultados **descritivos** e **inferenciais**: 

| Tipo | Descri√ß√£o |
|------|-----------|
| **üìà Estat√≠stica Descritiva** | Descrever os dados amostrados para uma dada an√°lise |
| **üî¨ Estat√≠stica Inferencial** | Inferir - tirar conclus√µes a partir dos dados amostrados |

Discutiremos sobre ambas ao longo do curso! 

---

## üéØ Conclus√£o

A estat√≠stica n√£o √© apenas matem√°tica abstrata - √© uma **ferramenta essencial** para transformar dados em conhecimento, independentemente da sua √°rea de atua√ß√£o! 

---

<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>
</center>

## üìã Atividade 1: Explorando a Estat√≠stica na Pesquisa Cient√≠fica

A metodologia cient√≠fica √© composta por etapas estruturadas que guiam o processo de investiga√ß√£o.   **A estat√≠stica est√° presente em v√°rias dessas etapas**, desde o planejamento da coleta de dados at√© a an√°lise e interpreta√ß√£o dos resultados.  Nesta atividade, voc√™ ir√° identificar como a estat√≠stica √© aplicada em um estudo real da sua √°rea de interesse.

---

### üéØ Objetivo da Atividade

**Busque um artigo cient√≠fico do campo de seu interesse que utiliza a estat√≠stica.**

Ao analisar o artigo, voc√™ ir√° mapear as principais etapas da metodologia cient√≠fica e identificar onde e como a estat√≠stica foi aplicada. 

---

### üìù Roteiro de An√°lise

 **1Ô∏è‚É£ PROBLEMA DE PESQUISA - Qual √© o principal objetivo da pesquisa?**

> *Na metodologia cient√≠fica, toda pesquisa come√ßa com uma pergunta ou problema a ser investigado.*

**Reflita:**

- ‚ùì Qual √© a quest√£o central que a pesquisa busca responder?

- üéØ Os autores apresentam claramente os objetivos do estudo? 

- üìä O que se espera alcan√ßar com os resultados? 

- üí° Existem hip√≥teses formuladas?  Se sim, quais s√£o?

---

 **2Ô∏è‚É£ METODOLOGIA - Como a pesquisa foi conduzida?**

> *A metodologia descreve o "caminho" percorrido pelo pesquisador.   √â aqui que a estat√≠stica come√ßa a aparecer no planejamento da pesquisa.*

**Analise os seguintes aspectos:**

| Aspecto | O que observar no artigo |
|---------|--------------------------|
| **üî¨ Tipo de pesquisa** | A pesquisa √© qualitativa, quantitativa ou mista? |
| **üë• Popula√ß√£o e Amostra** | Qual √© a popula√ß√£o-alvo? Quantos participantes comp√µem a amostra? |
| **üßÆ C√°lculo Amostral** | Os autores justificam o tamanho da amostra? Foi realizado c√°lculo amostral? |
| **üìä T√©cnica de Amostragem** | Como os participantes foram selecionados? (aleat√≥ria, por conveni√™ncia, estratificada, etc.) |
| **üìã Instrumentos de Coleta** | Quais instrumentos foram utilizados? (question√°rios, testes, medi√ß√µes, observa√ß√µes, etc.) |
| **üìà An√°lise Estat√≠stica** | Quais t√©cnicas estat√≠sticas foram aplicadas para analisar os dados? |
| **üíª Software Utilizado** | Qual programa foi usado para as an√°lises? (SPSS, R, Python, Excel, etc.) |

**üí≠ Reflita:** *Por que essas escolhas metodol√≥gicas s√£o importantes para a validade da pesquisa?*

---

 **3Ô∏è‚É£ RESULTADOS - O que √© apresentado por meio de tabelas ou gr√°ficos?**

> *A estat√≠stica descritiva organiza e resume os dados coletados, facilitando a visualiza√ß√£o e interpreta√ß√£o dos resultados.*

**Observe:**

- üìä Quais informa√ß√µes est√£o sendo representadas visualmente?

- ‚úÖ Os gr√°ficos e tabelas s√£o claros e bem organizados? 

- üîç Que tipo de gr√°ficos foram utilizados?  (barras, dispers√£o, boxplot, histograma, pizza, etc.)

- üìâ Os dados apresentados respondem aos objetivos da pesquisa? 

- üí¨ Como os autores interpretam os resultados a partir dessas representa√ß√µes?

**üí° Dica:** *Preste aten√ß√£o nas legendas, t√≠tulos e notas de rodap√© das tabelas e gr√°ficos - eles cont√™m informa√ß√µes importantes! *

---

**4Ô∏è‚É£ GLOSS√ÅRIO ESTAT√çSTICO - Termos encontrados no artigo**

> *Familiarizar-se com a terminologia estat√≠stica √© essencial para compreender e aplicar essas t√©cnicas em suas pr√≥prias pesquisas.*

**Crie uma lista dos termos e conceitos estat√≠sticos mencionados no artigo.**

**Exemplos do que voc√™ pode encontrar:**

| Categoria | Exemplos de Termos |
|-----------|-------------------|
| **üìè Medidas Descritivas** | M√©dia, mediana, moda, desvio-padr√£o, vari√¢ncia, percentis |
| **üìä Tipos de Vari√°veis** | Vari√°vel dependente, independente, qualitativa, quantitativa |
| **üî¨ Testes de Hip√≥tese** | Teste t, ANOVA, qui-quadrado, Mann-Whitney, Kruskal-Wallis |
| **üìà An√°lises de Rela√ß√£o** | Correla√ß√£o de Pearson, Spearman, regress√£o linear, regress√£o log√≠stica |
| **üéØ Conceitos Inferenciais** | Intervalo de confian√ßa, n√≠vel de signific√¢ncia, p-valor, poder do teste, tamanho do efeito |
| **üìê Outros** | Normalidade, homocedasticidade, distribui√ß√£o, outliers |

**‚úçÔ∏è Para cada termo identificado:**

- Anote a p√°gina onde aparece

- Tente definir com suas pr√≥prias palavras

- Pesquise o significado caso n√£o conhe√ßa

---

### üéì Reflex√£o Final

Ap√≥s completar esta an√°lise, voc√™ ser√° capaz de: 

‚úÖ Reconhecer como a estat√≠stica se integra √†s etapas da metodologia cient√≠fica  
‚úÖ Identificar as principais t√©cnicas estat√≠sticas aplicadas na sua √°rea  
‚úÖ Compreender a import√¢ncia do planejamento estat√≠stico para a qualidade da pesquisa  
‚úÖ Desenvolver um olhar cr√≠tico sobre a apresenta√ß√£o e interpreta√ß√£o de dados  

**üí¨ Quest√£o B√¥nus:** *Com base no artigo analisado, que decis√µes metodol√≥gicas voc√™ faria diferente se fosse conduzir uma pesquisa semelhante?*

---


# Conceitos Fundamentais

Antes de mergulharmos nas an√°lises estat√≠sticas, √© fundamental compreender dois conceitos essenciais que formam a base de qualquer estudo quantitativo:  **Estat√≠stica Descritiva** e **Estat√≠stica Inferencial**. 

Pense assim: a Estat√≠stica Descritiva **organiza e resume** os dados que voc√™ coletou, enquanto a Estat√≠stica Inferencial **tira conclus√µes** sobre uma popula√ß√£o maior a partir da amostra. 

Vamos entender cada uma com exemplos pr√°ticos! 

---

## üìä Estat√≠stica Descritiva

> **O que √©? **  
> A Estat√≠stica Descritiva organiza, resume e apresenta dados de forma clara e compreens√≠vel, usando tabelas, gr√°ficos e medidas num√©ricas.

### üí≠ Exemplo 1: Sa√∫de Mental dos Estudantes

Imagine que voc√™ deseja avaliar a **sa√∫de mental dos estudantes da UFTM**, coletando informa√ß√µes sobre: 

- N√≠veis de **estresse**

- N√≠veis de **ansiedade**  

- Presen√ßa de **depress√£o**

- **Bem-estar geral**

> **Como esses dados s√£o coletados? **  
> Essas informa√ß√µes s√£o obtidas por meio de **instrumentos psicom√©tricos** - question√°rios e escalas cient√≠ficas padronizadas que medem caracter√≠sticas psicol√≥gicas de forma objetiva e confi√°vel.  Esses instrumentos passam por rigorosos processos de valida√ß√£o estat√≠stica para garantir que realmente medem o que se prop√µem a medir.

**Exemplos de instrumentos que podem ser aplicados:**

| Aspecto Avaliado | Instrumento | Descri√ß√£o |
|------------------|-------------|-----------|
| **Estresse** | **PSS-10** (Escala de Estresse Percebido) | Avalia o quanto situa√ß√µes da vida s√£o percebidas como estressantes |
| **Ansiedade** | **BAI** (Invent√°rio de Ansiedade de Beck) ou **GAD-7** | Medem sintomas de ansiedade em diferentes intensidades |
| **Depress√£o** | **BDI-II** (Invent√°rio de Depress√£o de Beck) ou **PHQ-9** | Avaliam presen√ßa e gravidade de sintomas depressivos |
| **Bem-estar** | **Escala de Bem-Estar Subjetivo** ou **WHO-5** | Medem qualidade de vida e satisfa√ß√£o geral |

üí° **Importante:** Embora muitos desses instrumentos possam ser aplicados por pesquisadores de diferentes √°reas (n√£o apenas psic√≥logos), a **interpreta√ß√£o cl√≠nica** e o **diagn√≥stico** devem ser realizados exclusivamente por profissionais habilitados em psicologia ou psiquiatria. 


#### üîß O que a Estat√≠stica Descritiva faz com esses dados? 

| A√ß√£o | Como ajuda?  | Exemplo pr√°tico |
|------|-------------|-----------------|
| **1. Organizar dados** | Cria tabelas sistem√°ticas | Agrupar respostas por curso, per√≠odo, faixa et√°ria |
| **2. Calcular m√©dias** | Resume os dados em um n√∫mero | M√©dia de estresse = 6,5 (escala 0-10) |
| **3. Criar gr√°ficos** | Facilita a visualiza√ß√£o | Gr√°fico de barras mostrando % de alunos com ansiedade baixa/m√©dia/alta |
| **4. Medir variabilidade** | Mostra o quanto os dados variam | Desvio padr√£o alto = muita diferen√ßa entre os alunos |
| **5. Identificar padr√µes** | Encontra rela√ß√µes entre vari√°veis | Alunos que dormem menos t√™m mais estresse?  |

#### üí° Por que isso √© importante? 

Essas an√°lises criam um **panorama claro** da sa√∫de mental dos estudantes, fornecendo base para:

- ‚úÖ Programas de apoio psicol√≥gico

- ‚úÖ Pol√≠ticas institucionais de bem-estar

- ‚úÖ Identifica√ß√£o de grupos que precisam de mais aten√ß√£o

---

### üèÉ‚Äç‚ôÇÔ∏è Exemplo 2: Pr√°tica de Atividades F√≠sicas

Agora, suponha que voc√™ quer entender **como os estudantes se exercitam**. 

#### üìã Dados que voc√™ pode coletar:

1. **Frequ√™ncia semanal**
   - Quantos alunos praticam atividades **mais de 3x por semana**?
   - Resultado: 45% dos estudantes

2. **Tipos de atividade**
   - Use um **gr√°fico ou tabela** para mostrar a distribui√ß√£o: 
     - üèÉ Corrida: 30%
     - üí™ Muscula√ß√£o: 25%
     - ‚öΩ Futebol: 20%
     - üíÉ Dan√ßa: 15%
     - üßò Yoga: 10%

3. **Intensidade da pr√°tica**
   - Crie categorias:  leve, moderada, intensa
   - Use um **gr√°fico ou tabela** para comparar

#### üéØ Aplica√ß√£o pr√°tica:

Com essas informa√ß√µes, a universidade pode:

- ‚úÖ Criar campanhas direcionadas

- ‚úÖ Oferecer novas modalidades esportivas

- ‚úÖ Melhorar a infraestrutura de acordo com as prefer√™ncias

---

## üî¨ Estat√≠stica Inferencial

> **O que √©?**  
> A Estat√≠stica Inferencial usa dados de uma **amostra** (grupo menor) para tirar conclus√µes sobre a **popula√ß√£o inteira**, com margem de confian√ßa conhecida.

### üí≠ Exemplo 1: Sa√∫de Mental dos Estudantes

Voc√™ pesquisou **200 estudantes** (amostra) e quer saber sobre **todos os 6.900 estudantes** da UFTM (popula√ß√£o).

#### üéØ O que a Estat√≠stica Inferencial permite fazer?

**Situa√ß√£o 1: Estimar a m√©dia populacional**

| Da amostra...  | Para a popula√ß√£o... |
|---------------|---------------------|
| M√©dia de ansiedade = 7,0 (escala 0-10) | Estimativa:  ansiedade m√©dia de todos os estudantes est√° entre **6,5 e 7,5** |
| Baseado em 200 alunos | Com **95% de confian√ßa** |

**Situa√ß√£o 2: Comparar grupos diferentes**

Pergunta: *"Estudantes de Medicina t√™m mais ansiedade que estudantes de Engenharia?"*


üìä **Teste de Hip√≥tese:**

- M√©dia Medicina: 7,8

- M√©dia Engenharia: 6,2

- Diferen√ßa: 1,6 pontos

- Resultado do teste:  Diferen√ßa √© estatisticamente significativa (p < 0,05)

- Conclus√£o: Sim, estudantes de Medicina apresentam n√≠veis significativamente maiores de ansiedade


#### ‚úÖ Vantagem: 

Voc√™ **n√£o precisa pesquisar todos os 6.900 alunos** - com uma amostra bem planejada, pode fazer afirma√ß√µes confi√°veis sobre toda a universidade! 

---

### üèÉ‚Äç‚ôÇÔ∏è Exemplo 2: Pr√°tica de Atividades F√≠sicas

Voc√™ pesquisou **300 estudantes** de diferentes cursos. 

#### üéØ Perguntas que a Estat√≠stica Inferencial responde:

**1. Qual a propor√ß√£o real de estudantes ativos? **

- üìä Na amostra:  60% praticam exerc√≠cios regularmente

- üìà Estimativa para toda UFTM: entre 55% e 65%

- üéØ Confian√ßa: 95%


**2. Educa√ß√£o F√≠sica vs. Medicina: quem se exercita mais?**

- üéì Educa√ß√£o F√≠sica: 85% ativos

- üè• Medicina: 42% ativos

- üìä Teste estat√≠stico: Diferen√ßa √© significativa

- üí° Conclus√£o: Estudantes de Educa√ß√£o F√≠sica s√£o mais ativos fisicamente


---

## üé≤ Conex√£o com a Probabilidade

A **Teoria de Probabilidade** √© a ponte entre Estat√≠stica Descritiva e Inferencial! 

### üîó Como funciona? 

```
Estat√≠stica Descritiva
        ‚Üì
   (Probabilidade)
        ‚Üì
Estat√≠stica Inferencial
```

**Exemplo pr√°tico:**

Com base nos dados descritivos, podemos calcular a **probabilidade** de: 

- Um estudante desenvolver sintomas de estresse durante o semestre

- Um aluno que dorme menos de 6h ter ansiedade alta

- Estudantes que praticam exerc√≠cios terem melhor bem-estar mental

Isso permite **prever** e **prevenir**, n√£o apenas descrever!

---

## üë• Popula√ß√£o vs. Amostra

Entender essa diferen√ßa √© **FUNDAMENTAL** para qualquer pesquisa!

### üåç Popula√ß√£o

> √â o **conjunto completo** de todos os indiv√≠duos que voc√™ quer estudar.

**Exemplo UFTM:**

- üë®‚Äçüéì **6.900 estudantes** (dado:  DRCA, dezembro/2024 - Incluindo:  gradua√ß√£o, cursos t√©cnicos e p√≥s-gradua√ß√£o)

### üéØ Amostra

> √â um **grupo menor e representativo** selecionado da popula√ß√£o.

**Exemplo UFTM:**

- üë• **364 estudantes** selecionados aleatoriamente

- Representa toda a popula√ß√£o com **95% de confian√ßa**

- Erro m√°ximo de **5%**

---

### üìê Exemplo Aplicado Completo

Vamos juntar tudo em um exemplo real:

#### üéØ Objetivo da Pesquisa
Avaliar o **bem-estar emocional** dos estudantes da UFTM. 

#### üìä Etapa 1: Coleta de Dados (Estat√≠stica Descritiva)
- **Popula√ß√£o:** 6.900 estudantes
- **Amostra:** 364 estudantes (sele√ß√£o aleat√≥ria)
- **Instrumento:** Question√°rio padronizado (escala 0-10)

#### üìà Etapa 2: An√°lise Descritiva

Resultados da amostra (364 estudantes):

- M√©dia de bem-estar:  6,8

- Desvio padr√£o: 1,5

- M√≠nimo: 2,0

- M√°ximo: 10,0


#### üî¨ Etapa 3: Infer√™ncia Estat√≠stica

Generaliza√ß√£o para TODA a UFTM (6.900 estudantes):

-‚úÖ M√©dia estimada: 6,8

-üìè Intervalo de confian√ßa (IC95%): 6,46 a 7,14

-‚ö†Ô∏è Margem de erro: ¬±5%

-üéØ **Interpreta√ß√£o:** 
Temos 95% de confian√ßa de que o bem-estar emocional m√©dio de TODOS os estudantes da UFTM est√° entre 6,46 e 7,14.


#### üí° O que √© IC95%?

Se voc√™ repetisse essa pesquisa **100 vezes** com diferentes amostras aleat√≥rias de 364 estudantes: 

- ‚úÖ Em **95 vezes**, a m√©dia estaria entre 6,46 e 7,14

- ‚ùå Em **5 vezes**, poderia estar fora desse intervalo (erro amostral)

---

### ‚ú® Resumo Visual

```
POPULA√á√ÉO (6.900 estudantes)
        ‚Üì
   Sele√ß√£o aleat√≥ria
        ‚Üì
AMOSTRA (364 estudantes)
        ‚Üì
   Estat√≠stica Descritiva
   (organizar, calcular, visualizar)
        ‚Üì
   Estat√≠stica Inferencial
   (estimar, comparar, concluir)
        ‚Üì
CONCLUS√ïES sobre a POPULA√á√ÉO INTEIRA
   (com margem de erro conhecida)
```

---

## üéì Recapitulando

| Conceito | O que faz?  | Quando usar? |
|----------|------------|--------------|
| **Estat√≠stica Descritiva** | Organiza e resume os dados | Quando voc√™ quer **descrever** o que coletou |
| **Estat√≠stica Inferencial** | Tira conclus√µes sobre a popula√ß√£o | Quando voc√™ quer **generalizar** da amostra para todos |
| **Popula√ß√£o** | Todos que voc√™ quer estudar | Define o **alcance** da sua pesquisa |
| **Amostra** | Grupo menor representativo | Torna a pesquisa **vi√°vel** |
| **Probabilidade** | Calcula chances e incertezas | **Conecta** descritiva e inferencial |

---


<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>
</center>

**üí≠ Agora reflita:** *Em uma pesquisa sobre h√°bitos alimentares dos estudantes, como voc√™ aplicaria esses conceitos?*

# Tamanho da Amostra

O c√°lculo do **tamanho da amostra** √© um passo importante em qualquer pesquisa. Ele nos ajuda a determinar quantos participantes precisamos para que os resultados sejam representativos e estatisticamente confi√°veis. Embora o c√°lculo envolva alguns conceitos de **estat√≠stica inferencial**, hoje em dia, esse processo pode ser muito mais simples, gra√ßas a ferramentas online e at√© mesmo com o aux√≠lio de **Intelig√™ncia Artificial (IA)**.

## Passos b√°sicos para o c√°lculo do tamanho da amostra

Quando o **objetivo √© estimar uma propor√ß√£o**, o c√°lculo do tamanho amostral exige algumas informa√ß√µes essenciais:

1. **Tamanho da popula√ß√£o**: Neste caso, os estudantes da UFTM, que somam cerca de **6.900**.
2. **Margem de erro**: A precis√£o com que queremos que nossa estimativa esteja pr√≥xima da realidade. Por exemplo, uma margem de erro de **5%** √© comum em muitos estudos.
3. **N√≠vel de confian√ßa**: Normalmente, utiliza-se 95%, que indica a probabilidade de que o intervalo de confian√ßa contenha o valor real.

A f√≥rmula para calcular o tamanho da amostra √©:

\[
n = \frac{{Z^2 \cdot p \cdot (1 - p)}}{{E^2}}
\]

Onde:

- \(n\) = tamanho da amostra
- \(Z\) = valor da distribui√ß√£o normal (geralmente 1,96 para 95% de confian√ßa)
- \(p\) = propor√ß√£o estimada (por exemplo, 0,5 para o pior cen√°rio)
- \(E\) = margem de erro (por exemplo, 0,05 para 5%)

### Exemplo de c√°lculo simples

Vamos calcular o tamanho da amostra para uma pesquisa na UFTM, onde sabemos que a popula√ß√£o tem **6.900 estudantes**, a margem de erro √© **5%**, o n√≠vel de confian√ßa √© **95%**, e vamos supor que queremos estimar uma propor√ß√£o de **50%** (o pior cen√°rio para garantir maior precis√£o).

Usando a f√≥rmula, temos:

- \(Z = 1,96\) (para 95% de confian√ßa)
- \(p = 0,5\) (propor√ß√£o estimada)
- \(E = 0,05\) (margem de erro de 5%)

Substituindo os valores na f√≥rmula, obtemos:

\[
n = \frac{{1,96^2 \cdot 0,5 \cdot (1 - 0,5)}}{{0,05^2}} = 384
\]

Logo, o tamanho da amostra necess√°rio √© **384** estudantes para garantir uma margem de erro de 5% com 95% de confian√ßa.

**Observa√ß√£o:** A f√≥rmula apresentada acima √© utilizada para o c√°lculo do tamanho amostral quando se deseja estimar uma propor√ß√£o, assumindo uma popula√ß√£o infinita (ou muito grande). Para situa√ß√µes em que o objetivo √© estimar a m√©dia populacional, a f√≥rmula adequada √© diferente e leva em conta o desvio padr√£o da vari√°vel em vez da propor√ß√£o. Al√©m disso, se a popula√ß√£o for finita, √© necess√°rio aplicar o fator de corre√ß√£o amostral.

### Ferramentas para c√°lculo de amostra

Nosso foco aqui n√£o √© ensinar a fazer os c√°lculos manualmente, mas compreender os conceitos envolvidos. Existem diversas ferramentas online gratuitas que fazem o c√°lculo automaticamente. Por exemplo:

## C√°lculo do Tamanho da Amostra

Para calcular o tamanho da amostra, podemos utilizar diferentes ferramentas, tanto no **R** quanto online. Aqui est√£o algumas op√ß√µes:

- **No R**: Para calcular o tamanho da amostra, podemos utilizar o **pacote pwr**, que oferece fun√ß√µes espec√≠ficas para realizar esses c√°lculos de forma simples e eficaz. O pacote √© ideal para quem precisa calcular o tamanho da amostra para testes de hip√≥teses, como testes de m√©dias, propor√ß√µes ou an√°lise de vari√¢ncia, ajustando facilmente os par√¢metros conforme as necessidades da pesquisa.

- **Calculadora Amostral Online da USP Bauru**: [Clique aqui para acessar](http://estatistica.bauru.usp.br/calculoamostral/) - Uma ferramenta simples e eficiente para c√°lculos amostrais.

- **G\*Power**: Um software gratuito que pode ajudar a calcular o tamanho da amostra dependendo do tipo de an√°lise estat√≠stica que voc√™ ir√° realizar. [Saiba mais sobre o G*Power](https://www.gpower.hhu.de/en.html).

- **OpenEpi ‚Äì Sample Size**: [Acesse aqui](https://www.openepi.com/SampleSize/SSMean.htm) - Muito usado na √°rea da sa√∫de, permite calcular amostras para m√©dia, propor√ß√£o, estudos de caso-controle, coorte, entre outros.

## Conclus√£o

Em resumo, o c√°lculo do **tamanho da amostra** √© um passo essencial para garantir que suas pesquisas sejam precisas e representativas. Embora os c√°lculos possam parecer complexos, hoje em dia, existem ferramentas poderosas e **Intelig√™ncia Artificial** para facilitar esse processo, economizando tempo e esfor√ßo na sua pesquisa.


<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
```
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>

</center>

## Atividade 2

**Responda a partir do artigo buscado na atividade 1.**

1. **Os autores discutem o c√°lculo do tamanho da amostra no estudo?**
   - Voc√™ consegue identificar se os autores fornecem uma explica√ß√£o clara sobre como determinaram o tamanho da amostra na pesquisa? Eles utilizaram alguma f√≥rmula espec√≠fica ou ferramenta estat√≠stica para esse c√°lculo?

2. **A popula√ß√£o da pesquisa foi claramente definida pelos autores?**
   - Os autores descreveram com clareza quem comp√µe a popula√ß√£o da pesquisa (por exemplo, caracter√≠sticas demogr√°ficas, contexto da amostra, entre outros)? A popula√ß√£o foi bem delineada para garantir que os resultados sejam representativos?

3. **O tamanho da amostra utilizado no estudo foi adequado?**
   - Com base no c√°lculo do tamanho de amostra, voc√™ acha que a amostra utilizada no estudo foi grande o suficiente para garantir a precis√£o dos resultados? Ela foi suficientemente representativa da popula√ß√£o alvo da pesquisa?

4. **Realize o c√°lculo do tamanho de amostra para este estudo.**
   - Com as informa√ß√µes fornecidas pelos autores, voc√™ pode calcular o tamanho da amostra necess√°rio para o estudo utilizando uma f√≥rmula ou ferramenta de c√°lculo amostral. Considere aspectos como o n√≠vel de confian√ßa, margem de erro e variabilidade dos dados.

5. **Os autores mencionaram se a pesquisa foi aprovada pelo Comit√™ de √âtica?**
   - No artigo, h√° alguma refer√™ncia sobre a aprova√ß√£o √©tica da pesquisa? Os autores informaram se a pesquisa foi submetida e aprovada por um Comit√™ de √âtica em Pesquisa (CEP)?

6. **Qual √© a import√¢ncia de submeter a pesquisa ao Comit√™ de √âtica?**
   - Por que √© essencial que a pesquisa seja submetida a um Comit√™ de √âtica? Quais s√£o as implica√ß√µes √©ticas de n√£o realizar essa submiss√£o, especialmente em pesquisas que envolvem seres humanos?


**Importante**

> Conhe√ßa o Comit√™ de √âtica em Pesquisa (CEP) da UFTM

<https://www.uftm.edu.br/comitesecomissoes/cep>


# T√©cnicas de Amostragem

Em pesquisas, uma das etapas mais importantes √© o **c√°lculo amostral**, que determina quantos participantes ser√£o necess√°rios para garantir que os resultados sejam confi√°veis. Depois, √© preciso escolher uma **t√©cnica de amostragem**, ou seja, como vamos selecionar as pessoas ou unidades que far√£o parte da pesquisa. Uma parte essencial disso √© garantir que o processo de amostragem evite **vi√©s**, que ocorre quando a amostra n√£o representa adequadamente a popula√ß√£o.

Existem v√°rias t√©cnicas de amostragem, cada uma com suas caracter√≠sticas, vantagens e desvantagens.

---

## Amostragem Aleat√≥ria Simples

Nesta t√©cnica, cada elemento da popula√ß√£o tem a mesma chance de ser selecionado.

> **Exemplo:** Se quisermos estudar a sa√∫de mental dos estudantes da UFTM, podemos utilizar uma lista completa dos alunos e, de maneira aleat√≥ria (sorteio), selecionar os estudantes que far√£o parte da amostra, conforme o n√∫mero determinado pelo c√°lculo amostral.

- **Vantagens:** √â simples de aplicar e garante que todos t√™m a mesma chance de ser escolhidos, minimizando o vi√©s.
- **Desvantagens:** Pode ser dif√≠cil de implementar se a popula√ß√£o for muito grande ou se n√£o tivermos uma lista completa de todos os membros da popula√ß√£o. 
- **Como evitar vi√©s:** Garantir que a lista de onde ser√£o sorteados os participantes seja completa e atualizada.

---

## Amostragem Estratificada

Aqui, a popula√ß√£o √© dividida em grupos ou "estratos" (por exemplo, cursos ou faixas et√°rias) e, em seguida, amostras s√£o selecionadas dentro de cada estrato.

> **Exemplo:** Suponha que queremos estudar a pr√°tica de atividade f√≠sica entre os estudantes da UFTM. Podemos usar amostragem estratificada, dividindo os alunos por curso (estratos). Dentro de cada curso, selecionamos aleatoriamente um n√∫mero proporcional de alunos, garantindo que todos os cursos estejam representados de forma adequada na amostra, refletindo a diversidade da universidade.

- **Vantagens:** Melhora a representatividade da amostra, especialmente quando diferentes subgrupos podem ter comportamentos ou caracter√≠sticas distintas. Ajuda a evitar vi√©s ao garantir que todos os grupos da popula√ß√£o estejam representados.
- **Desvantagens:** √â necess√°rio conhecer a popula√ß√£o e seus estratos de antem√£o, o que pode ser dif√≠cil em alguns casos.
- **Como evitar vi√©s:** A defini√ß√£o dos estratos deve ser precisa e relevante para a pesquisa.

---

## Amostragem Sistem√°tica

Na amostragem sistem√°tica, escolhemos um ponto de partida aleat√≥rio e, a partir da√≠, selecionamos unidades a intervalos regulares de "n" unidades.

> **Exemplo:** Se quisermos estudar a pr√°tica de atividade esportiva entre os estudantes da UFTM e temos uma lista de todos os alunos, podemos selecionar a cada 10¬∫ aluno da lista para participar da pesquisa.

- **Vantagens:** F√°cil de implementar, especialmente em popula√ß√µes grandes, e garante uma distribui√ß√£o uniforme dos selecionados ao longo da lista.
- **Desvantagens:** Pode ocorrer vi√©s caso haja algum padr√£o na ordem da lista (por exemplo, se alunos de cursos espec√≠ficos forem listados consecutivamente, a amostra pode n√£o ser representativa).
- **Como evitar vi√©s:** A lista de sele√ß√£o deve ser aleat√≥ria e n√£o seguir um padr√£o que favore√ßa um grupo espec√≠fico.

---

## Amostragem por Conglomerados

Nessa t√©cnica, a popula√ß√£o √© dividida em grupos (chamados de conglomerados) e, em seguida, seleciona-se aleatoriamente alguns desses grupos para fazer parte da amostra.

> **Exemplo:** Em vez de selecionar alunos aleatoriamente, selecionar alguns cursos espec√≠ficos da UFTM e estudar todos os alunos desses cursos. Essa t√©cnica √© √∫til quando a popula√ß√£o √© muito grande e dif√≠cil de acessar como um todo.

- **Vantagens:** Mais f√°cil de administrar em popula√ß√µes grandes, quando n√£o se tem acesso a uma lista completa de todos os indiv√≠duos.
- **Desvantagens:** Pode n√£o ser t√£o representativa, pois estamos escolhendo grupos inteiros e n√£o indiv√≠duos aleat√≥rios.
- **Como evitar vi√©s:** Os conglomerados escolhidos devem representar adequadamente a diversidade da popula√ß√£o.

---

## Amostragem por Conveni√™ncia

Na **amostragem por conveni√™ncia**, os participantes s√£o selecionados por serem mais f√°ceis de acessar pelo pesquisador.

> **Exemplo:** O uso de formul√°rios online, como o Google Forms, √© uma forma comum de amostragem por conveni√™ncia. O pesquisador compartilha o formul√°rio em redes sociais, grupos de WhatsApp ou por e-mail, e os primeiros que responderem entram para a amostra.

- **Vantagens:** R√°pida, pr√°tica, econ√¥mica e permite coletar dados de muitas pessoas em pouco tempo.
- **Desvantagens:** Forte risco de vi√©s, pois a amostra pode n√£o representar a popula√ß√£o como um todo, j√° que depende de quem tem acesso ao link, internet e interesse em responder.
- **Como evitar vi√©s:** Embora n√£o seja poss√≠vel eliminar totalmente o vi√©s, recomenda-se divulgar o formul√°rio em diferentes canais e para p√∫blicos diversos, incentivando a participa√ß√£o de v√°rios grupos.

**Aten√ß√£o aos Vieses no Uso de Formul√°rios Online:**

- **Vi√©s de acesso:** Apenas pessoas com acesso √† internet podem responder.
- **Vi√©s de auto-sele√ß√£o:** Aqueles mais motivados ou interessados no tema tendem a participar mais.
- **Vi√©s de distribui√ß√£o:** Se o link for enviado apenas a determinados grupos, outros podem ser sub-representados.

Portanto, ao usar formul√°rios online, √© importante considerar essas limita√ß√µes e, se poss√≠vel, adotar estrat√©gias para ampliar o alcance e a diversidade dos respondentes.

---

## Combinando T√©cnicas na Pr√°tica

Na pr√°tica, √© comum que pesquisadores combinem diferentes t√©cnicas de amostragem para aumentar a representatividade e reduzir o vi√©s da amostra, adaptando o processo √†s caracter√≠sticas espec√≠ficas da popula√ß√£o e aos objetivos do estudo.

Por exemplo, pode-se aplicar a **amostragem estratificada** para garantir que todos os subgrupos relevantes (como cursos, faixas et√°rias ou regi√µes) estejam proporcionalmente representados na amostra. Em seguida, dentro de cada estrato, pode-se utilizar a **amostragem aleat√≥ria simples** para selecionar os participantes de forma justa e imparcial.

Al√©m disso, em situa√ß√µes em que o acesso √† popula√ß√£o √© limitado, pode-se recorrer √† combina√ß√£o de t√©cnicas probabil√≠sticas (como estratificada ou sistem√°tica) com m√©todos n√£o probabil√≠sticos (como conveni√™ncia), sempre buscando estrat√©gias para minimizar poss√≠veis vieses e aumentar a diversidade dos participantes.

Ao combinar m√©todos, o pesquisador consegue contornar limita√ß√µes pr√°ticas (como listas incompletas ou dificuldades de acesso) e, ao mesmo tempo, assegurar que a amostra reflita com maior fidelidade a diversidade da popula√ß√£o, tornando os resultados mais robustos e confi√°veis.

---

## Evitar Vi√©s na Amostragem

O **vi√©s de amostragem** ocorre quando certos grupos da popula√ß√£o t√™m mais chance de ser selecionados do que outros, o que pode distorcer os resultados da pesquisa. Para evitar vi√©s, √© essencial:

- Garantir que todos os grupos da popula√ß√£o tenham uma chance igual ou proporcional de ser selecionados.
- Utilizar t√©cnicas que levem em considera√ß√£o as caracter√≠sticas espec√≠ficas da popula√ß√£o.
- Combinar diferentes m√©todos de amostragem para melhorar a representatividade.

---

## Resumindo

- **Probabil√≠stica:** amostragem aleat√≥ria simples, sistem√°tica, estratificada, por conglomerados.
- **N√£o probabil√≠stica:** amostragem por conveni√™ncia (incluindo Google Forms), intencional, por cotas.

> A escolha da t√©cnica deve considerar os objetivos da pesquisa, os recursos dispon√≠veis e a necessidade de representatividade da amostra.





<!--chapter:end:01-Introducao.Rmd-->

# Ambiente Computacional {#ambiente-computacional}

Existem diversos softwares dedicados √† an√°lise estat√≠stica, que v√£o desde planilhas eletr√¥nicas, como o Excel, at√© programas mais robustos, como o SPSS. Abaixo, listamos algumas das principais ferramentas utilizadas:

## Softwares pagos

- [SPSS (IBM)](https://www.ibm.com/br-pt/spss)
- [Stata](https://www.stata-brasil.com/software/stata.html)
- [SAS](https://www.sas.com/pt_br)
- [JMP](https://www.jmp.com/)
- [Prism](https://software.com.br/p/prism)
- [Minitab](https://osbsoftware.com.br/produto/minitab-statistical-software)
- Microsoft Excel

## Softwares livres

- [Jamovi](https://www.jamovi.org)
- [OpenStat](https://openstat.info)

## Linguagens computacionais

- [R](https://www.r-project.org)
- [Python](https://www.python.org/)

Neste curso, utilizaremos a linguagem **R**, desenvolvida especialmente para an√°lise estat√≠stica. Quer entender por que essa escolha? Recomendamos a leitura: [Por que usar R?](https://blog.curso-r.com/posts/2021-07-23-por-que-usar-r/)

## Preparando o Ambiente Computacional

Vamos preparar o ambiente computacional para realizar nossas an√°lises com R.

> Para esclarecer:
> - **R** √© uma linguagem de programa√ß√£o (mas n√£o se preocupe, n√£o vamos programar profundamente).
> - **RStudio** √© o software onde os c√≥digos R ser√£o executados. √â o que chamamos de IDE ‚Äì *Integrated Development Environment* (Ambiente de Desenvolvimento Integrado).

## Plano A: Instala√ß√£o do R e RStudio

Nos laborat√≥rios da UFTM, o R e o RStudio j√° est√£o instalados. No entanto, sugerimos que voc√™ tamb√©m os instale em seu computador pessoal, pois nem sempre conseguiremos realizar todas as atividades em sala.

Siga estes passos:

1. Instale o R: [https://cran.rstudio.com](https://cran.rstudio.com)
2. Instale o RStudio Desktop: [https://posit.co/download/rstudio-desktop](https://posit.co/download/rstudio-desktop)

> Certifique-se de baixar vers√µes compat√≠veis com o sistema operacional do seu computador.

Se tudo estiver correto, ao abrir o RStudio, voc√™ ver√° uma tela semelhante a esta:

<center>![Figura: Tela inicial do RStudio](telaRStudio.png)</center>

Caso enfrente dificuldades, siga para o Plano B.

## Plano B: R e RStudio na Nuvem

O Plano B √© utilizar o RStudio diretamente na nuvem, sem precisar instalar nada. Essa alternativa √© excelente, mas requer uma boa conex√£o com a internet.

Siga os passos:

1. Acesse: [https://posit.cloud](https://posit.cloud)
2. Fa√ßa login (voc√™ pode usar sua conta do Google, por exemplo)
3. Ap√≥s o login, voc√™ ver√° esta tela:

<center>![Figura: Tela inicial na nuvem da Posit](telaPosit.png)</center>

4. Crie um novo projeto clicando em *New Project* e, depois, *New RStudio Project*:

<center>![Figura: Bot√£o de cria√ß√£o de um novo projeto](telaCriarProjetoRStudio.png){width=40%}</center>

5. Pronto! A interface do RStudio ser√° carregada na nuvem:

<center>![Figura: Tela do RStudio online na Posit Cloud](telaRStudioPosit.png)</center>

> Vantagem: seus arquivos e an√°lises ficam salvos na nuvem, em um local seguro e acess√≠vel de qualquer lugar.

---

Com o ambiente configurado, estaremos prontos para explorar o mundo da estat√≠stica com R!

<!--chapter:end:02-Ambiente-Computacional.Rmd-->

# Trabalhando no RStudio {#trabalhando-RStudio}

Seja na vers√£o instalada no seu computador (plano A) ou na nuvem (plano B), conhe√ßa melhor as √°reas do RStudio:

1. **Console:** local onde ser√£o apresentadas as respostas para c√≥digos executados;

2. **Ambiente de mem√≥ria (Environment):** √© o c√©rebro do R, onde ficam registrados os objetos que ele reconhece.

3. A √°rea de **Arquivos (Files), Gr√°ficos (Plots), Pacotes (Packages), Ajuda (Help), Visualiza√ß√£o (Viewer) e Apresenta√ß√£o (Presentation)**: mostram, respectivamente, os arquivos do diret√≥rio onde est√£o seus arquivos no computador, os gr√°ficos, os pacotes, a ajuda, a janela de visualiza√ß√£o e a apresenta√ß√£o.

A figura abaixo identifica cada uma dessas √°reas:

<center>![<font size="2">Figura: Identifica√ß√£o das √°reas do RStudio</font>](telaRStudio123.png)</center>

Digitaremos os c√≥digos da linguagem R, em um arquivo que chamamos de **script**. Para abrir um arquivo do tipo script R, fa√ßa:

1. Acesse a op√ß√£o **File** no menu principal do RStudio;
2. Escolha a op√ß√£o **New File**;
3. E depois a op√ß√£o **R Script**.

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](arquivoScript.png){width=40%}</center>

Assim, na tela da IDE RStudio aparecer√° uma nova √°rea, que √© a √°rea do arquivo script, como mostra a figura.

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](telaScript.png)</center>

Observe que o arquivo est√° sem um nome (**Untitled1**, sem t√≠tulo). Salve o arquivo atribuindo-lhe um nome adequado. Para isso, no menu principal, escolha *File*, depois *Save*.

> Dica: O ideal seria criar um **Projeto**. Veja a op√ß√£o _File > New Project_.

<!--chapter:end:03-RStudio.Rmd-->

# Primeiros exerc√≠cios no R

Nos cap√≠tulos  \@ref(ambiente-computacional) e \@ref(trabalhando-RStudio) vimos sobre o ambiente computacional (computador ou nuvem) e identificamos as 4 √°reas da tela da interface do RStudio: **console**, **ambiente de mem√≥ria**, **arquivos, gr√°ficos, etc.** e **script**, assim estamos prontos para escrever alguns c√≥digos e execut√°-los a partir da √°rea de script.

> **Aten√ß√£o:** TODOS os c√≥gigos ser√£o digitados no arquivo de script, seguindo uma sequ√™ncia l√≥gica de passos, ou seja, escreveremos um roteiro (*script*), como se fosse uma receita de bolo, isso √© o que o pessoal da computa√ß√£o chama de algoritmo.


## Exemplo 1

* Observe o c√≥digo escrito na linha 1 do arquivo de script e o bot√£o **Run** (primeira seta verde):

<center>![<font size="2">Figura: Primeiro exemplo de c√≥gigo R</font>](telaExemplo1.png)
</center>

* O sequ√™ncia de caracteres **<-** √© o s√≠mbolo de atribui√ß√£o no R.

> Pressionando as teclas ALT e - (menos) simultaneamente cria no script o sinal de atribui√ß√£o.

* O c√≥digo significa que criamos um objeto chamado **x** e atribuimos a esse objeto o valor 2.

* No entanto, o R ainda n√£o sabe que o valor de x √© igual a 2! 

* Para registrar essa informa√ß√£o na mem√≥ria do R, devemos executar essa linha.

> Para executar uma linha posicione o cursor na linha, e clique no bot√£o **Run**

<center>![<font size="2">Figura: O objeto x √© registrado na mem√≥ria do R, armazenando o valor igual a 2</font>](telaValorMemoria.png){width=40%}
</center>

> Observe sempre o ambiente de mem√≥ria (bem como o console) quando executar uma linha.

## Exemplo 2

Execute o seguinte c√≥gigo no R.

```{r}
idades <- c( 23, 18, 17, 25, 21, 19, 22, 24, 19, 19 )
```

* Esse c√≥digo significa que foi criado um objeto chamado idade que armazena 10 valores: 23, 18, 17, 25, 21, 19, 22, 24, 19, 19, diferentemente do exemplo 1 em que x armazenava somente o valor 2. 

* Isso foi poss√≠vel pois usamos a fun√ß√£o **c( )**.

* observe que os valores foram colocado dentro dos par√™nteses da fun√ß√£o **c( )**

> Com fun√ß√£o **c( )** podemos **combinar** v√°rios valores em um objeto, esse objeto recebe o nome de vetor ou lista.


## Exemplo 3 

Observe nesse c√≥digo as fun√ß√µes:

* **max( )**

* **min( )**

* **range( )**

* **mean( )**

* **sd( )**

```{r echo=TRUE}
# criando o vetor idades 
idades <- c( 23, 18, 17, 25, 21, 19, 22, 24, 19, 19 )

# maior valor
# fun√ß√£o max( )
max(idades)

# menor valor
# fun√ß√£o min( )
min(idades)

# faixa de valores
# fun√ß√£o range( )
range(idades)

# m√©dia (mean)
# fun√ß√£o mean( )
mean(idades)

# desvio padr√£o (standard deviation)
# fun√ß√£o sd() 
sd(idades)
```

> Copie o c√≥digo e cole no seu arquivo script, selecione todo conte√∫do (CRTL+A) e execute todo o c√≥gigo de uma √∫nica vez.

* Observe que as respostas apareceram no **console**, conforme mostrado na figura abaixo:

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](telaRespostaConsole.png){width=40%}
</center>

> O s√≠mbolo # √© o s√≠mbolo de coment√°rio, isso significa que podemos escrever qualquer texto diferente do que o R sabe interpretar, e mesmo executando o c√≥digo nenhum erro acontece! 

> **IMPORTANTE**: √© uma boa pr√°tica comentar os trechos de c√≥digos para deixar documentado qual √© o objetivo do c√≥digo.


<!--chapter:end:04-Primeiros-Exercicios.Rmd-->

# Tipos de Vari√°veis

As vari√°veis podem ser classificadas de acordo com sua natureza:

## Vari√°veis Quantitativas
Expressam **quantidade** e podem ser divididas em:

- **Discreta**: Assume valores inteiros (contagem).
  - *Exemplo*: O n√∫mero de filhos de uma pessoa. Voc√™ pode contar 0, 1, 2, 3 filhos, mas n√£o pode ter 2,5 filhos.
  
- **Cont√≠nua**: Assume qualquer valor dentro de um intervalo espec√≠fico (mensura√ß√£o).
  - *Exemplo*: A altura de uma pessoa, que pode ser 1,70 m, 1,71 m, 1,711 m, e assim por diante, com infinitas possibilidades entre os valores.

## Vari√°veis Qualitativas
Expressam **qualidade** e s√£o representadas por **categorias** ou **r√≥tulos**. S√£o subdivididas em:

- **Nominal**: Categorias que n√£o podem ser ordenadas.
  - *Exemplo*: O tipo de fruta que voc√™ prefere, como ma√ß√£, banana, laranja. N√£o faz sentido ordenar essas categorias de maneira que uma seja "maior" que a outra.
  
- **Ordinal**: Categorias que podem ser ordenadas, com uma gradua√ß√£o entre elas.
  - *Exemplo*: N√≠veis de satisfa√ß√£o de um servi√ßo, como "satisfeito", "neutro" e "insatisfeito". Aqui, existe uma ordem em que "satisfeito" √© maior que "neutro", e "neutro" √© maior que "insatisfeito".

Uma aplica√ß√£o comum das vari√°veis ordinais √© a **Escala Likert**, que √© amplamente utilizada em pesquisas de opini√£o para medir atitudes ou percep√ß√µes. A escala Likert geralmente apresenta uma s√©rie de afirmativas, e o participante deve indicar seu n√≠vel de concord√¢ncia com cada uma delas, com respostas em uma sequ√™ncia ordenada.

*Exemplo*: Em uma pesquisa de satisfa√ß√£o de clientes, a pergunta poderia ser: "Concordo que a alimenta√ß√£o oferecida pelo hospital foi satisfat√≥ria." As op√ß√µes de resposta poderiam ser:

1. **Discordo totalmente**
2. **Discordo parcialmente**
3. **Neutro**
4. **Concordo parcialmente**
5. **Concordo totalmente**

Essas respostas formam uma escala ordinal, pois a ordem das categorias reflete um aumento no n√≠vel de concord√¢ncia, mas as diferen√ßas entre elas n√£o s√£o necessariamente iguais.

> **Dica**: Veja o v√≠deo do Prof. Heitor no **Canal Pesquise**: [Assista aqui](https://youtu.be/_oc37Ea_tl8).

## Aplica√ß√£o das Vari√°veis em Estat√≠stica

A natureza da vari√°vel influencia o tipo de procedimento estat√≠stico que ser√° utilizado. Exemplos:

### Estat√≠stica Descritiva:
- **Vari√°veis Qualitativas**: S√£o representadas por sua **frequ√™ncia absoluta** ou **percentual**.
  - *Exemplo*: Em uma pesquisa de prefer√™ncia de frutas, pode-se dizer que 40% das pessoas escolheram ma√ß√£, 35% escolheram banana, e 25% escolheram laranja.
  
- **Vari√°veis Quantitativas**: S√£o representadas por **medidas resumo**, como **m√©dia** e **desvio padr√£o**.
  - *Exemplo*: Se voc√™ calcular a m√©dia de altura de um grupo de pessoas, e o desvio padr√£o indicar que a altura das pessoas varia em torno de 5 cm da m√©dia.

### Estat√≠stica Inferencial:
- **Teste Qui-Quadrado**: Usado para verificar se h√° associa√ß√£o entre as categorias de duas vari√°veis qualitativas.
  - *Exemplo*: Um teste Qui-Quadrado poderia ser utilizado para verificar se a escolha de fruta (ma√ß√£, banana, laranja) tem rela√ß√£o com o sexo (masculino, feminino) dos participantes.

- **Teste de Correla√ß√£o de Pearson**: Mede a for√ßa da correla√ß√£o linear entre duas vari√°veis quantitativas.
  - *Exemplo*: O teste de Pearson poderia ser utilizado para verificar se existe uma rela√ß√£o entre a altura e o peso das pessoas. Quanto maior a altura, maior o peso? Esse teste nos diria a for√ßa dessa rela√ß√£o.


<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>

## Atividade 3

**Leia o artigo _Estado nutricional, tempo de interna√ß√£o e mortalidade em pacientes submetidos √† cirurgia card√≠aca em um hospital na cidade de Macei√≥_**  
Dispon√≠vel em: [RASBRAN, Revista da Associa√ß√£o Brasileira de Nutri√ß√£o, 2023](https://www.rasbran.com.br/rasbran/article/view/1724/443)  
Acesse tamb√©m o portal: [RASBRAN - Revista da Associa√ß√£o Brasileira de Nutri√ß√£o](https://www.rasbran.com.br/).

### An√°lise das Tabelas

- **Tabela 1 - Caracter√≠sticas cl√≠nicas dos pacientes submetidos √† cirurgia card√≠aca**: Esta tabela apresenta as caracter√≠sticas da amostra analisada na pesquisa. 
  - **Tarefa**: Classifique as vari√°veis (caracter√≠sticas) em **qualitativas** e **quantitativas**.
  - **Observa√ß√£o**: Verifique como as vari√°veis foram resumidas. Elas foram apresentadas em **porcentagens**? Ou foram calculadas medidas de **m√©dia** e **desvio padr√£o**?

- **Tabela 2 - Associa√ß√£o entre estado nutricional, sexo, idade e tempo de interna√ß√£o hospitalar entre os pacientes submetidos √† cirurgia card√≠aca**  
- **Tabela 3 - Associa√ß√£o entre evolu√ß√£o cl√≠nica, sexo, idade, tempo de interna√ß√£o hospitalar e estado nutricional entre os pacientes submetidos √† cirurgia card√≠aca**: Estas tabelas mostram os resultados de um **teste de hip√≥tese** (parte da estat√≠stica inferencial).
  - **Tarefa**: Identifique qual **teste estat√≠stico** foi aplicado.
  - **Objetivo**: Qual √© o objetivo deste teste?


<!--chapter:end:05-Tipos-Variaveis.Rmd-->

# Estat√≠stica Descritiva

A estat√≠stica descritiva permite **resumir, organizar e interpretar** dados de forma clara e objetiva. Para isso, utilizamos **medidas de tend√™ncia central**, **medidas de dispers√£o** e **medidas relativas de variabilidade**.

## Medidas de Tend√™ncia Central (ou Posi√ß√£o)

### M√©dia

- **Defini√ß√£o:** Soma de todos os valores dividida pelo n√∫mero de observa√ß√µes.  
- **Interpreta√ß√£o:** Representa o valor m√©dio ou t√≠pico do conjunto de dados.  
- **Como reportar:**  

> A m√©dia dos batimentos card√≠acos foi de 58,6 bpm, indicando o valor m√©dio da amostra analisada.

### Mediana

- **Defini√ß√£o:** Valor central de um conjunto ordenado de dados.  
- **Interpreta√ß√£o:** Divide o conjunto de dados ao meio, sendo √∫til quando h√° valores extremos (outliers).  
- **Como reportar:**  

> A mediana dos batimentos foi de 60,0 bpm, indicando que 50% dos indiv√≠duos apresentaram valores abaixo ou iguais a esse valor.

### Quartis

- **Defini√ß√£o:** Q1 (primeiro quartil) e Q3 (terceiro quartil) representam os valores que dividem os 25% e os 75% inferiores dos dados, respectivamente.  
- **Interpreta√ß√£o:** Ajudam a entender a distribui√ß√£o dos dados e identificar a dispers√£o em torno da mediana.  
- **Como reportar:**  

> O primeiro e o terceiro quartis foram 54,0 bpm e 64,0 bpm, respectivamente, revelando que 50% dos batimentos ficaram entre esses dois valores.

### Moda

- **Defini√ß√£o:** Valor mais frequente do conjunto de dados.  
- **Interpreta√ß√£o:** Indica o valor mais comum, embora possa n√£o existir ou haver mais de uma moda.  
- **Como reportar:**  

> A moda foi 62 bpm, valor que ocorreu com maior frequ√™ncia na amostra.

**Observa√ß√£o importante:**  
- **M√©dia e desvio padr√£o** s√£o medidas que devem ser usadas juntas, especialmente para dados sim√©tricos (distribui√ß√£o sim√©trica) e sem valores extremos.
- **Mediana e quartis** formam outro conjunto de medidas, mais apropriado quando h√° assimetria ou presen√ßa de outliers.

**Sugest√£o de v√≠deo:** Canal Pesquise - [Tend√™ncia Central](https://youtu.be/ot0aDB-grDY)


## Medidas de Dispers√£o (ou Variabilidade)

### Amplitude

- **Defini√ß√£o:** Diferen√ßa entre o maior e o menor valor.  
- **Interpreta√ß√£o:** Indica o intervalo total em que os dados variam.  
- **Como reportar:**  

> A amplitude foi de 36 bpm, com valores variando de 39 a 75 bpm.

### Vari√¢ncia

- **Defini√ß√£o:** M√©dia dos quadrados das diferen√ßas entre os valores e a m√©dia.  
- **Interpreta√ß√£o:** Mede a dispers√£o, mas sua unidade √© o quadrado da unidade original.  
- **Como reportar:**  

> A vari√¢ncia foi de 98,8 bpm¬≤, indicando a variabilidade dos batimentos em rela√ß√£o √† m√©dia.

**Observa√ß√£o:**  
A unidade da vari√¢ncia √© expressa ao quadrado da unidade original dos dados (por exemplo, bpm¬≤ no caso de batimentos por minuto), o que pode dificultar sua interpreta√ß√£o direta.  
Por isso, costuma-se utilizar o **desvio padr√£o**, que tem a **mesma unidade dos dados originais** e fornece uma no√ß√£o mais intuitiva da dispers√£o dos valores em torno da m√©dia.


### Desvio padr√£o (DP)

- **Defini√ß√£o:** Raiz quadrada da vari√¢ncia.  
- **Interpreta√ß√£o:** Expressa, em m√©dia, o quanto os dados se afastam da m√©dia.  
- **Como reportar:**  

**Como reportar:**  
O desvio padr√£o foi de 9,9 bpm, o que indica que, em m√©dia, os batimentos card√≠acos dos indiv√≠duos da amostra variam aproximadamente 9,9 unidades em rela√ß√£o √† m√©dia.

### Amplitude interquartil (IQR)

- **Defini√ß√£o:** Diferen√ßa entre o terceiro e o primeiro quartis (Q3 - Q1).  
- **Interpreta√ß√£o:** Indica a dispers√£o dos 50% centrais dos dados.  
- **Como reportar:**  

> A amplitude interquartil foi de 10,0 bpm, mostrando a concentra√ß√£o dos valores m√©dios.

**Sugest√£o de v√≠deo:** Canal Pesquise - [Variabilidade](https://youtu.be/sISPcOIcwXs)


## Medida Relativa de Variabilidade

### Coeficiente de Varia√ß√£o (CV)

- **Defini√ß√£o:** Quociente entre o desvio padr√£o e a m√©dia, multiplicado por 100.  
- **Interpreta√ß√£o:** Expressa a variabilidade dos dados em rela√ß√£o √† m√©dia, permitindo comparar conjuntos com unidades diferentes.  
- **Como reportar:**  

> O coeficiente de varia√ß√£o foi de 16,9%, indicando que os dados s√£o relativamente homog√™neos.

**Observa√ß√£o:**  
Um CV inferior a 25% geralmente indica homogeneidade; valores muito altos indicam alta variabilidade.

## Apresenta√ß√£o dos Resultados

Uma maneira eficiente de apresentar estat√≠sticas descritivas √© organizar as vari√°veis em linhas, facilitando a visualiza√ß√£o dos principais par√¢metros de cada vari√°vel estudada. Veja abaixo uma sugest√£o de tabela para esse formato:

| Vari√°vel           | n   | M√©dia ¬± DP        | Mediana (Q1; Q3)   | M√≠nimo | M√°ximo |
|--------------------|-----|-------------------|--------------------|--------|--------|
| Idade (anos)       | 98  | 24,5 ¬± 4,2        | 24,0 (21,0; 28,0)  | 18     | 35     |
| IMC (kg/m¬≤)        | 98  | 22,3 ¬± 3,1        | 21,9 (20,3; 23,7)  | 17,0   | 31,5   |
| Press√£o Sist√≥lica  | 98  | 118,5 ¬± 13,0      | 120 (110; 128)     | 90     | 145    |
| Press√£o Diast√≥lica | 98  | 76,2 ¬± 9,1        | 76 (70; 82)        | 60     | 98     |

> Reportar uma medida de tend√™ncia central (como m√©dia ou mediana) junto com uma medida de dispers√£o (como desvio padr√£o, intervalo interquartil ou amplitude) √© fundamental porque, isoladamente, a tend√™ncia central n√£o fornece informa√ß√µes suficientes sobre o conjunto de dados.


Para vari√°veis qualitativas, a tabela pode ser organizada assim:

| Vari√°vel     | Categoria         | n   | %     |
|:--------------|:-------------------|:-----|:-------|
| Sexo         | Masculino         | 52  | 53,1% |
|              | Feminino          | 46  | 46,9% |
| Tabagismo    | Sim               | 18  | 18,4% |
|              | N√£o               | 80  | 81,6% |

Essas tabelas permitem uma apresenta√ß√£o clara e objetiva das principais caracter√≠sticas da amostra analisada.

## Fun√ß√µes no R

Com um vetor `x` contendo os dados, utilize:

| Medida                     | C√≥digo R                    |
|----------------------------|-----------------------------|
| M√©dia                      | `mean(x)`                   |
| Mediana                    | `median(x)`                 |
| Primeiro quartil (Q1)      | `quantile(x, 0.25)`         |
| Terceiro quartil (Q3)      | `quantile(x, 0.75)`         |
| Moda                       | `sort(table(x))`            |
| Menor valor                | `min(x)`                    |
| Maior valor                | `max(x)`                    |
| Resumo geral               | `summary(x)`                |
| Amplitude                  | `range(x)`                  |
| Vari√¢ncia                  | `var(x)`                    |
| Desvio padr√£o              | `sd(x)`                     |
| Amplitude interquartil     | `IQR(x)`                    |
| Coeficiente de varia√ß√£o    | `sd(x)/mean(x)*100`         |


> Calcular √© importante, mas interpretar corretamente √© essencial. Ao elaborar suas interpreta√ß√µes, descreva o que os n√∫meros revelam sobre o fen√¥meno analisado.

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 4

**Considere o objeto Batimentos, que √© uma amostra de batimentos card√≠acos de 20 homens.**

```{r}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54)
```

+ Obtenha as seguintes medidas:
   + Menor valor:
   + Maior valor:
   + M√©dia:
   + Mediana:
   + Primeiro quartil:
   + Terceiro quartil:
   + Vari√¢ncia:
   + Desvio padr√£o:
   + Amplitude interquartil:
   + Coeficiente de vari√ß√£o:
   
+ Escreva sobre o conjunto media e desvio padr√£o: 

> A m√©dia dos dados foi de X (unidade), com um desvio padr√£o de Y (unidade), indicando que os valores est√£o, em geral, relativamente pr√≥ximos/espalhados em torno da m√©dia. O desvio padr√£o reflete a quantidade de variabilidade ou dispers√£o dos dados em rela√ß√£o √† m√©dia, e neste caso, a dispers√£o √© baixa/m√©dia/alta, dependendo do valor de Y.

+ Escreva sobre conjunto mediana e quartis:

> A mediana foi Z (unidade), e o intervalo interquartil (IQR), que representa a diferen√ßa entre o terceiro quartil (Q3) e o primeiro quartil (Q1), foi Q3 - Q1 (unidade). Isso indica que 50% dos dados est√£o concentrados nesse intervalo.

+ Escreva sobre o coeficiente de varia√ß√£o: 

> O coeficiente de varia√ß√£o (CV) foi calculado como X%, o que reflete a dispers√£o relativa dos dados em rela√ß√£o √† m√©dia. Valores mais baixos de CV indicam que os dados est√£o mais concentrados em torno da m√©dia, enquanto valores mais altos indicam uma maior dispers√£o.

+ Acrescente mais uma amostra com valor de batimento igual a 120, recalcule as medidas acima. Qual conjunto voc√™ consideraria mais adequado para resumir sua amostra, na presen√ßa desse valor discrepante (_outlier_)? A m√©dia (DP) ou mediana (1o.Q ; 3o.Q)? Explique.




<!--chapter:end:06-Estatistica-Descritiva.Rmd-->

# Importando banco de dados

Na pr√°tica, os dados que vamos analisar estar√£o armazenado em um **banco de dados**, um arquivo de banco de dados pode ser de diferentes tipos, por exemplo:

+ Arquivo do tipo Excel (xls ou xlsx)

+ Arquivo de texto separado por v√≠rgulas (csv - _comma-separated values_)


> Existem v√°rias fontes de dados abertas, onde podemos baixar um banco de dados para realizar analises estat√≠sticas, aqui est√£o algumas delas:

+ DataSus: <https://datasus.saude.gov.br/transferencia-de-arquivos>

+ OMS: <https://www.who.int/data/collections>

+ Kaggle: <https://www.kaggle.com/datasets>


> No link (google drive) existem alguns bancos que podemos usar para compreender como importar um banco de dados para o ambiente do RStudio: <https://drive.google.com/drive/folders/1gyORbBEuKBstfSKULA58TLhawOXaY-st>

## Importando um banco csv

1. Fa√ßa _download_ do banco de dados **mcdonald.csv** 
(fonte original: https://www.kaggle.com/datasets/mcdonalds/nutrition-facts)

2. Na √°rea de ambinete de mem√≥ria, localize **Import Dataset**, ao clicar nessa op√ß√£o voc√™ ter√° o seguinte:

<center>![<font size="2"> Figura: Importando banco de dados</font>](telaImportDataset.png){width=40%}
</center>

+ Como queremos importar um arquivo csv, a melhor op√ß√£o √© a segunda **From Text (readr)**

+ **_readr_** √© uma pacote do R que faz a leitura de arquivo csv (se o pacote ainda n√£o estiver instalado no seu computador, o R far√° a instala√ß√£o, se voc√™ concordar!)

3. Clicando na op√ß√£o **From Text (readr)**, no bot√£o **browser** indidique onde (no seu computador) est√° localizado o arquivo a ser importado. A seguinte tela ser√° apresentada:

<center>![<font size="2"> Figura: Pr√©via dos dados</font>](telaImportBrowser.png)
</center>

+ No quadro **Data Preview**, temos uma "pr√©via" com os nomes da vari√°veis, seus tipos computacionais e os primeiros valores que est√£o armazenados no banco de dados.

+ No quadro **Import Options** temos as op√ß√µes de importa√ß√£o, fique atento ao **Name** do seu banco de dados, geralmente usamos nomes sem espa√ßos ou caracteres especiais (', ~  ou √ß), √© at√© permitido usar alguns desses caracteres especiais, mas evite. 

+ Ainda no quadro **Import Options**, observe que a op√ß√£o **Open Data Viewer** est√° marcada, isso significa que ao importar o banco de dados, o arquivo de banco de dados ser√° aberto pelo RStudio. Caso esteja trabalhando com bancos com muitos dados (como os bancos do dataSUS), talvez seja melhor desmarcar essa op√ß√£o para n√£o sobrecarregar o processamento do seu computador.

+ O quadro **Code Preview** mostra como √© a importa√ß√£o (leitura) do banco de dados via c√≥digo. √â interessante copiar esse trecho de c√≥digo para o arquivo de script.

4. Clique no bot√£o **Import** e observe que no ambiente de mem√≥ria ser√° criado o objeto do tipo **Data** com o nome do banco de dados que foi importado. 

<center>![<font size="2"> Figura: Import dataset</font>](telaImportObjetoData.png){width=60%}
</center>

+ Observe que esse objeto do tipo **Data** √© diferente dos objetos do tipo **Values** que vimos nos exemplos iniciais.

+ Ao clicar no √≠cone ao lado do nome do objeto, temos acesso ao nomes e tipos computacionais das vari√°veis, e ao clicar sobre nome do objeto, o banco ser√° aberto!

## Importando um banco xls

Na √°rea de ambiente de mem√≥ria, localize **Import Dataset**, ao clicar sobre essa op√ß√£o, escolha **From Excel...**

<center>![<font size="2"> Figura: Importando banco de dados</font>](telaImportDataset.png){width=40%}
</center>

+ Se for a primeira vez que voc√™ estiver importando um arquivo Excel, pode ser necess√°ria a instala√ß√£o do pacote que fornece a biblioteca que tem a fun√ß√£o de leitura de arquivo xls (**readxl**)! O RStudio mostrar√° um aviso parecido com este: 

<center>![<font size="2"> Figura: Aviso para instala√ß√£o de pacote</font>](telaImportPacote.png){width=40%}
</center>


## Exemplo 1

Como obter a m√©dia da vari√°vel **Calories** que √© uma coluna do objeto **mcdonald**, que por sua vez, √© um objeto do tipo **Data**? 

```{r eval=FALSE, results='hide'}
# Usamos o operador $
# Para calcular a m√©dia precisamos informar para fun√ß√£o: 
# mean( NOME DO BANCO $ NOME DA COLUNA ): 
mean(mcdonald$Calories)
```

## Exemplo 2

Como armazenar os valores de uma vari√°vel (coluna), em um objeto do tipo **Values** e depois calcular a m√©dia?

```{r eval=FALSE, results='hide'}
# Uso o operador <- 
# Criamos o objeto 
caloria <- mcdonald$Calories
# Agora podemos usar o objeto que criamos, por exemplo para calcular a m√©dia e o desvio padr√£o
mean(caloria)
sd(caloria)
```

## Exemplo 3

O que acontece se usamos a fun√ß√£o **summary()** para o objeto **mcdonald**, sem usar o operador, isto √© sem indicar uma vari√°vel?
```{r eval=FALSE, results='hide'}
# No console ser√° mostrado o resumo de todas as vari√°veis do banco!
summary(mcdonald)
```

> Essa forma de obter os resultados n√£o √© a melhor forma, vamos **instalar um pacote** para obter os resultados em uma tabela bem formatada que podemos copiar e colar diretamente para um editor de texto. 

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/packages/lf20_ynsr82zq.json"  background="transparent"  speed="2"  style="width: 200px; height: 200px;"  loop  autoplay></lottie-player>
</center>

<!--chapter:end:07-Importando-BD.Rmd-->

# Instalando pacotes

Quando instalamos nosso ambiente computacional R e RStudio, instalamos uma vers√£o b√°sica, onde apenas os recursos b√°sicos do R est√£o dipon√≠veis, o pacote b√°sico (**base**) do R.

Os pacotes (**packages**) do R s√£o compostos por uma biblioteca (**library**) que √© um conjunto de fun√ß√µes. Por exemplo, do pacote **base** usamos as fun√ß√µes min(), max(), mean(), median(), table(), var(), sd(), summary(), etc.

Para ver a lista de fun√ß√µes que comp√µem a bilbioteca do pacote base, execute o c√≥digo:
```{r}
library(help = "base")
```

Os pacotes s√£o an√°logos aos aplicativos que instalamos nos nossos celulares, s√£o m√≥dulos que agregam funcionalidades espec√≠ficas. Ao longo das nossas atividades usaremos alguns desses pacotes.

Como nesse momento estamos interessados em otimizar o trabalho para realizar uma an√°lise descritiva dos dados, ent√£o vamos instalar um pacote chamado **gtsummary** (<https://www.danieldsjoberg.com/gtsummary/>).

> O pacote **gtsummary** nos fornecer√° uma tabela resumo de todo banco de dados, otimizando bastante nosso trabalho de resumir o banco de dados. 

+ IMPORTANTE 1: instalamos um pacote apenas uma vez (como um aplicativo no celular... a gente s√≥ refaz a instala√ß√£o se o app _bugar_!)

+ IMPORTANTE 2: todas vez precisamos carregar o pacote com as fun√ß√µes que queremos usar por meio da fun√ß√£o **library()**

Veja o c√≥digo:

```{r eval=FALSE}
# comando para instalar o pacote gtsummary
install.packages("gtsummary")

# comando para carregar a biblioteca de fun√ß√µes do gtsummary
library(gtsummary)

# a fun√ß√£o que vamos usar para gerar uma tabela que resume os dados √©
# tbl_summary
tbl_summary(mcdonald)
```

+ Ao executar **tbl_summary(mcdonald)** a tabela de resultados ser√° mostrada na √°rea de arquivos, gr√°ficos, pacotes... na aba **Viewer**, no quadrante abaixo do ambiente de mem√≥ria.

+ Essa tabela pode ser copiada e colada para o editor de texto que voc√™ utiliza para escrever seus trabalhos, claro essa tabela pode ser melhorada!

+ Observe no rodap√© da tabela a seguinte legenda  **n (%); Median (IQR)**, isso significa que para

    + **vari√°veis qualitativas:** n √© a contagem (frequ√™ncia absoluta) e entre parenteses (%) √© mostrado a porcentagem de cada categoria.
  
    + **variveis quantitativas:** Median √© a mediana e entre parenteses (IQR - de InterQuantile Range) est√£o o primeiro e terceiro quartil respectivamente. 

## Exemplo 1
Como mostrar o resultado com a m√©dia e desvio padr√£o?

```{r eval=FALSE}
# acrescente nos argumentos da fun√ß√£o tbl_summary() a op√ß√£o:
# statistic = list(all_continuous() ~ "{mean} ({sd})"
tbl_summary(
            mcdonald, 
            statistic = list(all_continuous() ~ "{mean} ({sd})")
            )
```

## Exemplo 2
Como selecionar somente algumas vari√°veis do banco de dados?
```{r eval=FALSE}
# Precisamos do pacote tidyverse, tire o s√≠mbolo de # se precisar instalar!
# install.packages("tidyverse")

# ative tidyverse
library(tidyverse)

# vamos usar a fun√ß√£o select() do pacote tidyverse
dadosSelecionados <- select (mcdonald, Cholesterol, Sodium, Carbohydrates)

# fa√ßa uma tabela para o objeto dadosSelecionados
tbl_summary(dadosSelecionados)
```

## Exemplo 3
Algumas vezes √© mais f√°cil excluir algumas vari√°veis, por exemplo queremos todas, menos **Item** e **Serving  Size**	
```{r eval=FALSE}
# vamos usar a fun√ß√£o select() do pacote tidyverse e colocar o sinal de menos (-)
# antes dos nomes das vari√°veis que queremos excluir
# IMPORTANTE: Serving Size √© um nome de vari√°vel com espa√ßo 
# ent√£o devemos refer√™nci√°-la entre aspas: `Serving Size`
dadosSelecionados2 <- select (mcdonald, -Item, -`Serving Size`)

# fa√ßa uma tabela para o objeto dadosSelecionados2
tbl_summary(dadosSelecionados2)
```


## Exemplo 4
Como selecinar um conjunto de vari√°veis que est√£o em sequ√™ncia, por exemplo, de **Carbohydrates** a **Cholesterol (% Daily Value)**
```{r eval=FALSE}
# vamos usar a fun√ß√£o select() do pacote tidyverse e colocar o sinal de dois pontos (:)
# entre a primeira vari√°vel e a √∫ltima da sequ√™ncia 
# IMPORTANTE: Cholesterol (% Daily Value) √© um nome de vari√°vel com espa√ßo 
# ent√£o devemos refer√™nci√°-la entre aspas: `Cholesterol (% Daily Value)`
dadosSelecionados3 <- select (mcdonald, Carbohydrates:`Cholesterol (% Daily Value)`)

# fa√ßa uma tabela para o objeto dadosSelecionados
tbl_summary(dadosSelecionados3)
```

> Saiba mais sobre o Tidyverse <https://www.tidyverse.org/packages/>

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 5

**Escolha outro banco de dados (voc√™ pode at√© criar um banco fict√≠cio!), fa√ßa uma tabela descritiva dos dados e escreva sobre os dados (um ou dois par√°grafos), afinal, o nosso trabalho n√£o √© s√≥ obter a tabela, √© dissertar sobre o que essa tabela revela sobre a amostra em estudo!**



<!--chapter:end:08-Instalando-Pacotes.Rmd-->

# Gr√°ficos

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/packages/lf20_kgyknvpj.json"  background="transparent"  speed="2"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>

Nesse link <https://r-graph-gallery.com/> est√° algumas possibilidades de gr√°ficos que podemos fazer usando o R. Para fazer gr√°ficos mais elaborados (aparentemente mais atrativos visualmente) usamos o pacote **GGPlot2** <https://ggplot2.tidyverse.org/>.

Focaremos nossa aten√ß√£o em dois gr√°ficos espec√≠ficos para vari√°veis quantitativas: **Histograma** e **Boxplot**, em nem faremos nada atrativo, usaremos o pacote b√°sico do R que nos fornece as fun√ß√µes **hist()** e **boxplot()**, pois o nosso obtivo para esse momento √© simplesmente estudar a import√¢ncia desses gr√°ficos.

O que a gente levaria um tempinho... √© simplesmente assim em c√≥digo R:

```{r eval=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)

# Para fazer o Histograma de Batimentos
hist(Batimentos)

# Para fazer o Boxplot de Batimentos
boxplot(Batimentos)
```

Na √°rea de gr√°ficos (**Plots**), abaixo do ambiente de mem√≥ria, ser√£o mostrados os gr√°ficos:

> Histograma

```{r echo=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)
hist(Batimentos)
```


> Boxplot

```{r echo=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)
boxplot(Batimentos)
```

> Observa√ß√µes

+ Os gr√°ficos mostram a informa√ß√£o batimentos de duas formas diferentes, mas elas est√£o relacionadas!

+ Observe que eixo horizontal do histograma corresponde ao eixo vertical do boxplot

## Histograma

O histograma √© um gr√°fico que usado para vari√°veis quantitativas cont√≠nua.

O histograma pode nos dar uma no√ß√£o do tipo de **distribui√ß√£o de probabibilidade** que os dados seguem.

A ideia desse gr√°fico √© agrupar os dados em  **classes** (cada barra do histograma √© uma classe) e no eixo vertical tem-se a contagem (frequ√™ncia) de quantos valores foram alocados em cada classe.

Para fazer a **leitura do histograma**:

  + Identifique as classes no "eixo x" 
  
  + Identifique quantos elementos tem em cada classe no "eixo y"
 
Acredito que nesse exemplo, √© f√°cil verificar:

  + A segunda classe: 40 - 50 batimentos, que tem 1 elemento (verifique no objeto Batimentos)
  
  + A terceira classe: 50 - 60 batimentos, que tem 6 elementos  
  
  + Ent√£o, a **aplitude das classes** √© igual a 10. Logo, a primeira classe √© de 30 - 40. 
  
  + As classes 80 - 90; 90 - 100 e 100 - 110 n√£o tiveram ocorr√™ncias!
  
  + A classe 110-120 possui 1 elemento, que √© aquele valor discrepante em rela√ß√£o aos demais valores.


Se n√£o for f√°cil identificar as classes (eixo x) voc√™ pode usar o comando abaixo: 

```{r eval=FALSE}
# Para obter as "quebras" de cada classe 
hist(Batimentos)$breaks
```

Se n√£o for f√°cil identificar as frequencias (eixo y) voc√™ pode usar o comando abaixo:  
```{r eval=FALSE}
# Para obter a frequ√™ncia em cada classe
hist(Batimentos)$count
```

De fato, o que estamos lendo por meio do histograma √© o que chamamos de **tabela de frequ√™ncia**: 

|   Classe  | Frequ√™ncia |
|:---------:|:----------:|
|  30 - 40  |      3     |
|  40 - 50  |      1     |
|  50 - 60  |      6     |
|  60 - 70  |      7     |
|  70 - 80  |      3     |
|  80 - 90  |      0     |
|  90 - 100 |      0     |
| 100 - 110 |      0     |
| 110 - 120 |      1     |
|$\sum n$  |     21     |

  + Por meio do histograma ou da tabela podemos concluir que a classe modal (moda) √© a classe de 60 - 70 batimentos;
  
  + A frequ√™ncia foi apresentada em termos absolutos mais pode ser transformada em frequ√™ncia percentual.
  
  + Quando estamos aprendendo a fazer um histograma manualmente, primeiro constru√≠mos essa tabela de frenqu√™ncia, e para constru√≠-la √© necess√°rio calcular o n√∫mero √≥timo de classes, umas das regras mais usada √© a Regra Sturges (essa √© op√ß√£o padr√£o do R).

Podemos usar o pacote b√°sico R para melhorar a apar√™ncia desse gr√°fico.
```{r}
hisBat <- hist(Batimentos,
               main = "Histograma",
               xlab = "Batimentos card√≠acos",
               sub = "por classes",
               ylab = "Frequ√™ncia absoluta",
               xlim = c(20, 120),
               ylim = c(0, 8),
               col = "lightgreen")
text(hisBat$mids, hisBat$counts, labels=hisBat$counts, adj = c(0.5,-0.5))

# adicionar linha para indicar a m√©dia
abline(v = mean(Batimentos),                      
       col = "red",
       lwd = 3)
```

## Boxplot

Boxplot ou diagrama de caixa, √© um gr√°fico que mostra as medidas: menor valor, primeiro quartil, mediana, terceiro quartil e m√°ximo valor.

+ Valores discrepantes (_outliers_) s√£o detectados pelo boxplot. Veja a figura:

<center>![<font size="2">Figura: "Anatomia de um boxplot"</font>](Boxplotexemplo.png){width=50%}
</center>

Essa figura foi retirada do site da Prof. Fernanda https://fernandafperes.com.br/blog/interpretacao-boxplot/ (uma exelente refer√™ncia para estudar estat√≠stica!)

> Geralmente eles s√£o representados na vertical, mas tamb√©m √© comum a representa√ß√£o na horizontal.

```{r eval=FALSE}
# Para fazer o Boxplot de Batimentos na horizontal
boxplot(Batimentos, horizontal = TRUE)
```

> √â uma forma de comparar dois grupos em rela√ß√£o a uma medida, por exemplo os batimentos cardiacos de grupo de homens e de mulheres
```{r}
# Gera√ß√£o de amostras simuladas
set.seed(1)
BatimentosMulheres <- rnorm(30, 70, 3)
BatimentosHomens <- rnorm(30, 75, 8)
# Boxplot para os dois grupos Homens e Mulheres 
boxplot(BatimentosHomens, BatimentosMulheres)
```


> O boxplot tamb√©m pode nos informar se uma distribui√ß√£o de probabilidade √© sim√©trica ou n√£o. Analise os gr√°ficos abaixo, veja a conex√£o entre histograma e boxplot.

```{r echo=FALSE}
set.seed(1000)
simetrica <- rnorm(1000, 40, 5)
hist(simetrica,
     main="Distribui√ß√£o SIM√âTRICA",
     xlab = "",
     ylab="")
```



```{r echo=FALSE}
set.seed(1000)
assimetrica <- 20 + 10*rexp(1000, 5)
hist(assimetrica,
     main="Distribui√ß√£o ASSIM√âTRICA",
     xlab = "",
     ylab="")
abline(v = mean(assimetrica),                      
       col = "red",
       lwd = 3)
boxplot(assimetrica, horizontal = T)
summary(assimetrica)
```

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 6

**Para o banco de dados escolhido na atividade 5, fa√ßa gr√°ficos como o histograma e boxplot, al√©m disso, pesquise outras formas de fazer gr√°ficos no R.**

# Pacote `ggplot` 

O `ggplot2` √© um dos pacotes mais populares do R para a cria√ß√£o de gr√°ficos estat√≠sticos sofisticados e visualmente atraentes. Baseado no conceito da "Gram√°tica dos Gr√°ficos", o `ggplot2` permite construir gr√°ficos de maneira flex√≠vel e modular, combinando camadas (layers) de dados, geometrias, escalas e temas.

## Principais Vantagens

- Produz gr√°ficos de alta qualidade e personaliz√°veis.
- Permite adicionar camadas de informa√ß√£o facilmente.
- Suporta uma variedade de tipos de gr√°ficos.


## Exemplos de Gr√°ficos Simples e Bonitos com ggplot2

Antes de come√ßar, certifique-se de instalar e carregar o pacote:

```r
install.packages("ggplot2")
library(ggplot2)
```

Para ilustrar alguns gr√°ficos utilizando o `ggplot2`, empregaremos o conjunto de dados *iris*, que j√° est√° dispon√≠vel nativamente no R.

O *iris* √© um dos bancos de dados mais cl√°ssicos e utilizados em estat√≠stica e aprendizado de m√°quina, trazendo informa√ß√µes sobre 150 flores de tr√™s esp√©cies diferentes, com quatro vari√°veis quantitativas (comprimento e largura das s√©palas e p√©talas). Ele √© amplamente utilizado para exemplos de an√°lise explorat√≥ria de dados, classifica√ß√£o e visualiza√ß√£o de padr√µes.

Al√©m do iris, o R oferece outros conjuntos de dados nativos bastante √∫teis para exerc√≠cios e demonstra√ß√µes em diversas √°reas, como *mtcars* (carros), *ToothGrowth* (crescimento de dentes em cobaias), *sleep* (efeito de medicamentos no sono), *airquality* (qualidade do ar em Nova Iorque) e *CO2* (absor√ß√£o de CO2 em plantas).

### Gr√°fico de Dispers√£o (Scatterplot)

```{r, ggplotIris, message=FALSE, warning=FALSE}
library(ggplot2)
# Exemplo com o dataset iris
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  geom_point(size = 3, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Gr√°fico de Dispers√£o: iris",
       x = "Comprimento da S√©pala",
       y = "Largura da S√©pala")
```

### Gr√°fico de Barras

```{r, ggbarIris}
# Contagem das esp√©cies no dataset iris
ggplot(iris, aes(x = Species, fill = Species)) +
  geom_bar() +
  theme_classic() +
  labs(title = "Gr√°fico de Barras: Contagem de Esp√©cies",
       x = "Esp√©cie",
       y = "Contagem")
```

### Histograma

```{r, gghistIris}
# Distribui√ß√£o do comprimento da s√©pala
ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_histogram(binwidth = 0.3, color = "white", alpha = 0.7, position = "identity") +
  theme_light() +
  labs(title = "Histograma: Comprimento da S√©pala",
       x = "Comprimento da S√©pala",
       y = "Frequ√™ncia")
```

### Boxplot

```{r, ggboxplotIris}
# Distribui√ß√£o do comprimento da p√©tala por esp√©cie
ggplot(iris, aes(x = Species, y = Petal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  theme_bw() +
  labs(title = "Boxplot: Comprimento da P√©tala por Esp√©cie",
       x = "Esp√©cie",
       y = "Comprimento da P√©tala")
```


O `ggplot2` oferece diversas op√ß√µes de personaliza√ß√£o, como cores, temas e anota√ß√µes, permitindo criar gr√°ficos bonitos e informativos para diferentes finalidades.


## Exemplos de Bancos de Dados do R

| Banco de Dados    | Pacote      | √Årea/Descri√ß√£o                                               |
|:-------------------|:-------------|:--------------------------------------------------------------|
| iris              | datasets    | Bot√¢nica, estat√≠stica, aprendizado de m√°quina (flores)       |
| mtcars            | datasets    | Autom√≥veis, regress√£o, an√°lise multivariada                  |
| airquality        | datasets    | Qualidade do ar, sa√∫de ambiental                             |
| ToothGrowth       | datasets    | Farmacologia, sa√∫de, crescimento de dentes                   |
| sleep             | datasets    | Psicologia, farmacologia, estudo do sono                     |
| ChickWeight       | datasets    | Nutri√ß√£o, crescimento animal                                 |
| USArrests         | datasets    | Sociologia, estat√≠sticas criminais dos EUA                   |
| CO2               | datasets    | Biologia, fisiologia vegetal                                 |
| BOD               | datasets    | Biologia, demanda bioqu√≠mica de oxig√™nio                     |
| Boston            | MASS        | Imobili√°rio, regress√£o, an√°lise multivariada                 |
| lung              | survival    | Medicina, an√°lise de sobreviv√™ncia (dados de c√¢ncer de pulm√£o)|
| bfi               | psych       | Psicologia, personalidade (Big Five Inventory)               |
| NHANES            | NHANES      | Sa√∫de p√∫blica, epidemiologia (pesquisa nacional dos EUA)     |
| titanic           | titanic     | Sobreviv√™ncia, estat√≠stica, aprendizado de m√°quina           |
| worldcup          | faraway     | Esportes (Copa do Mundo de Futebol)                          |

**Nota:**  
Os bancos do pacote `datasets` j√° v√™m instalados por padr√£o no R. Outros, como `MASS`, `psych`, `NHANES`, `survival`, `titanic` e `faraway`, podem ser instalados via `install.packages("nome_do_pacote")`.  
Verifique sempre a documenta√ß√£o do pacote para acessar o nome correto dos bancos de dados e exemplos de uso.

<!--chapter:end:09-Graficos.Rmd-->

# Distribui√ß√£o de Probabilidade

Uma distribui√ß√£o de probabilidade √© um modelo matem√°tico que descreve a rela√ß√£o entre os valores poss√≠veis de uma vari√°vel e as probabilidades de ocorr√™ncia desses valores. Essencialmente, ela nos permite prever a probabilidade de eventos com base em um conjunto de dados.

Entre as distribui√ß√µes mais comuns, destacam-se:

- Distribui√ß√£o Normal (ou Gaussiana)
- Distribui√ß√£o Binomial
- Distribui√ß√£o Poisson
- Distribui√ß√£o Exponencial
- Distribui√ß√£o Uniforme
- Distribui√ß√£o Qui-quadrado
- Distribui√ß√£o t-Student
- Distribui√ß√£o Gama, entre outras.

Cada tipo de distribui√ß√£o possui caracter√≠sticas pr√≥prias e √© aplicada em diferentes contextos. A distribui√ß√£o normal √© uma das mais amplamente utilizadas, especialmente para modelar fen√¥menos naturais e sociais, como a altura de indiv√≠duos ou o tempo de vida de produtos.

> **Propriedades Gerais das Distribui√ß√µes de Probabilidade**

- **√Årea total sob a curva √© igual a 1:** Isso significa que a soma de todas as probabilidades poss√≠veis de ocorr√™ncia dos eventos √© igual a 100%.
- **A √°rea sob a curva representa a probabilidade de um evento.** Por exemplo, a probabilidade de um evento ocorrer entre dois valores quaisquer pode ser calculada pela √°rea sob a curva entre esses dois pontos.

## Distribui√ß√£o Normal

A distribui√ß√£o normal √© uma das mais conhecidas na estat√≠stica. Ela modela fen√¥menos que seguem um comportamento sim√©trico em torno de uma m√©dia. A distribui√ß√£o normal tem v√°rias aplica√ß√µes, desde a an√°lise de medidas biol√≥gicas (como a press√£o arterial) at√© a previs√£o de fen√¥menos econ√¥micos (como o pre√ßo das a√ß√µes).

> **A distribui√ß√£o normal √© definida por dois par√¢metros principais:**

- **M√©dia (Œº):** Representa o valor central da distribui√ß√£o.
- **Desvio Padr√£o (œÉ):** Mede a dispers√£o dos dados em rela√ß√£o √† m√©dia.

> **Caracter√≠sticas da Distribui√ß√£o Normal**

- **Forma de sino:** A distribui√ß√£o normal tem a forma de um sino sim√©trico, com a maior concentra√ß√£o de dados perto da m√©dia.
- **Simetria:** A distribui√ß√£o √© sim√©trica em rela√ß√£o √† m√©dia.
- **M√©dia, Mediana e Moda:** Para uma distribui√ß√£o normal, a m√©dia, mediana e moda s√£o "iguais" e localizam-se no centro da distribui√ß√£o.

> **Teoricamente o comportamento da Distribui√ß√£o Normal √© dado por:**

<center>

![<font size="2">Figura: Distribui√ß√£o Normal te√≥rica (Fonte: <https://www.inf.ufsc.br/~andre.zibetti/probabilidade/figures/normal.PNG>)</font>](normalTeorica.png){width="80%"}

</center>

Onde:

-   A m√©dia est√° representada por $\mu$
-   O devio padr√£o est√° representado por $\sigma$

> **Regra empirica 68% - 95% - 99,7%**
Se os dados seguem uma distribui√ß√£o normal, √© poss√≠vel fazer afirma√ß√µes sobre a concentra√ß√£o dos dados em torno da m√©dia, conforme a regra emp√≠rica:

- *68%* dos dados est√£o no intervalo de uma vez o desvio padr√£o (Œº ¬± 1œÉ).
- *95%* dos dados est√£o no intervalo de duas vezes o desvio padr√£o (Œº ¬± 2œÉ).
- *99,7%* dos dados est√£o no intervalo de tr√™s vezes o desvio padr√£o (Œº ¬± 3œÉ).

**Importante:** Dados fora do intervalo de Œº ¬± 3œÉ s√£o considerados raros.

> Exemplo de distribui√ß√£o Normal, com dados simulados usado a fun√ß√£o rnorm().

```{r}

# semente de gera√ß√£o de n√∫meros aleat√≥rios 
set.seed(1)

# Ser√° simulada uma amostra com a seguinte caracter√≠stica:
# 1000 valores
# m√©dia ~ 70
# desvio padr√£o ~ 3
# A fun√ß√£o rnorm() gera n√∫meros rand√¥micos com comportamento de uma distribui√ß√£o Normal 
BatimentosMulheres <- rnorm(1000, 70, 3)

# Arrendodamento com nenhuma casa depois da v√≠rugula
BatimentosMulheres <- round(BatimentosMulheres,0)

# histograma
hist(BatimentosMulheres)

# Classes e frequencias do histograma
hist(BatimentosMulheres)$breaks
hist(BatimentosMulheres)$count

# histograma e curva de densidade (da Dist. Normal)
hist(BatimentosMulheres, prob = TRUE)
lines(density(BatimentosMulheres), col = 4, lwd = 2)

# idica√ß√£o da m√©dia
abline(v = mean(BatimentosMulheres), col = 2, lwd = 3)

# medidas resumo
summary(BatimentosMulheres)
sort(table(BatimentosMulheres), decreasing = T)
sd(BatimentosMulheres)

# CV em %
sd(BatimentosMulheres)/mean(BatimentosMulheres)*100
```

> As fun√ß√µes **pnorm()** e **dnorm()** s√£o usadas para calcular a probabilidade de um evento que segue uma distribui√ß√£o, a qual conhecemos a m√©dia e o desvio padr√£o.

**Exemplo:** Sabendo que os batimentos card√≠acos de mulheres de 18 a 65 anos tem m√©dia de 70bmp e desvio padr√£o igual a 3bmp.

Calcule as probabilidades:

-   de uma mulher ter batimentos inferior a 70bmp, ou seja, $P(x<70)$:

```{r}
# pnorm(): Calcula a probabilidade acumulada at√© um valor espec√≠fico. Ou seja, retorna a probabilidade de que uma vari√°vel aleat√≥ria, que segue uma distribui√ß√£o normal, seja menor ou igual a um determinado valor.

# observa√ß√£o: a resposta √© 0.5 pois a m√©dia 70.
pnorm(70, 70, 3)
```

-   de uma mulher ter batimentos superior a 70bmp, ou seja, $P(x>70)$:

```{r}
# observa√ß√£o: 1 √© o valor da √°rea total
# a pnorm() fornece a √°rea √° esquerda
1 - pnorm(70, 70, 3)
```

-   de uma mulher ter batimentos igual a 70bmp, ou seja, $P(x=70)$:

```{r}
# dnorm(): Calcula a densidade de probabilidade de um valor espec√≠fico em uma distribui√ß√£o normal. Em outras palavras, ela retorna o valor da fun√ß√£o densidade de probabilidade no ponto especificado.
dnorm(70, 70, 3)
```

-   de uma mulher ter batimentos entre 67 e 73bmp $P(67 < x < 73)$:

```{r}
# Observe que estamos testando a regra emp√≠rica (68%)
pnorm(73, 70, 3) - pnorm(67, 70, 3)
```

-   de uma mulher ter batimentos entre 67 e 73bmp $P(64 < x < 76)$:

```{r}
# Observe que estamos testando a regra emp√≠rica (95%)
pnorm(76, 70, 3) - pnorm(64, 70, 3)
```

-   de uma mulher ter batimentos entre 61 e 79bmp $P(61 < x < 79)$:

```{r}
# Observe que estamos testando a regra emp√≠rica (99,7%)
pnorm(79, 70, 3) - pnorm(61, 70, 3)
```

-   de uma mulher ter batimentos maior que 90bmp $P(x > 90)$:

```{r}
# Um evento raro
1 - pnorm(90, 70, 3)
```

-   de uma mulher ter batimentos menor que 65bmp $P(x < 65)$:

```{r}
pnorm(65, 70, 3)
```

## Gr√°fico QQ

Uma maneira comum de verificar a normalidade de uma distribui√ß√£o √© utilizando o gr√°fico QQ. Ele compara os quantis de uma amostra com os quantis de uma distribui√ß√£o normal padr√£o, e √© muito √∫til para identificar se os dados seguem uma distribui√ß√£o normal.

> **Distribui√ß√£o Normal Padr√£o**

A distribui√ß√£o normal padr√£o tem duas caracter√≠sticas importantes:

- M√©dia (Œº) igual a 0
- Desvio padr√£o (œÉ) igual a 1


> **C√°lculo do Escore Z**

Qualquer distribui√ß√£o normal pode ser transformada na distribui√ß√£o normal padr√£o utilizando o escore Z. O **escore Z** √© calculado pela f√≥rmula:

\[
z = \frac{(x - \mu)}{\sigma}
\]

Onde:

- \(x\) √© o valor da observa√ß√£o.
- \(\mu\) √© a m√©dia da distribui√ß√£o.
- \(\sigma\) √© o desvio padr√£o da distribui√ß√£o.

O gr√°fico QQ realiza exatamente o que a f√≥rmula do escore Z descreve: ele transforma os dados da amostra para a distribui√ß√£o normal padr√£o (m√©dia 0 e desvio padr√£o 1) e ent√£o compara esses valores transformados com os quantis da distribui√ß√£o normal te√≥rica. Se os pontos formarem uma linha reta, isso sugere que os dados seguem uma distribui√ß√£o normal.

Veja um exemplo no R para uma Distribui√ß√£o Normal Padr√£o: 

```{r}
set.seed(1)
# rnorm(10000, 0, 1): normal padr√£o m√©dia 0, dp=1
# ou simplesmente rnorm(10000)
NormalPadrao <- rnorm(10000)
hist(NormalPadrao, probability = T)
lines(density(NormalPadrao), col = 4, lwd = 2)
axis(side = 1, at = seq(-3, 3, by = 1), labels = seq(-3, 3, by = 1))
abline(v = mean(NormalPadrao), col = 2, lwd = 3)
```

No gr√°fico QQ, os quantis da amostra s√£o comparados com os quantis da distribui√ß√£o normal padr√£o. Se a amostra segue uma distribui√ß√£o normal, os pontos no gr√°fico QQ devem se alinhar aproximadamente a uma linha reta.

Se os pontos se afastam dessa linha reta de forma sistem√°tica, isso indica que os dados n√£o seguem uma distribui√ß√£o normal. O tipo de desvio pode dar pistas sobre a natureza dessa n√£o-normalidade (por exemplo, se os pontos se curvam para cima ou para baixo, pode indicar assimetria ou caudas pesadas).


> Distrbui√ß√£o normal √© usada para dados cont√≠nuos!

```{r}
# Gr√°fico QQ
set.seed(1)
BatimentosMulheres <- rnorm(1000, 70, 3)
qqnorm(BatimentosMulheres)
qqline(BatimentosMulheres, col="red")

# Fa√ßa o arredondamento
BatimentosMulheresR <- round(BatimentosMulheres,0)
qqnorm(BatimentosMulheresR)
qqline(BatimentosMulheresR)
```

> A distribui√ß√£o Normal √© uma distribui√ß√£o para modelar vari√°veis **CONT√çNUAS**!

## Atividade 7

**Utilizando o banco de dados escolhido para as atividades 5 e 6, gere gr√°ficos QQ para as vari√°veis quantitativas. Em seguida, avalie visualmente se essas vari√°veis seguem uma distribui√ß√£o normal.**

<!--chapter:end:10-DistribuicaoNormal.Rmd-->

# Exemplos de distribui√ß√µes

```{r setupDist, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
```
<center>
<script src="https://unpkg.com/@dotlottie/player-component@2.7.12/dist/dotlottie-player.mjs" type="module"></script>
<dotlottie-player src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" background="transparent" speed="1" style="width: 300px; height: 300px" loop autoplay></dotlottie-player>
</center>

## Distribui√ß√µes Discretas

### Binomial

Modela o n√∫mero de sucessos em n tentativas com probabilidade `p`.

```{r binomialDist}
n <- 10
p <- 0.5
x <- 0:n
y <- dbinom(x, size = n, prob = p)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Distribui√ß√£o Binomial (n = 10, p = 0.5)", x = "N√∫mero de Sucessos", y = "Probabilidade")
```

### Poisson

Modela o n√∫mero de eventos raros num intervalo fixo.

```{r poissonDist}
lambda <- 3
x <- 0:15
y <- dpois(x, lambda)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "darkorange") +
  labs(title = "Distribui√ß√£o de Poisson", x = "N√∫mero de Eventos", y = "Probabilidade")
```

### Geom√©trica

Modela o n√∫mero de falhas antes do primeiro sucesso.

```{r geometricaDist}
p <- 0.3
x <- 0:10
y <- dgeom(x, prob = p)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "purple") +
  labs(title = "Distribui√ß√£o Geom√©trica (p = 0.3)", x = "Tentativas at√© o 1¬∫ Sucesso", y = "Probabilidade")
```

## Distribui√ß√µes Cont√≠nuas

### Normal

Modela fen√¥menos naturais e erros de medida.

```{r normal_plot_Dist}
x <- seq(-4, 4, length.out = 100)
y <- dnorm(x)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "darkgreen", linewidth = 1.2) +
  labs(title = "Distribui√ß√£o Normal (m√©dia = 0, sd = 1)", x = "x", y = "Densidade")
```

### Exponencial

Tempo at√© um evento ocorrer.

```{r exponencialDist}
lambda <- 1
x <- seq(0, 5, length.out = 100)
y <- dexp(x, rate = lambda)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "firebrick", size = 1.2) +
  labs(title = "Distribui√ß√£o Exponencial", x = "Tempo", y = "Densidade")
```

### Uniforme Cont√≠nua

Todos os valores t√™m a mesma chance.

```{r uniformeDist}
x <- seq(0, 1, length.out = 100)
y <- dunif(x, min = 0, max = 1)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "goldenrod", size = 1.2) +
  labs(title = "Distribui√ß√£o Uniforme Cont√≠nua (0 a 1)", x = "x", y = "Densidade")
```

### t de Student

Usada em testes com amostras pequenas.

```{r studentDist}
x <- seq(-4, 4, length.out = 100)
y <- dt(x, df = 5)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "navy", size = 1.2) +
  labs(title = "Distribui√ß√£o t de Student (df = 5)", x = "x", y = "Densidade")
```

### Qui-Quadrado (œá¬≤)

Usada para testes de ader√™ncia e independ√™ncia.

```{r chisqDist}
x <- seq(0, 20, length.out = 100)
y <- dchisq(x, df = 5)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "tomato", size = 1.2) +
  labs(title = "Distribui√ß√£o Qui-quadrado (df = 5)", x = "x", y = "Densidade")
```

### F de Fisher

Usada em ANOVA para comparar vari√¢ncias.

```{r fisherDist}
x <- seq(0, 5, length.out = 100)
y <- df(x, df1 = 5, df2 = 10)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "darkviolet", size = 1.2) +
  labs(title = "Distribui√ß√£o F de Fisher (df1 = 5, df2 = 10)", x = "x", y = "Densidade")
```

> Cada distribui√ß√£o tem uma aplica√ß√£o espec√≠fica conforme o tipo de vari√°vel (discreta ou cont√≠nua), o contexto do problema e as suposi√ß√µes do modelo. Entender suas formas e usos ajuda na escolha correta da an√°lise estat√≠stica.

<!--chapter:end:11-Distribuicoes-Probabilidade.Rmd-->

# Normal ou N√£o?

<center>
<script src="https://unpkg.com/@dotlottie/player-component@2.7.12/dist/dotlottie-player.mjs" type="module"></script>
<dotlottie-player src="https://lottie.host/32368ff6-8150-40df-a981-abe61d0c919f/Uobp2rITzh.lottie" background="transparent" speed="1" style="width: 300px; height: 300px" loop autoplay></dotlottie-player>
</center>

Antes de avan√ßarmos para a aplica√ß√£o dos testes estat√≠sticos, √© importante avaliarmos se os dados seguem ou n√£o uma distribui√ß√£o normal. Essa verifica√ß√£o inicial √© muito importante porque muitos testes param√©tricos, como o teste t e a ANOVA, partem da suposi√ß√£o de normalidade dos dados. Compreender esse aspecto permite escolher os m√©todos estat√≠sticos mais adequados, aumentando a confiabilidade dos resultados e evitando interpreta√ß√µes equivocadas que poderiam comprometer a an√°lise.

Esta se√ß√£o apresenta uma an√°lise visual da normalidade dos dados por meio de gr√°ficos QQ (Quantil-Quantil), com a compara√ß√£o de tr√™s cen√°rios distintos: dados que seguem uma distribui√ß√£o normal, dados que levantam d√∫vidas quanto √† normalidade e dados que claramente n√£o seguem essa distribui√ß√£o.

- Dados normalmente distribu√≠dos
- Dados que geram d√∫vida quanto √† normalidade
- Dados que claramente n√£o seguem distribui√ß√£o normal

## Dados que seguem distribui√ß√£o normal

```{r enormalDist}
set.seed(10)
dados_normais <- rnorm(500, mean = 0, sd = 1)

hist(dados_normais, main = "Histograma - Distribui√ß√£o Normal", col = "lightblue")
boxplot(dados_normais, main = "Boxplot - Distribui√ß√£o Normal")
qqnorm(dados_normais, main = "QQ Plot - Distribui√ß√£o Normal")
qqline(dados_normais, col = "blue", lwd = 2)
```

*Observa√ß√£o:* Os pontos seguem de perto a linha, indicando que os dados s√£o normalmente distribu√≠dos.

## Dados que geram d√∫vida

```{r duvidosaDist}
set.seed(20)
dados_mistos <- c(rnorm(250, 0, 1), rnorm(250, 2, 1))

hist(dados_mistos, main = "Histograma - Mistura de Normais", col = "lightgreen")
boxplot(dados_mistos, main = "Boxplot - Mistura de Normais")
qqnorm(dados_mistos, main = "QQ Plot - Mistura de Normais")
qqline(dados_mistos, col = "orange", lwd = 2)
```

*Observa√ß√£o:* As caudas do gr√°fico QQ come√ßam a se afastar da linha, o que pode gerar d√∫vida sobre a normalidade.


## Dados que n√£o seguem distribui√ß√£o normal

```{r nnormalDist}
set.seed(30)
dados_chi <- rchisq(500, df = 3)

hist(dados_chi, main = "Histograma - Distribui√ß√£o Qui-quadrado", col = "lightpink")
boxplot(dados_chi, main = "Boxplot - Qui-quadrado")
qqnorm(dados_chi, main = "QQ Plot - Qui-quadrado")
qqline(dados_chi, col = "red", lwd = 2)
```

*Observa√ß√£o:* A forte curvatura do gr√°fico QQ indica clara viola√ß√£o da normalidade (assimetria √† direita).

## Dados com forte concentra√ß√£o de repeti√ß√£o de valor (n√£o seguem distribui√ß√£o normal)

```{r dados_repetidos_dist}
set.seed(42)
dados_repetidos <- c(rep(18, 5), rep(23, 10), rep(26,7)) 

# Histograma
hist(dados_repetidos, main = "Histograma - Dados Repetidos", col = "lightblue", xlab = "Valor", ylab = "Frequ√™ncia")

# Boxplot
boxplot(dados_repetidos, main = "Boxplot - Dados Repetidos", col = "lightgreen")

# QQ Plot
qqnorm(dados_repetidos, main = "QQ Plot - Dados Repetidos")
qqline(dados_repetidos, col = "red", lwd = 2)
```

> O gr√°fico QQ √© uma ferramenta visual poderosa para avaliar se um conjunto de dados segue uma distribui√ß√£o normal. Em conjunto com histogramas e boxplots, permite identificar desvios, outliers e assimetrias de maneira clara.

<!--chapter:end:12-diagnostico-normalidade.Rmd-->

# Estat√≠stica Inferencial

A **estat√≠stica inferencial** √© uma √°rea essencial da estat√≠stica que permite fazer generaliza√ß√µes sobre uma popula√ß√£o com base em dados coletados de uma amostra. Um passo fundamental nesse processo √© o **c√°lculo amostral**, que determina o tamanho ideal da amostra para garantir a validade dos resultados, e esse c√°lculo depende diretamente do **tipo de teste estat√≠stico** que ser√° utilizado, pois diferentes testes exigem diferentes par√¢metros, como variabilidade, efeito esperado e poder do teste. 

Ao conduzir uma an√°lise inferencial, formulam-se **hip√≥teses**: a **hip√≥tese nula (H‚ÇÄ)**, que representa a aus√™ncia de efeito ou diferen√ßa, e a **hip√≥tese alternativa (H‚ÇÅ)**, que sugere a exist√™ncia de um efeito ou diferen√ßa. Define-se tamb√©m um **n√≠vel de signific√¢ncia (Œ±)**, geralmente 0,05 (5%), que representa a probabilidade de rejeitar H‚ÇÄ quando ela √© verdadeira (**erro tipo I**). O **valor-p**, calculado a partir dos dados, indica a probabilidade de obter um resultado t√£o extremo quanto o observado, supondo que H‚ÇÄ seja verdadeira. Com base na compara√ß√£o entre o valor-p e o n√≠vel de signific√¢ncia, aplica-se o **crit√©rio de decis√£o**: se o valor-p for menor que Œ±, rejeita-se H‚ÇÄ, o que indica **evid√™ncias estat√≠sticas suficientes para apoiar a hip√≥tese alternativa**.


## Etapas de um Teste Estat√≠stico

Para realizar qualquer **teste estat√≠stico**, seguimos uma sequ√™ncia b√°sica de passos:

1. **Escrevemos as hip√≥teses do teste**, come√ßando com a **hip√≥tese nula (H‚ÇÄ)**, que geralmente afirma que n√£o h√° efeito ou diferen√ßa, e a **hip√≥tese alternativa (H‚ÇÅ)**, que prop√µe o contr√°rio.

2. **Definimos o n√≠vel de signific√¢ncia (Œ±)**, que √© a margem de erro aceit√°vel. Esse valor, geralmente 0,05 (ou 5%), j√° foi considerado no **c√°lculo do tamanho da amostra**, garantindo que os resultados tenham confiabilidade.

3. **Utilizamos um recurso computacional**, como um software estat√≠stico, para calcular o **valor-p**, que mostra a probabilidade de observarmos os dados coletados caso a hip√≥tese nula seja verdadeira.

5. **Comparamos o valor-p com o n√≠vel de signific√¢ncia**. Se o valor-p for menor que Œ±, **rejeitamos a hip√≥tese nula**. Caso contr√°rio, n√£o rejeitamos.

6. Por fim, **chegamos √† conclus√£o do teste**, que nos diz se h√° ou n√£o **evid√™ncia estat√≠stica** suficiente para apoiar a hip√≥tese alternativa.




## Erros Tipo I e Tipo II

Em um **teste estat√≠stico**, tomamos uma decis√£o com base nos dados coletados de uma amostra: **rejeitar** ou **n√£o rejeitar a hip√≥tese nula (H‚ÇÄ)**. Por isso, √© fundamental realizar um **c√°lculo amostral adequado**, selecionar cuidadosamente a **t√©cnica de amostragem** e estar atento √†s poss√≠veis **fontes de vieses**, garantindo que a amostra seja representativa e que os resultados do teste sejam confi√°veis.

Entretanto, essa decis√£o envolve **riscos de erro**, que s√£o inerentes ao processo justamente porque estamos baseando nossas conclus√µes em uma amostra e n√£o na popula√ß√£o inteira. Esses erros se dividem em dois tipos:

- **Erro Tipo I (Œ±) ‚Äì Falso Positivo**  
  Ocorre quando **rejeitamos H‚ÇÄ mesmo ela sendo verdadeira**.  
  √â como afirmar que existe um efeito quando, na verdade, n√£o existe.  
 
  > Exemplo na medicina: concluir que um novo medicamento reduz a press√£o arterial quando ele n√£o tem efeito real, o que pode levar √† aprova√ß√£o de um tratamento ineficaz.  
  
  > Exemplo no esporte: afirmar que um programa de treinamento melhora o desempenho dos atletas quando ele n√£o traz benef√≠cio real, gerando investimentos desnecess√°rios.  
  
  > Exemplo na psicologia: dizer que uma terapia cognitivo-comportamental reduz a ansiedade, mesmo sem efeito comprovado, gerando falsas expectativas nos pacientes.  
 
  Essa √© a chance de um **falso positivo**, e o **n√≠vel de signific√¢ncia Œ±** (geralmente 0,05) representa a probabilidade de cometer esse erro.

- **Erro Tipo II (Œ≤) ‚Äì Falso Negativo**  
  Ocorre quando **n√£o rejeitamos H‚ÇÄ mesmo ela sendo falsa**.  
  √â como deixar passar um efeito real sem detect√°-lo.  
  
  > Exemplo na medicina: n√£o identificar que o medicamento √© eficaz, rejeitando seu uso quando ele realmente funciona.  
  
  > Exemplo no esporte: n√£o perceber a melhora no desempenho causada pelo programa de treinamento, deixando de adot√°-lo e prejudicando os atletas.  
  
  > Exemplo na psicologia: n√£o detectar que a terapia √© eficaz para reduzir a ansiedade, levando √† rejei√ß√£o de um tratamento que poderia beneficiar os pacientes.  
  
  Isso √© um **falso negativo**, e **Œ≤** √© a probabilidade de cometer esse erro.

## Poder do Teste Estat√≠stico

- O **poder do teste** √© a probabilidade de **detectar um efeito real quando ele realmente existe**, ou seja, **rejeitar H‚ÇÄ quando H‚ÇÄ √© falsa**.  
- O poder √© calculado como:  
  **Poder = 1 - Œ≤**

Um teste com **alto poder** (geralmente desejado acima de 80%) tem menos chance de cometer erro tipo II, o que significa maior capacidade de detectar diferen√ßas reais quando elas existem. O poder depende do **tamanho da amostra**, do **n√≠vel de signific√¢ncia**, da **variabilidade dos dados** e da **magnitude do efeito** que se deseja identificar.


## Tabela: Erros, Decis√µes e Poder do Teste

| Situa√ß√£o Real       | Decis√£o: Rejeitar H‚ÇÄ            | Decis√£o: N√£o Rejeitar H‚ÇÄ          |
|:-------------------:|:------------------------------:|:--------------------------------:|
| H‚ÇÄ √© verdadeira     | Erro Tipo I (*Œ±*)    | Decis√£o correta                  |
| H‚ÇÄ √© falsa          | Decis√£o correta (*poder*)                | Erro Tipo II (*Œ≤*)    |


- **Poder do teste:** Probabilidade de rejeitar H‚ÇÄ quando H‚ÇÄ √© falsa (ou seja, evitar o erro tipo II).


## Tamanho do Efeito

### O que √© o Tamanho do Efeito?

O **tamanho do efeito** √© uma medida que indica **o quanto uma diferen√ßa ou rela√ß√£o observada nos dados √© relevante na pr√°tica**. 

Enquanto o **valor-p** nos informa se um resultado √© estatisticamente significativo (ou seja, se √© improv√°vel que tenha ocorrido por acaso), o tamanho do efeito **complementa essa an√°lise mostrando a magnitude real do efeito observado**.


### Exemplos para Entender Melhor

> Imagine que um novo rem√©dio reduza a press√£o arterial em m√©dia em **1 mmHg** comparado ao tratamento padr√£o.  
  Com uma amostra muito grande, essa pequena diferen√ßa pode ser estatisticamente significativa (*valor-p* < 0,05), mas **clinicamente irrelevante**. O tamanho do efeito, neste caso, mostra que, apesar do resultado ser significativo, **o impacto pr√°tico √© muito pequeno**.

> Suponha um estudo que compara dois m√©todos de treinamento de for√ßa e encontra uma diferen√ßa m√©dia de **0,5 kg** no aumento de carga m√°xima entre os grupos ap√≥s 8 semanas.  
  Com uma amostra grande, essa diferen√ßa pode ser estatisticamente significativa, mas **na pr√°tica, esse ganho √© muito pequeno** para justificar a troca de m√©todo. O tamanho do efeito indica que, embora exista diferen√ßa detectada, **ela tem pouco impacto real no desempenho atl√©tico**.

> Considere uma pesquisa que compara n√≠veis de ansiedade entre terapia online e presencial, com diferen√ßa m√©dia de **1 ponto** (em escala de 0 a 100).  
  Mesmo que essa diferen√ßa seja estatisticamente significativa, **n√£o representa uma mudan√ßa clinicamente relevante** no estado emocional dos pacientes. O tamanho do efeito ajuda a perceber que a diferen√ßa entre as modalidades pode ser m√≠nima na pr√°tica.


## Medidas Comuns de Tamanho do Efeito

A escolha da medida depende do tipo de teste e das vari√°veis analisadas.

### d de Cohen (teste t)

Usado para comparar m√©dias entre dois grupos, mede a diferen√ßa em unidades de desvio padr√£o.

| Valor do d | Interpreta√ß√£o       |
|:------------|:---------------------|
| ‚âà 0.2      | Efeito pequeno      |
| ‚âà 0.5      | Efeito m√©dio        |
| ‚â• 0.8      | Efeito grande       |

### C de Cramer, para tabela 2x2 (teste qui-quadrado)

Mede a associa√ß√£o entre vari√°veis categ√≥ricas (varia de 0 a 1).

| Valor de C | Interpreta√ß√£o       |
|:------------|:---------------------|
| ‚âà 0.1      | Associa√ß√£o fraca    |
| ‚âà 0.3      | Associa√ß√£o moderada |
| ‚â• 0.5      | Associa√ß√£o forte    |

### Coeficiente de Correla√ß√£o de Pearson (r)

Mede a for√ßa da rela√ß√£o linear entre duas vari√°veis quantitativas.

| Valor de r   | Interpreta√ß√£o          |
|:--------------|:------------------------|
| ‚âà 0.1        | Correla√ß√£o fraca       |
| ‚âà 0.3        | Correla√ß√£o moderada    |
| ‚â• 0.5        | Correla√ß√£o forte       |
| 0            | Nenhuma correla√ß√£o     |
| ¬±1           | Correla√ß√£o perfeita    |


## Por que o Tamanho do Efeito √© Importante?

Um resultado estatisticamente significativo **nem sempre indica relev√¢ncia pr√°tica**. O tamanho do efeito responde √† pergunta: **"Esse resultado faz diferen√ßa no mundo real?"**

## Testes

Nas pr√≥ximas se√ß√µes, abordaremos os testes de **compara√ß√£o entre grupos** com base em uma vari√°vel quantitativa, os testes de **associa√ß√£o entre vari√°veis categ√≥ricas** nominais, e os testes de **correla√ß√£o**, que podem envolver vari√°veis quantitativas ou qualitativas ordinais. Essa abordagem visa facilitar a compreens√£o e a interpreta√ß√£o dos resultados estat√≠sticos em variados contextos, ressaltando sempre a import√¢ncia de avaliar a relev√¢ncia pr√°tica dos achados para uma tomada de decis√£o mais informada.


<!--chapter:end:13-Estat√≠stica-Inferencial.Rmd-->

# Testes de Compara√ß√£o entre Grupos

Os testes de compara√ß√£o s√£o usados para verificar se existem diferen√ßas significativas entre grupos em rela√ß√£o a uma vari√°vel quantitativa. Essas compara√ß√µes podem variar conforme a rela√ß√£o entre os grupos, o n√∫mero de grupos e o tipo de dado.

## Compara√ß√µes Pareadas (Dependentes)

Quando os grupos comparados s√£o relacionados ou ‚Äúligados‚Äù de alguma forma, dizemos que a compara√ß√£o √© **pareada** ou entre grupos **dependentes**. Isso acontece, por exemplo, quando medimos a mesma amostra em dois momentos diferentes ‚Äî antes e depois de uma interven√ß√£o ‚Äî ou quando comparamos pares de indiv√≠duos relacionados, como g√™meos.

**Exemplos:**

> Avaliar a press√£o arterial dos pacientes antes e depois de um tratamento.

> Medir a for√ßa muscular dos atletas antes e ap√≥s um programa de treinamento.

> Aplicar um teste de ansiedade em pacientes antes e depois de uma terapia.

## Compara√ß√µes N√£o-Pareadas (Independentes)

As compara√ß√µes s√£o **n√£o-pareadas** ou entre grupos **independentes** quando os grupos n√£o t√™m rela√ß√£o entre si, ou seja, os participantes de um grupo n√£o pertencem ao outro. Cada observa√ß√£o √© independente das outras.

**Exemplos:**

> Comparar a press√£o arterial entre pacientes que receberam medicamento e pacientes que receberam placebo.

> Comparar a velocidade m√©dia de corrida entre dois times diferentes.

> Comparar n√≠veis de estresse entre grupos que fizeram terapia presencial e terapia online.

## N√∫mero de Grupos na Compara√ß√£o

A compara√ß√£o pode ser feita entre **dois grupos** ou **mais de dois grupos**:

- **Dois grupos:** Por exemplo, comparar o desempenho entre dois m√©todos de ensino.
- **Mais de dois grupos:** Por exemplo, comparar o efeito de tr√™s diferentes dietas no peso corporal.

## Testes Param√©tricos e N√£o Param√©tricos

Para escolher o teste estat√≠stico adequado, √© importante considerar as caracter√≠sticas dos dados:

- **Testes Param√©tricos:**  
  Utilizados quando os dados seguem certas condi√ß√µes, como distribui√ß√£o normal e vari√¢ncia homog√™nea, permitindo uma an√°lise mais precisa.

- **Testes N√£o Param√©tricos:**  
  Indicados quando os dados n√£o atendem √†s condi√ß√µes dos testes param√©tricos, como em distribui√ß√µes assim√©tricas ou dados ordinais, oferecendo uma alternativa robusta para compara√ß√£o.


```{r setup2diag, include=FALSE}
library(DiagrammeR)
```

# Compara√ß√£o entre dois grupos

O fluxograma abaixo apresenta a sequ√™ncia de etapas para a escolha do teste estat√≠stico mais adequado na compara√ß√£o entre dois grupos, considerando o tipo de compara√ß√£o entre os dois grupos (pareada ou n√£o pareada) e a verifica√ß√£o da normalidade dos dados.

```{r fluxograma2gr, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
grViz("
digraph fluxo_teste {
  graph [layout = dot, rankdir = TB, bgcolor = white]

  node [shape = box, style = solid, fontname = 'Arial']
  grupos2      [label = '2 grupos']
  pareados     [label = 'Pareados']
  naopareados  [label = 'N√£o Pareados']
  norm_p       [label = 'Normalidade?']
  p_sim        [label = 'Teste t']
  p_nao        [label = 'Teste Wilcoxon']
  norm_np      [label = 'Normalidade?']
  variancia    [label = 'Teste de vari√¢ncia']
  t_indep      [label = 'Teste t']
  wmw_indep    [label = 'Teste Wilcoxon']

  # C√≠rculos para Sim/N√£o
  sim1         [label = 'Sim', shape = circle, width = 0.2, style = solid]
  nao1         [label = 'N√£o', shape = circle, width = 0.2, style = solid]
  sim2         [label = 'Sim', shape = circle, width = 0.2, style = solid]
  nao2         [label = 'N√£o', shape = circle, width = 0.2, style = solid]

  grupos2      -> pareados
  grupos2      -> naopareados

  pareados     -> norm_p
  norm_p       -> sim1
  norm_p       -> nao1
  sim1         -> p_sim
  nao1         -> p_nao

  naopareados  -> norm_np
  norm_np      -> sim2
  norm_np      -> nao2
  sim2         -> variancia
  variancia    -> t_indep
  nao2         -> wmw_indep
}
")
```

Exemplos did√°ticos para compara√ß√£o entre dois grupos s√£o mostrados a seguir. 

## Teste t pareado

O teste t (pareado ou n√£o pareado) √© um teste **param√©trico**, por isso, antes de aplicar o teste, recomenda-se verificar a normalidade dos dados.

O teste t pareado avalia se h√° diferen√ßa entre as m√©dias de dois conjuntos dependentes (ex: antes e depois em um mesmo grupo).

**Hip√≥teses:**

> H‚ÇÄ: A m√©dia antes √© igual √† m√©dia depois (n√£o h√° efeito).

> H‚ÇÅ: A m√©dia antes √© diferente da m√©dia depois (h√° efeito).

```{r t-pareadotest, message=FALSE}
# Simulando dados: press√£o antes e depois
set.seed(123)
antes <- rnorm(20, mean=120, sd=10)
depois <- antes + rnorm(20, mean=-5, sd=8) # espera-se uma redu√ß√£o m√©dia de 5

# Teste t pareado
t.test(antes, depois, paired = TRUE)
```

No R, fazer o teste t pareado √© muito f√°cil. Voc√™ s√≥ precisa usar uma linha: `t.test(antes, depois, paired = TRUE)`.  

Basta colocar os seus dois conjuntos de dados (por exemplo, as medidas antes e depois) e escrever **`paired = TRUE`** para avisar ao R que os dados s√£o do mesmo grupo em dois momentos.  

Assim, o R faz todo o c√°lculo para voc√™!

Ao realizar o teste t pareado no R, a sa√≠da apresenta v√°rias informa√ß√µes importantes:

- **t**: Este √© o valor do teste t calculado a partir dos dados. Ele indica o quanto a diferen√ßa m√©dia observada entre os grupos se afasta do que seria esperado se n√£o houvesse diferen√ßa real.
- **df**: Significa "degrees of freedom" (graus de liberdade), que neste caso √© igual ao n√∫mero de pares menos 1 (aqui, 19).
- **p-value**: √â a probabilidade de observarmos uma diferen√ßa igual ou maior que a encontrada, caso a hip√≥tese nula (de que n√£o h√° diferen√ßa) seja verdadeira. Um p-valor pequeno (por exemplo, menor que 0,05) indica que a diferen√ßa √© estatisticamente significativa.
- **alternative hypothesis**: Mostra qual hip√≥tese alternativa est√° sendo testada ‚Äì neste caso, que a diferen√ßa m√©dia entre "antes" e "depois" √© diferente de zero.
- **95 percent confidence interval**: Indica o intervalo de valores no qual a verdadeira diferen√ßa m√©dia est√° com 95% de confian√ßa. Aqui, podemos dizer que a diferen√ßa m√©dia entre os grupos est√° provavelmente entre 2,30 e 8,52.
- **mean difference**: √â a diferen√ßa m√©dia observada nos dados, neste exemplo, aproximadamente 5,41.

**Resumo:**  

O resultado sugere que h√° uma diferen√ßa significativa entre "antes" e "depois" (p = 0,0017), com a diferen√ßa m√©dia estimada em 5,41 unidades e um intervalo de confian√ßa que n√£o inclui zero.

> **Observa√ß√£o**: Se p √© maior que 0,05, n√£o rejeitamos H‚ÇÄ, nesse caso a conclus√£o seria que n√£o h√° evid√™ncia de diferen√ßa significativa.


## Wilcoxon pareado

O teste de Wilcoxon para amostras pareadas √© a alternativa n√£o param√©trica ao teste t pareado, sendo utilizado quando os dados n√£o seguem uma distribui√ß√£o normal.

**Hip√≥teses:**

> H‚ÇÄ: As distribui√ß√µes dos pares s√£o iguais (n√£o h√° diferen√ßa entre antes e depois).

> H‚ÇÅ: As distribui√ß√µes dos pares s√£o diferentes (h√° diferen√ßa entre antes e depois).

Formalmente, o teste verifica se a **distribui√ß√£o das diferen√ßas entre os pares** √© sim√©trica em torno de zero. Quando essa condi√ß√£o de simetria √© atendida, podemos interpretar o teste como uma compara√ß√£o das **medianas** das duas situa√ß√µes (por exemplo, antes e depois).

**Hip√≥teses:**

> H‚ÇÄ: A mediana das diferen√ßas entre os pares √© igual a zero (n√£o h√° diferen√ßa entre antes e depois).

> H‚ÇÅ: A mediana das diferen√ßas entre os pares √© diferente de zero (h√° diferen√ßa entre antes e depois).

*Observa√ß√£o: Esta formula√ß√£o das hip√≥teses em termos de mediana √© v√°lida quando as diferen√ßas apresentam distribui√ß√£o sim√©trica.*

```{r wilcoxon-pareadotest, message=FALSE}
wilcox.test(antes, depois, paired = TRUE)
```

Ao fazer o teste de Wilcoxon pareado no R, a resposta traz as seguintes informa√ß√µes:

- **V**: √â o valor da estat√≠stica do teste de Wilcoxon, calculado a partir das diferen√ßas entre os pares. N√£o precisamos interpretar esse n√∫mero diretamente; ele serve para o c√°lculo do p-valor.
- **p-value**: √â a chance de observarmos uma diferen√ßa igual ou maior que a encontrada, caso n√£o exista diferen√ßa real entre os grupos. Se o p-valor for menor que 0,05, dizemos que h√° diferen√ßa significativa entre "antes" e "depois".
- **alternative hypothesis**: Mostra qual hip√≥tese alternativa foi testada. Nesse caso, que a posi√ß√£o central (mediana) dos dois momentos n√£o √© igual.


No R, por padr√£o, a fun√ß√£o `wilcox.test()` n√£o mostra o intervalo de confian√ßa para a mediana das diferen√ßas.
No entanto, voc√™ pode pedir para calcular o intervalo de confian√ßa usando o argumento **`conf.int = TRUE`**:

```{r wilcoxon-pareado-ictest, message=FALSE}
wilcox.test(antes, depois, paired = TRUE, conf.int = TRUE)
```

Observa√ß√µes sobre o intervalo de confian√ßa do teste de Wilcoxon

**95 percent confidence interval:**  
  O intervalo de confian√ßa de 95% vai de 2,29 at√© 8,68. Isso significa que, com 95% de confian√ßa, a verdadeira mediana da diferen√ßa entre "antes" e "depois" est√° entre esses valores.  
  Como esse intervalo **n√£o inclui o zero**, temos mais uma indica√ß√£o de que existe diferen√ßa significativa entre os dois momentos.

**(pseudo)median:**  
  O valor de 5,55 indica a mediana das diferen√ßas observadas nos dados.  
  √â chamado de ‚Äúpseudo-median‚Äù porque, no teste de Wilcoxon, esse valor √© uma estimativa robusta do deslocamento central entre os pares.
 
  O termo ‚Äúpseudo-median‚Äù aparece no teste de Wilcoxon porque, nesse teste, a maneira de calcular a ‚Äúmediana‚Äù √© um pouco diferente da mediana comum.

**Mediana comum:** √â o valor do meio quando colocamos todos os n√∫meros em ordem.

**Pseudo-median:** No teste de Wilcoxon, em vez de pegar s√≥ o valor do meio, o c√°lculo usa todos os pares poss√≠veis de diferen√ßas entre os grupos. Ele faz uma m√©dia especial desses valores do meio. Por isso, chama-se ‚Äúpseudo‚Äù (uma ‚Äúfalsa‚Äù ou ‚Äúquase‚Äù mediana).

  
## Teste t n√£o pareado

Se voc√™ olhar no fluxograma apresentado no in√≠cio do cap√≠tulo, voc√™ ver√° que antes de executar o teste t para amostras n√£o pareadas, √© necess√°rio executar o teste de vari√¢ncia.

### Teste de vari√¢ncia

**√â um pr√©-requisito para o teste t n√£o pareado** Verifica se as vari√¢ncias de dois grupos n√£o pareados podem ser consideradas iguais ou n√£o. 

**Hip√≥teses:**

> H‚ÇÄ: As vari√¢ncias dos dois grupos s√£o iguais.

> H‚ÇÅ: As vari√¢ncias dos dois grupos s√£o diferentes.

**Interpreta√ß√£o:**  

Se p < 0,05, rejeitamos H‚ÇÄ e conclu√≠mos que as vari√¢ncias s√£o diferentes

> No teste t acrescentado o argumento `var.equal=FALSE` ou `var.equal=F`.

Se p > 0,05, consideramos as vari√¢ncias iguais.

> No teste t acrescentado o argumento `var.equal=TRUE` ou `var.equal=T`

**Importante:**  

O argumento **`var.equal`** dentro de **`t.test()`** define qual vers√£o do teste ser√° utilizada: se `var.equal = TRUE`, o teste assume vari√¢ncias iguais; se `var.equal = FALSE`, √© usada a corre√ß√£o de Welch, que n√£o assume homogeneidade. A escolha incorreta desse par√¢metro pode comprometer a validade do p-valor obtido, afetando a conclus√£o do teste.

**Explica√ß√£o did√°tica**

Imagine que voc√™ quer comparar as m√©dias de duas turmas. A Turma A tem poucos alunos e notas parecidas; a Turma B tem muitos alunos, mas as notas variam bastante.

Se voc√™ comparar as m√©dias assumindo que ambas t√™m a mesma varia√ß√£o, o resultado pode ser injusto.

A corre√ß√£o de Welch resolve isso: ela ajusta o c√°lculo do teste para considerar que as turmas s√£o diferentes ‚Äî olhando para a varia√ß√£o e o tamanho de cada grupo separadamente. Assim, o teste fica mais confi√°vel quando os grupos s√£o desiguais.

---

O teste t para amostras n√£o pareadas compara m√©dias de dois grupos independentes.

**Hip√≥teses:**

> H‚ÇÄ: A m√©dia do grupo A √© igual √† m√©dia do grupo B.

> H‚ÇÅ: As m√©dias dos grupos s√£o diferentes.

```{r t-independentetest, message=FALSE}
# Simulando dados
set.seed(456)
grupoA <- rnorm(30, mean=50, sd=7)
grupoB <- rnorm(30, mean=55, sd=7)

# Teste de vari√¢ncia (pr√©-requisito do t independente)
var.test(grupoA, grupoB)

# Teste t independente
t.test(grupoA, grupoB, var.equal = TRUE)
```

**Descri√ß√£o dos resultados do teste F para compara√ß√£o de vari√¢ncias**

- **F = 1.8842**: Este √© o valor da estat√≠stica F, que compara as duas vari√¢ncias. Ele √© calculado dividindo a vari√¢ncia do grupo com maior vari√¢ncia pela vari√¢ncia do outro grupo.
- **num df = 29, denom df = 29**: Esses s√£o os graus de liberdade, relacionados ao tamanho de cada grupo (n - 1), neste caso ambos com 30 participantes.
- **p-value = 0.09347**: Este √© o valor de signific√¢ncia. Ele mostra a probabilidade de observarmos uma diferen√ßa entre as vari√¢ncias t√£o grande quanto a encontrada, caso as vari√¢ncias dos grupos fossem realmente iguais. Como o p-valor √© maior que 0,05, n√£o podemos dizer que as vari√¢ncias s√£o diferentes de forma significativa.
- **alternative hypothesis: true ratio of variances is not equal to 1**: Isso mostra que o teste est√° verificando se as vari√¢ncias s√£o diferentes (n√£o iguais).
- **95 percent confidence interval: 0.896797 a 3.958627**: Com 95% de confian√ßa, o verdadeiro valor da raz√£o entre as vari√¢ncias est√° entre aproximadamente 0,90 e 3,96. Como esse intervalo inclui o valor 1, n√£o h√° diferen√ßa significativa entre as vari√¢ncias.
- **ratio of variances = 1.884167**: Esse √© o valor observado da raz√£o entre as vari√¢ncias dos dois grupos. O grupo com maior vari√¢ncia tem uma vari√¢ncia cerca de 1,88 vezes maior que o outro grupo.

**Resumo:**  
O teste F mostrou que n√£o h√° diferen√ßa estatisticamente significativa entre as vari√¢ncias dos grupos A e B, pois o p-valor √© maior que 0,05 e o intervalo de confian√ßa inclui o valor 1.


**Descri√ß√£o dos resultados do teste t para duas amostras n√£o pareadas**

- **t = -2.4453**: Este √© o valor da estat√≠stica t, que indica o quanto as m√©dias dos grupos A e B diferem em rela√ß√£o √† varia√ß√£o dos dados.
- **df = 58**: S√£o os graus de liberdade do teste, relacionados ao tamanho das amostras.
- **p-value = 0.01753**: O p-valor representa a probabilidade de encontrar uma diferen√ßa igual ou maior que a observada entre as m√©dias, caso realmente n√£o haja diferen√ßa entre os grupos. Como o p-valor √© menor que 0,05, podemos considerar que h√° diferen√ßa estatisticamente significativa entre as m√©dias de grupoA e grupoB.
- **alternative hypothesis: true difference in means is not equal to 0**: O teste verifica se existe diferen√ßa entre as m√©dias dos dois grupos (hip√≥tese alternativa de diferen√ßa).
- **95 percent confidence interval: -8.13 a -0.81**: Com 95% de confian√ßa, a diferen√ßa real entre as m√©dias est√° entre -8,13 e -0,81. Como esse intervalo n√£o inclui o zero, refor√ßa a indica√ß√£o de diferen√ßa significativa.
- **mean of x (grupoA): 51.62**  
  **mean of y (grupoB): 56.09**  
  As m√©dias dos grupos mostram que o grupo B teve, em m√©dia, um valor maior que o grupo A.

**Resumo:**  
O teste t indicou que existe uma diferen√ßa estatisticamente significativa entre as m√©dias dos grupos A e B. O grupo B apresentou m√©dia maior que o grupo A, e essa diferen√ßa dificilmente ocorreu ao acaso.


## Wilcoxon n√£o pareado

O teste √© tamb√©m conhecido como Wilcoxon-Mann-Whitney. √â a alternativa n√£o param√©trica ao t independente para comparar dois grupos independentes.

**Hip√≥teses:**

> H‚ÇÄ: As distribui√ß√µes dos grupos s√£o iguais.

> H‚ÇÅ: As distribui√ß√µes dos grupos s√£o diferentes.

```{r mann-whitneytest, message=FALSE}
wilcox.test(grupoA, grupoB)
```

**Descri√ß√£o dos resultados do teste de Wilcoxon para duas amostras n√£o pareadas**

- **W = 316**: Este √© o valor da estat√≠stica de Wilcoxon, que representa a soma dos postos atribu√≠dos aos valores dos grupos ao comparar suas distribui√ß√µes.
- **p-value = 0.04789**: O valor de p indica a probabilidade de observar uma diferen√ßa igual ou maior entre os grupos, caso n√£o exista diferen√ßa real. Como √© menor que 0,05, isso sugere que h√° diferen√ßa estatisticamente significativa entre os grupos A e B.
- **alternative hypothesis: true location shift is not equal to 0**: O teste est√° avaliando se h√° diferen√ßa (deslocamento) entre as localiza√ß√µes centrais dos dois grupos (medianas diferentes).

**Resumo:**  
O teste de Wilcoxon mostrou que h√° uma diferen√ßa estatisticamente significativa nas distribui√ß√µes dos grupos A e B, indicando que eles provavelmente apresentam medianas diferentes.


## Teste bilateral vs. teste unilateral

### O que s√£o?

- **Teste bilateral (bicaudal ou two-sided):**
  - Verifica se h√° diferen√ßa **em qualquer dire√ß√£o** entre os grupos ou condi√ß√µes.
  - Exemplo: "Ser√° que a m√©dia do grupo A √© **diferente** da m√©dia do grupo B?" (pode ser maior ou menor).

- **Teste unilateral (caudal ou one-sided):**
  - Verifica se h√° diferen√ßa **em uma dire√ß√£o espec√≠fica**.
  - Exemplo: "Ser√° que a m√©dia do grupo A √© **maior** que a m√©dia do grupo B?" ou "Ser√° que √© **menor**?".

---

### Formula√ß√£o das hip√≥teses

- **Teste bilateral:**
  - Hip√≥tese nula (\(H_0\)): n√£o h√° diferen√ßa (\(\mu_A = \mu_B\))
  - Hip√≥tese alternativa (\(H_1\)): h√° diferen√ßa (\(\mu_A \neq \mu_B\))

- **Teste unilateral (maior):**
  - Hip√≥tese nula (\(H_0\)): \(\mu_A \leq \mu_B\)
  - Hip√≥tese alternativa (\(H_1\)): \(\mu_A > \mu_B\)

- **Teste unilateral (menor):**
  - Hip√≥tese nula (\(H_0\)): \(\mu_A \geq \mu_B\)
  - Hip√≥tese alternativa (\(H_1\)): \(\mu_A < \mu_B\)

---

### Influ√™ncia no c√°lculo do p-valor

- **Teste bilateral:**  
  O p-valor representa a probabilidade de encontrar um resultado t√£o extremo quanto o observado **em ambas as dire√ß√µes** (para mais ou para menos).  
  √â mais rigoroso, pois considera desvios para cima e para baixo.

- **Teste unilateral:**  
  O p-valor considera apenas **uma dire√ß√£o** (maior ou menor).  
  Geralmente, o p-valor do teste unilateral √© a metade do bilateral, para o mesmo dado e dire√ß√£o, tornando o teste **mais sens√≠vel** a detectar diferen√ßas naquela dire√ß√£o, mas exige justificativa te√≥rica para ser usado.

---

### O que muda nas fun√ß√µes `t.test()` e `wilcox.test()`

Nas duas fun√ß√µes, voc√™ controla o tipo de teste pelo argumento `alternative`:

- **Teste bilateral (padr√£o):**
  - `alternative = "two.sided"`

- **Teste unilateral (maior):**
  - `alternative = "greater"`

- **Teste unilateral (menor):**
  - `alternative = "less"`

**Exemplo:**
```r
# Teste t bilateral (padr√£o)
t.test(x, y, alternative = "two.sided")

# Teste t unilateral (x maior que y)
t.test(x, y, alternative = "greater")

# Teste de Wilcoxon unilateral (x menor que y)
wilcox.test(x, y, alternative = "less")
```

Ou seja:
- **O argumento `alternative` define se o teste √© bilateral ou unilateral.**
- Isso altera a formula√ß√£o das hip√≥teses, o c√°lculo do p-valor e a interpreta√ß√£o do resultado.


## Exerc√≠cio 1 

**Compara√ß√£o da velocidade dos Pok√©mons verdes e amarelos**

1. **Baixe o banco de dados**  
   Use o banco de dados: [Pokemon.csv](https://drive.google.com/drive/folders/1gyORbBEuKBstfSKULA58TLhawOXaY-st)  
   Importe o arquivo **Pokemon.csv** para o RStudio.


2. **Pergunta do exerc√≠cio**  
   Teste se existe diferen√ßa significativa entre a velocidade (**speed**) dos Pok√©mons verdes (**green**) e amarelos (**yellow**).


3. **Formula√ß√£o das hip√≥teses de acordo com os testes**
   
   > Hip√≥tese nula (\(H_0\)): 
  
   > Hip√≥tese alternativa (\(H_1\)): 


4. **N√≠vel de signific√¢ncia**  
   Considere \(\alpha = 0,05\).
   
   
5. **Passos para executar o teste adequado**
   
   a) Separe os dados dos Pok√©mons de cor verde e de cor amarela.  
   b) Verifique a normalidade dos dados de velocidade de cada grupo (gr√°fico QQ).  
   c) Escolha o teste mais apropriado:
      - Se as duas amostras seguirem distibui√ß√£o Normal ‚Üí teste de vari√¢ncia ‚Üí teste t
      - Se uma das amostras n√£o seguir distibui√ß√£o Normal ‚Üí teste de Wilcoxon
   d) Execute o teste, compare o p-valor com \(\alpha\) e conclua
   
   
6. **Conclus√£o**  
   - Se \(p\)-valor < 0,05: rejeite a hip√≥tese nula e conclua que h√° diferen√ßa significativa nas velocidades.
   - Se \(p\)-valor ‚â• 0,05: n√£o rejeite a hip√≥tese nula e conclua que n√£o h√° diferen√ßa significativa nas velocidades.

**Resposta** [Posit.cloud](https://posit.cloud/content/10470490)

## Exerc√≠cio 2 

Considere a tabela de resultados publicados no artigo [Resposta da Press√£o Arterial ao Esfor√ßo em Adolescentes: Influ√™ncia do Sobrepeso e Obesidade](https://www.google.com/search?q=teste+t+medicina+artigo+&sca_esv=e5b91424496cf486&ei=2bREaLDDNsnX5OUPnpW78Ac&ved=0ahUKEwjwk8eEpuCNAxXJK7kGHZ7KDn4Q4dUDCBA&uact=5&oq=teste+t+medicina+artigo+&gs_lp=Egxnd3Mtd2l6LXNlcnAiGHRlc3RlIHQgbWVkaWNpbmEgYXJ0aWdvIDIHECEYoAEYCjIHECEYoAEYCjIFECEYnwVIlhdQrQlY4BVwAngBkAEAmAG6AaABrwmqAQMwLji4AQPIAQD4AQGYAgqgAt8JwgIKEAAYsAMY1gQYR8ICBRAhGKABwgIIEAAYCBgNGB7CAgUQABjvBcICCBAAGIAEGKIEmAMAiAYBkAYIkgcDMi44oAflIrIHAzAuOLgH1gnCBwUwLjcuM8gHHA&sclient=gws-wiz-serp#:~:text=Resposta%20da%20Press%C3%A3o,br%20%E2%80%BA%20abc):

| Grupo                  | GSO Meninas (n = 24) | GE Meninas (n = 24) | p        |
|------------------------|:--------------------:|:-------------------:|:--------:|
| **Idade** (anos)       | 12,1 ¬± 1,3           | 12,0 ¬± 1,5          | 0,86     |
| **Peso** (kg)          | 59,3 ¬± 12,9          | 38,8 ¬± 9,3**         | <0,0001  |
| **Estatura** (m)       | 1,53 ¬± 0,09          | 1,46 ¬± 0,10*         | 0,02     |
| **IMC** (kg/m¬≤)        | 25,2 ¬± 3,8           | 17,9 ¬± 2,3**         | <0,0001  |
| **RT/S** (mm)          | 0,85 ¬± 0,19          | 1,43 ¬± 0,40**        | <0,0001  |
| **PAS repouso** (mmHg) | 114 ¬± 12             | 108 ¬± 10             | 0,07     |
| **PAD repouso** (mmHg) | 66 ¬± 6               | 67 ¬± 8               | 0,51     |
| **PAM repouso** (mmHg) | 82 ¬± 7               | 81 ¬± 8               | 0,67     |
| **FC** (bpm)           | 84 ¬± 10              | 87 ¬± 9               | 0,34     |

*Teste t-Student para amostras independentes; *p ‚â§ 0,05; **p ‚â§ 0,01.  
Diferen√ßas entre m√©dias do grupo de sobrepeso e obesos vs eutr√≥ficos.

IMC - √≠ndice de massa corporal (peso/estatura¬≤); 

RT/S - rela√ß√£o tr√≠ceps/subescapular;  

PAS - press√£o arterial sist√≥lica; 

PAD - press√£o arterial diast√≥lica; 

PAM - press√£o arterial m√©dia; 

FC - frequ√™ncia card√≠aca m√©dia.*


**Contexto:**  
A tabela acima apresenta caracter√≠sticas antropom√©tricas e hemodin√¢micas de meninas do grupo de sobrepeso/obesidade (GSO) e do grupo eutr√≥fico (GE). Os autores utilizaram o teste t de Student para amostras independentes.

**Pergunta:**  
Escolha uma vari√°vel da tabela e formule as hip√≥teses nula e alternativa para a compara√ß√£o entre os grupos GSO e GE. Depois, descreva a conclus√£o dos autores com base no valor de p apresentado na tabela.

---

**Exemplo de resposta:**

**Vari√°vel escolhida:** Peso (kg)

**Hip√≥teses:**

- Hip√≥tese nula (H‚ÇÄ):  
  As m√©dias de peso (kg) dos grupos GSO e GE s√£o iguais.  

- Hip√≥tese alternativa (H‚ÇÅ):  
  As m√©dias de peso (kg) dos grupos GSO e GE s√£o diferentes.  

**N√≠vel de signific√¢ncia:** Œ± = 0,05

**Valor de p na tabela:** p < 0,0001

**Conclus√£o:**  
Como o valor de p √© menor que 0,05, rejeita-se a hip√≥tese nula. Portanto, os autores concluem que existe diferen√ßa estatisticamente significativa entre as m√©dias de peso dos grupos GSO e GE, sendo o peso significativamente maior no grupo GSO.

**Voc√™ pensou nisso?** 
O peso √© a vari√°vel intr√≠nseca √† compara√ß√£o, pois define os grupos.

---

## Exerc√≠cio 3 

O artigo [Sintomas de estresse pr√©-competitivo em atletas adolescentes de handebol](https://www.scielo.br/j/rbce/a/WkdgtTdkykSVHJ9rGYGh7Lx/?format=pdf&lang=pt) utilizou como instrumento a Lista de Sintomas de Estresse Pr√©-competitivo Infanto-juvenil (LSSPCI), uma escala do tipo Likert (De Rose Jr., 1998). A LSSPCI cont√©m 31 sintomas, para os quais cada atleta responde em uma escala de 1 (nunca) a 5 (sempre) sobre a frequ√™ncia com que cada situa√ß√£o ocorreu nas 24 horas anteriores √† competi√ß√£o. Os escores dos sintomas s√£o somados para cada atleta, resultando em um escore total de estresse. Analise os resultados da Tabela 1 do artigo:  

**Tabela 1. M√©dias, desvios-padr√£o, valores p da diferen√ßa de m√©dias e mediana dos sintomas de estresse medidos pela LSSPCI em atletas adolescentes de handebol, segundo o sexo (n = 97)** 

| Sintomas de estresse ‚Äì LSSPCI                         | Meninos  | Meninas  | Valor p·µÉ |
|------------------------------------------------------|:----------------------------:|:----------------------------:|:--------:|
| Meu cora√ß√£o bate mais r√°pido que o normal            | 2,2 ¬± 1,0 (2,0)              | 2,5 ¬± 0,9 (2,5)              | 0,1      |
| Suo bastante                                         | 2,5 ¬± 1,2 (2,0)              | 2,4 ¬± 1,3 (2,0)              | 0,4      |
| Fico agitado (a)                                     | 3,0 ¬± 0,9 (3,0)              | 3,2 ¬± 1,3 (3,0)              | 0,5      |
| Fico preocupado (a) com cr√≠ticas das pessoas         | 2,9 ¬± 1,5 (3,0)              | 2,6 ¬± 1,4 (2,0)              | 0,2      |
| Sinto muita vontade de fazer xixi                    | 2,0 ¬± 1,3 (1,0)              | 2,0 ¬± 1,2 (2,0)              | 0,7      |
| Fico preocupado (a) com meus advers√°rios             | 2,7 ¬± 1,2 (3,0)              | 2,9 ¬± 1,4 (3,0)              | 0,5      |
| Bebo muita √°gua                                      | 2,5 ¬± 1,2 (3,0)              | 2,9 ¬± 1,5 (3,0)              | 0,3      |
| Roo (como) as unhas                                 | 2,5 ¬± 1,9 (2,0)              | 2,1 ¬± 1,5 (1,0)              | 0,2      |
| Fico empolgado (a)                                   | 3,5 ¬± 1,3 (4,0)              | 3,6 ¬± 1,5 (4,0)              | 0,6      |
| Fico aflito (a)                                      | 2,3 ¬± 1,7 (2,0)              | 2,8 ¬± 1,3 (3,0)              | 0,1      |
| Tenho medo de competir mal                           | 2,6 ¬± 1,4 (3,0)              | 2,9 ¬± 1,4 (3,0)              | 0,4      |
| Demoro muito para dormir                             | 2,8 ¬± 2,4 (3,0)              | 2,3 ¬± 2,0 (2,0)              | 0,05     |
| Tenho d√∫vidas sobre minha capacidade de competir     | 2,4 ¬± 1,8 (2,0)              | 2,4 ¬± 1,2 (2,0)              | 0,7      |
| Sonho com a competi√ß√£o                             |  2,4 ¬± 1,2 (2,0)          | 1,9 ¬± 1,3 (1,0)        | 0,04 |
| Fico nervoso (a)                                     | 3,1 ¬± 1,6 (3,0)              | 3,3 ¬± 1,2 (3,0)              | 0,6      |
| Fico preocupado (a) com o resultado da competi√ß√£o    | 3,1 ¬± 1,4 (3,0)              | 3,7 ¬± 1,4 (4,0)              | 0,1      |
| Minha boca fica seca                                 | 2,4 ¬± 1,3 (2,0)              | 2,3 ¬± 1,4 (2,0)              | 0,6      |
| Sinto muito cansa√ßo no fim do treino                 | 2,6 ¬± 1,3 (2,0)              | 2,7 ¬± 1,3 (2,0)              | 0,9      |
| A presen√ßa de meus pais na competi√ß√£o me preocupa    | 3,1 ¬± 1,7 (2,0)              | 2,6 ¬± 1,6 (2,0)              | 0,1      |
| Falo muito sobre a competi√ß√£o                        | 3,0 ¬± 1,5 (3,0)              | 3,2 ¬± 1,3 (3,0)              | 0,6      |
| Tenho medo de perder                                 | 2,9 ¬± 1,4 (3,0)              | 3,1 ¬± 1,4 (3,0)              | 0,4      |
| Fico impaciente                                      | 2,4 ¬± 1,1 (2,0)              | 2,6 ¬± 1,3 (2,5)              | 0,5      |
| N√£o penso em outra coisa a n√£o ser na competi√ß√£o     | 2,2 ¬± 1,2 (2,0)              | 2,7 ¬± 1,4 (2,0)              | 0,2      |
| N√£o vejo a hora de competir                          | 3,2 ¬± 1,4 (3,0)              | 3,3 ¬± 1,4 (3,0)              | 0,7      |
| Fico emocionado (a)                                  | 1,8 ¬± 1,3 (1,0)              | 2,3 ¬± 1,3 (2,0)              | 0,1      |
| Fico ansioso (a)                                     | 3,6 ¬± 1,2 (3,0)              | 3,4 ¬± 1,5 (4,0)              | 0,7      |
| No dia da competi√ß√£o acordo mais cedo do que o normal| 3,1 ¬± 1,7 (3,0)              | 3,0 ¬± 1,6 (3,0)              | 0,8      |
| Tenho medo de decepcionar as pessoas                 | 2,7 ¬± 1,4 (3,0)              | 3,0 ¬± 1,5 (3,0)              | 0,3      |
| Sinto-me mais respons√°vel                            | 3,1 ¬± 1,3 (3,0)              | 2,7 ¬± 1,3 (3,0)              | 0,2      |
| Sinto que as pessoas exigem muito de mim             | 2,5 ¬± 1,4 (2,0)              | 2,4 ¬± 1,4 (2,0)              | 0,8      |
| Tenho medo de cometer erros na competi√ß√£o            | 3,4 ¬± 1,4 (3,0)              | 3,6 ¬± 1,3 (4,0)              | 0,4      |

M√©dia ¬± DP (mediana); ·µÉ Teste de Wilcoxon n√£o pareado; p < 0,05.

**Com base na Tabela 1, qual sintoma de estresse apresentou diferen√ßa estatisticamente significativa entre meninos e meninas segundo o teste de Wilcoxon? Explique como interpretar esse resultado considerando o contexto da escala LSSPCI.**

## Exerc√≠cio 4

O artigo [Qualidade de vida de estudantes de Psicologia](https://pepsic.bvsalud.org/pdf/psicoinfo/v16n16/v16n16a07.pdf) avaliou a qualidade de vida de acad√™micos de psicologia e correlacionou-a com fatores sociodemogr√°ficos. Participaram 310 alunos de psicologia que responderam a um question√°rio sociodemogr√°fico e ao The Medical Outcomes Study 36-item Short-Form Health Survey (SF-36) para avaliar a qualidade de vida. Veja os resultados do teste t na Tabela 2: 

**Tabela 2: Compara√ß√£o entre g√™neros nas dimens√µes de qualidade de vida**

| Dimens√µes             | Vari√°vel   | M√©dia   | DP     | t    | p-valor |
|-----------------------|:------------:|:---------:|:---------:|:------:|:---------:|
| Capacidade funcional  | Masculino  | 89,74   | 14,49   | 2,44 | 0,119   |
|                       | Feminino   | 86,95   | 11,6    |      |         |
| Aspectos f√≠sicos      | Masculino  | 79,74   | 25,84   | 0,76 | 0,383   |
|                       | Feminino   | 75,82   | 31,84   |      |         |
| Dor                   | Masculino  | 74,93   | 22,05   | 4,33 | 0,038   |
|                       | Feminino   | 68,26   | 22,00   |      |         |
| Estado geral de sa√∫de | Masculino  | 75,21   | 20,36   | 1,15 | 0,284   |
|                       | Feminino   | 72,32   | 17,67   |      |         |
| Vitalidade            | Masculino  | 61,38   | 22,47   | 1,50 | 0,222   |
|                       | Feminino   | 57,92   | 18,57   |      |         |
| Aspectos sociais      | Masculino  | 71,34   | 27,61   | 0,06 | 0,804   |
|                       | Feminino   | 70,43   | 24,31   |      |         |
| Aspecto emocional     | Masculino  | 63,16   | 40,67   | 0,38 | 0,536   |
|                       | Feminino   | 59,51   | 39,85   |      |         |
| Sa√∫de mental          | Masculino  | 70,55   | 19,97   | 3,05 | 0,082   |
|                       | Feminino   | 65,7    | 18,80   |      |         |

**Com base na Tabela 2, em qual dimens√£o da qualidade de vida foi observada diferen√ßa estatisticamente significativa entre estudantes do sexo masculino e feminino? O que esse resultado sugere sobre a experi√™ncia dos alunos nesses grupos?**

<!--chapter:end:14-Testes-Comparacao.Rmd-->

# C√°lculo amostral no R

O c√°lculo do tamanho da amostra √© fundamental para garantir a validade estat√≠stica de um estudo. No R, esse c√°lculo pode ser realizado de forma pr√°tica utilizando diversos pacotes.

## Principais Pacotes para C√°lculo Amostral

- **pwr**: Utilizado para an√°lise de poder estat√≠stico e c√°lculo do tamanho da amostra para diferentes testes (t-test, ANOVA, correla√ß√£o, etc.).
- **epiDisplay**: Oferece fun√ß√µes para c√°lculos amostrais em estudos epidemiol√≥gicos.
- **epiR**: Bastante utilizado em epidemiologia, com fun√ß√µes para diferentes desenhos de estudo.
- **samplesize**: Possui m√©todos para c√°lculo de tamanho amostral em diferentes contextos.

## Exemplo de c√°lculo amostral para teste t

```r
# Instale o pacote se necess√°rio
# install.packages("pwr")
library(pwr)

# C√°lculo do tamanho da amostra para detectar um efeito de tamanho m√©dio (d = 0.5)
# com poder de 80% e n√≠vel de signific√¢ncia de 5%
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```
O uso de fun√ß√µes e pacotes espec√≠ficos no R torna o c√°lculo amostral mais acess√≠vel, permitindo maior precis√£o no planejamento de estudos. Sempre leve em conta os par√¢metros do seu estudo, como efeito esperado, vari√¢ncia, poder e n√≠vel de signific√¢ncia.


No exemplo os seguintes par√¢metros foram utilizados:

- **d = 0.5**  
  *Tamanho do efeito (Effect size)*: Representa a magnitude da diferen√ßa que se espera detectar entre as m√©dias dos grupos, em unidades de desvio padr√£o. Quanto maior o efeito, mais f√°cil √© detect√°-lo com uma amostra menor.  
  - O tamanho do efeito pode ser estimado a partir de dados pr√©vios, estudos semelhantes ou com base em uma suposi√ß√£o informada.  
  - Categorias comuns: pequeno (~0,2), m√©dio (~0,5) e grande (~0,8).

- **power = 0.8**  
  *Poder estat√≠stico (Power)*: √â a probabilidade de detectar uma diferen√ßa real quando ela de fato existe (ou seja, de rejeitar corretamente a hip√≥tese nula se ela for falsa).  
  - Poder = 1 - Œ≤, onde Œ≤ √© a probabilidade de erro tipo II (falso negativo).  
  - O valor padr√£o mais utilizado √© 0,80 (ou 80%).

- **sig.level = 0.05**  
  *N√≠vel de signific√¢ncia (Œ±)*: √â a probabilidade de rejeitar a hip√≥tese nula quando ela √© verdadeira (erro tipo I, falso positivo).  
  - O valor padr√£o √© 0,05 (ou 5%), indicando que aceitamos at√© 5% de chance de um falso positivo.

- **type = "two.sample"**  
  Indica que estamos comparando dois grupos independentes (teste t para duas amostras).

**Interpreta√ß√£o dos Resultados**

Ao rodar o comando acima, o R retorna o tamanho m√≠nimo de amostra necess√°rio **em cada grupo** para que seja poss√≠vel detectar uma diferen√ßa de tamanho de efeito `d = 0.5` com 80% de poder e 5% de n√≠vel de signific√¢ncia, usando um teste t para duas amostras.

Por exemplo, o resultado pode ser algo assim:

```
     Two-sample t test power calculation 

              n = 63.76561
              d = 0.5
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group
```

**Explica√ß√£o:**

- *n ‚âà 64*: Voc√™ precisaria de pelo menos **64 participantes em cada grupo** para ter 80% de chance de detectar uma diferen√ßa de tamanho m√©dio (0,5 desvios padr√£o) entre os grupos, com risco de 5% de um falso positivo.

**Considera√ß√µes**

- O tamanho da amostra depende diretamente do tamanho do efeito esperado, do poder estat√≠stico desejado e do n√≠vel de signific√¢ncia escolhido.
- Quanto maior o efeito esperado, menor precisa ser a amostra.
- Quanto maior o poder ou menor o n√≠vel de signific√¢ncia, maior ser√° o tamanho da amostra necess√°ria.
- Use dados pr√©vios, literatura ou c√°lculos explorat√≥rios para definir o tamanho do efeito.

## O que √© o d de Cohen?

O d de Cohen √© uma **medida padronizada** do tamanho do efeito para comparar a diferen√ßa entre duas m√©dias, levando em conta a variabilidade dos dados. Ele √© muito utilizado para quantificar o qu√£o grande √© a diferen√ßa entre dois grupos em termos de desvios padr√£o.

---

### F√≥rmula Geral para Dados N√£o Pareados (Amostras Independentes)

\[
d = \frac{\bar{X}_1 - \bar{X}_2}{s_p}
\]

Onde:

- \(\bar{X}_1\) = m√©dia do grupo 1  
- \(\bar{X}_2\) = m√©dia do grupo 2  
- \(s_p\) = desvio padr√£o combinado (pooled) dos dois grupos

**Como calcular o desvio padr√£o combinado**

\[
s_p = \sqrt{ \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2} }
\]

Onde:

- \(n_1\), \(n_2\) = tamanhos das amostras dos grupos 1 e 2  
- \(s_1\), \(s_2\) = desvios padr√£o dos grupos 1 e 2

#### Exemplo pr√°tico em R

Suponha:

- Grupo 1: m√©dia = 10, desvio padr√£o = 2, n = 30  
- Grupo 2: m√©dia = 8, desvio padr√£o = 2.5, n = 35

```{r d-cohencal, message=FALSE}
media1 <- 10
media2 <- 8
sd1 <- 2
sd2 <- 2.5
n1 <- 30
n2 <- 35

# Desvio padr√£o combinado
sp <- sqrt( ((n1-1)*sd1^2 + (n2-1)*sd2^2) / (n1 + n2 - 2) )

# d de Cohen para dados n√£o pareados
d_np <- (media1 - media2) / sp
d_np
```


### F√≥rmula para Dados Pareados (Amostras Dependentes)

Quando os dados s√£o pareados (por exemplo, antes e depois para o mesmo grupo de indiv√≠duos), o c√°lculo do d de Cohen √© diferente:

\[
d = \frac{\bar{d}}{s_d}
\]

Onde:

- \(\bar{d}\) = m√©dia das diferen√ßas entre os pares  
- \(s_d\) = desvio padr√£o das diferen√ßas

#### Exemplo pr√°tico em R

Suponha que temos as diferen√ßas entre as medi√ß√µes de 5 sujeitos: -0,5; 0; 0,6; 1,2 e 1,7.

```{r d-cohenpareado, message=FALSE}
diferencas <- c(-0.5, 0.0, 0.6, 1.2, 1.7)

media_dif <- mean(diferencas)
sd_dif <- sd(diferencas)

# d de Cohen para dados pareados
d_p <- media_dif / sd_dif
d_p
```

**Valores t√≠picos para d de Cohen:**

- **0.2**: efeito pequeno  
- **0.5**: efeito m√©dio  
- **0.8**: efeito grande  

Assim, quanto maior o valor de d, maior a diferen√ßa entre os grupos em rela√ß√£o √† variabilidade dos dados.


Pense no **d de Cohen** como uma r√©gua que compara a diferen√ßa entre as m√©dias de dois grupos, levando em conta o quanto os dados variam dentro desses grupos.

- Se d √© pequeno, significa que a diferen√ßa entre as m√©dias dos grupos √© pequena em rela√ß√£o √† ‚Äúbagun√ßa‚Äù (varia√ß√£o) dos dados ‚Äì ou seja, os grupos s√£o parecidos.
- Se d √© grande, significa que a diferen√ßa entre as m√©dias √© grande em compara√ß√£o com a varia√ß√£o dos dados ‚Äì ou seja, os grupos s√£o bem diferentes.

Um valor alto de d indica que os grupos s√£o realmente diferentes entre si, enquanto um valor baixo mostra que eles s√£o muito parecidos, considerando o quanto os dados ‚Äúdispersam‚Äù dentro de cada grupo.

## Exemplos pr√°ticos

A seguir, apresento exemplos pr√°ticos para Medicina, Psicologia e Educa√ß√£o F√≠sica.

### Medicina: Compara√ß√£o de dois tratamentos para dor

**Cen√°rio:**  
Um estudo cl√≠nico quer comparar dois medicamentos para dor cr√¥nica.  

- Tamanho do efeito esperado (Cohen's d): 0.2 (pequeno)  
- Poder desejado: 0.80  
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-medcal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necess√°ria para cada grupo
pwr.t.test(d = 0.2, power = 0.8, sig.level = 0.05, type = "two.sample")
```

Tamanho da amostra: 394 em cada grupo

### Psicologia: Interven√ß√£o para redu√ß√£o de ansiedade

**Cen√°rio:**  
Um psic√≥logo quer testar se uma nova terapia reduz a ansiedade em rela√ß√£o ao tratamento padr√£o.  

- Tamanho do efeito esperado (Cohen's d): 0.6 (m√©dio/grande)  
- Poder desejado: 0.80  
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-psicocal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necess√°ria para cada grupo
pwr.t.test(d = 0.6, power = 0.8, sig.level = 0.05, type = "two.sample")
```

Tamanho da amostra: 45 em cada grupo

### Educa√ß√£o F√≠sica: Efeito de um programa de treinamento na performance de corrida

**Cen√°rio:**  
Um preparador f√≠sico quer comparar a performance de alunos submetidos a dois programas de treinamento diferentes.  

- Tamanho do efeito esperado (Cohen's d): 0.8 (grande)  
- Poder desejado: 0.80
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-educacal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necess√°ria para cada grupo
pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = "two.sample")
```
Tamanho da amostra: 26 em cada grupo

- O resultado de cada fun√ß√£o indica o **n√∫mero m√≠nimo de participantes em cada grupo** para atingir o **poder estat√≠stico** desejado.


## Como calcular o poder do teste quando voc√™ j√° tem o tamanho da amostra

O pacote `pwr` do R n√£o serve apenas para calcular o tamanho da amostra necess√°rio. Ele tamb√©m permite **descobrir o poder do teste** caso voc√™ j√° saiba quantos participantes ter√° em cada grupo.

### Exemplo 

Suponha que voc√™ fez um estudo com **26 participantes em cada grupo** e espera encontrar um **tamanho de efeito grande (d = 0.8)**. O n√≠vel de signific√¢ncia que voc√™ escolheu √© o padr√£o, **0,05**. Voc√™ quer saber: *com essa amostra, qual √© o poder do meu teste*?

Voc√™ pode usar:

```{r pwr-podercal, message=FALSE,  warning=FALSE}
pwr.t.test(n = 26, d = 0.8, power = NULL, sig.level = 0.05, type = "two.sample")
```

**Explica√ß√£o dos par√¢metros**

- `n = 20`: tamanho da amostra em cada grupo j√° definido.
- `d = 0.8`: tamanho do efeito (Cohen‚Äôs d), aqui considerado grande.
- `sig.level = 0.05`: n√≠vel de signific√¢ncia (chance m√°xima de um falso positivo).
- `type = "two.sample"`: teste t para dois grupos independentes.
- `power = NULL`: ao deixar o par√¢metro `power` em NULL, voc√™ est√° dizendo ao R para calcular **qual √© o poder do teste** com esses valores.

Nesse caso o poder do teste √© de 70%.

**O que acontece nesse c√°lculo?**

O R resolve a equa√ß√£o para o poder estat√≠stico usando os valores que voc√™ forneceu. Ou seja, ele vai informar a **probabilidade de detectar uma diferen√ßa real (de tamanho d = 0.8) entre os grupos, com 26 participantes em cada grupo**, considerando o n√≠vel de signific√¢ncia especificado.

**Por que isso √© √∫til?**

- Se o poder calculado for **menor que 0,80** (80%), pode ser interessante aumentar a amostra para garantir maior chance de detectar diferen√ßas reais.
- Se o poder j√° for **maior que 0,80**, seu estudo tem boa sensibilidade para o efeito esperado.

**Resumindo**

- Voc√™ pode usar `pwr.t.test` para calcular o poder do teste, **bastando informar `n` e deixar `power = NULL`**.
- Isso √© √∫til para analisar experimentos j√° realizados ou planejar com base em restri√ß√µes de amostra.


## C√°lculo do Tamanho da Amostra para Testes t Pareado e Wilcoxon

Al√©m do teste t para amostras independentes, voc√™ pode calcular o tamanho da amostra para outras situa√ß√µes, como o teste t pareado e os testes n√£o param√©tricos de Wilcoxon (para amostras pareadas ou n√£o pareadas). Para os testes n√£o param√©tricos, recomenda-se aumentar o tamanho da amostra em 15% em rela√ß√£o ao c√°lculo do teste t correspondente.


### Teste t Pareado

**Cen√°rio:**  
Voc√™ quer testar se uma interven√ß√£o reduz o n√≠vel de estresse dos mesmos participantes antes e depois do tratamento.  

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-t-pareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
```

Observe o argumento **type = "paired"** indicando que o c√°lculo √© para amostras pareadas.

### Teste de Wilcoxon para Amostras N√£o Pareadas

**Cen√°rio:**  
Voc√™ deseja comparar dois grupos de pacientes com dados n√£o normalmente distribu√≠dos. 

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-wilcox-naopareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t de duas amostras
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
# Acrescentar 15% para o teste de Wilcoxon
63.76 * 1.15
```

Acrescentando 15% ao c√°lculo amostral realizado com o `pwr.t.test`, s√£o necess√°rias 74 amostras. Os testes n√£o param√©tricos, como o teste de Wilcoxon, geralmente apresentam menor poder estat√≠stico em compara√ß√£o aos testes param√©tricos. Para compensar essa diferen√ßa e obter um poder semelhante ao dos testes param√©tricos, recomenda-se aumentar o tamanho da amostra em cerca de 15%. Assim, o teste n√£o param√©trico passa a ter uma chance semelhante de detectar um efeito real, caso ele exista.

### Teste de Wilcoxon Pareado

**Cen√°rio:**  
Voc√™ avalia o desempenho dos mesmos alunos antes e depois de um programa de treinamento, com dados n√£o normalmente distribu√≠dos.  

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- N√≠vel de signific√¢ncia: 0.05

```{r pwr-wilcox-pareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
# Acrescentar 15% para o teste de Wilcoxon
34 * 1.15
```
Acrescentando 15% ao c√°lculo amostral realizado com o `pwr.t.test`, s√£o necess√°rias aproximadamente 40 amostras.

<!--chapter:end:15-Calculo-amostral-R.Rmd-->

# Memes de Estat√≠stica: p-valor

O p-valor √© um dos conceitos mais populares (e pol√™micos) da estat√≠stica. A seguir, veja alguns memes famosos sobre p-valor, acompanhados de interpreta√ß√µes e tradu√ß√£o para o portugu√™s.

Memes ajudam a ilustrar de forma divertida como o p-valor √© frequentemente mal interpretado ou supervalorizado. Rejeitar H0 n√£o √© tudo: pense criticamente sobre seus resultados!

## Quando voc√™ encontra um p-valor baixo e sabe que deve rejeitar H0

![Fonte: https://library.fiveable.me/ap-stats/unit-6/concluding-test-for-population-proportion/study-guide/THZeUpkm11DAwnNb6p4g](p-value4.jpg)

**Tradu√ß√£o:**  
Quando voc√™ encontra um p-valor baixo e sabe que deve rejeitar a hip√≥tese nula.

**Interpreta√ß√£o:**  
O meme brinca com o entusiasmo de muitos pesquisadores ao encontrar um p-valor baixo (menor que 0,05), pois sabem que isso permite rejeitar a hip√≥tese nula (H0). No entanto, √© importante lembrar que rejeitar H0 n√£o garante que o resultado seja relevante do ponto de vista pr√°tico ou cient√≠fico. O p-valor indica o quanto os resultados observados seriam inesperados caso a hip√≥tese nula fosse verdadeira, mas n√£o informa o tamanho ou a relev√¢ncia pr√°tica dessa diferen√ßa encontrada.

---

## Homem-Aranha apontando

![Fonte: https://danawanzer.github.io/stats-with-jamovi/alpha-p-values.html](p-value3.jpg)

**Tradu√ß√£o:**  
P < 0,05  
Rejeitar a hip√≥tese nula  
Estatisticamente significativo

**Interpreta√ß√£o:**  
Esse meme mostra como as pessoas frequentemente confundem ou usam como sin√¥nimos as express√µes "p < 0,05", "rejeitar a hip√≥tese nula" e "signific√¢ncia estat√≠stica". Na pr√°tica, s√£o conceitos relacionados, mas n√£o exatamente iguais: um p-valor menor que o n√≠vel de signific√¢ncia leva √† rejei√ß√£o de H0, o que √© chamado de resultado estatisticamente significativo. Mas lembre-se: um resultado pode ser estatisticamente significativo e, mesmo assim, n√£o ter import√¢ncia pr√°tica no mundo real.

---

## Namorado distra√≠do

![Fonte: https://imgflip.com/i/2b00xk](p-values2.jpg)

**Tradu√ß√£o:**  
p-valor 0,083  
>  
N√≠vel de signific√¢ncia 0,05

**Interpreta√ß√£o:**  
O pesquisador est√° andando tranquilamente com sua fiel companheira, o n√≠vel de signific√¢ncia 0,05, mas n√£o resiste e joga aquele olhar para o p-valor 0,083 que acabou de passar. Mesmo sabendo que, tecnicamente, 0,083 √© ‚Äúmaior‚Äù do que 0,05 e n√£o deveria chamar tanta aten√ß√£o, ele fica tentado a inventar desculpas para dar uma chance √†quele resultado quase-significativo: ‚Äúah, mas foi quase!‚Äù, ‚Äúquem nunca, n√©?‚Äù. No fundo, esse √© o t√≠pico caso do pesquisador que se empolga com resultados que chegaram perto do valor de corte, tentando transformar um ‚Äúquase‚Äù em uma grande descoberta. Mas √© importante lembrar: resultado quase significativo ainda n√£o √© significativo!

---

## Willy Wonka e o p-valor menor que 0,05

![Fonte: https://naturallyspeaking.blog/2015/06/03/episode-25-the-problem-with-p-values/](p-values1.jpg)

**Tradu√ß√£o:**  
Ah, voc√™ encontrou um p-valor menor que 0,05?  
Por favor, me conte tudo sobre sua grande descoberta.

**Interpreta√ß√£o:**  
Willy Wonka ironiza a empolga√ß√£o de quem encontra um p-valor abaixo de 0,05, sugerindo que nem sempre isso significa uma grande descoberta. O meme alerta para a import√¢ncia de interpretar o p-valor no contexto do estudo, considerando tamanho de efeito, relev√¢ncia pr√°tica e outros fatores al√©m da simples signific√¢ncia estat√≠stica. O pr√≥prio Wonka pediria: ‚Äúme conven√ßa de que seu resultado importa de verdade!‚Äù

---

## Cantada Nerd

![Fonte: https://varshitasher.medium.com/memorizing-p-value-interpretation-through-coronavirus-76e36606b5ff](p-value5.jpg)

**Tradu√ß√£o**:  
Ei, garota, seu p deve ser maior que 0,05, porque eu falho em te rejeitar.

**Interpreta√ß√£o**:  
Esse meme faz uma brincadeira rom√¢ntica usando a linguagem estat√≠stica: em vez de rejeitar a hip√≥tese nula, a pessoa est√° dizendo que n√£o consegue rejeitar a garota, assim como um p-valor acima de 0,05 geralmente significa que n√£o rejeitamos H0. √â o cl√°ssico ‚Äún√£o posso te rejeitar, cientificamente falando‚Äù! Uma piada para conquistar cora√ß√µes e estat√≠sticos ao mesmo tempo.

---

## P-valor n√£o √© tudo

![Fonte: https://x.com/data_question/status/1675416773665890304](p-value6.jpg)

**Tradu√ß√£o:**  
Cena de duas pessoas no carro, uma com express√£o de frustra√ß√£o ao ouvir "p-values", enquanto a outra est√° alegre ou satisfeita.

**Interpreta√ß√£o:**  
A gra√ßa do meme est√° justamente no contraste entre frustra√ß√£o e alegria: enquanto uma pessoa demonstra cansa√ßo ou desapontamento ao ouvir sobre p-values de novo, a outra parece satisfeita s√≥ com isso. O meme brinca com as diferentes expectativas na an√°lise estat√≠stica, h√° quem se contente apenas com a signific√¢ncia estat√≠stica (p < 0,05), enquanto outros esperam uma an√°lise completa, considerando tamb√©m o tamanho do efeito, intervalos de confian√ßa, e a real relev√¢ncia dos achados. √â um lembrete de que estat√≠stica vai al√©m do p-value!

---

## Coitado do tamanho do efeito

![](p-value9.jpg)

**Tradu√ß√£o:**  
√Ä esquerda, uma fila enorme se forma na barraca "p-values". √Ä direita, a barraca "effect sizes" est√° vazia, quase ouvindo grilos.

**Interpreta√ß√£o:**  
Este meme √© o retrato da triste (e hil√°ria) realidade dos artigos cient√≠ficos: todo mundo corre para saber se o valor de p √© menor que 0,05, como se fosse a √∫ltima coca-cola do deserto. J√° o tamanho do efeito, que realmente diz se o resultado √© relevante, √© solenemente ignorado. Moral estat√≠stica: enquanto os p-values lotam (mesmo que tragam resultados irrelevantes), o effect size fica sozinho no canto, esperando algu√©m notar sua real import√¢ncia. Quem entende estat√≠stica sabe: tamanho do efeito merece aten√ß√£o!

---

## Senhora estat√≠stica

![Fonte: https://lovestats.wordpress.com/dman/survey-research-statistics-meme/](p-value7.jpg)

**Tradu√ß√£o:**  
Em cima: "ONE DOES NOT SIMPLY" ("SIMPLESMENTE N√ÉO SE...")
Embaixo: "REPORT P-VALUES WITHOUT EFFECT SIZES" ("RELATA P-VALORES SEM TAMANHOS DE EFEITO")

**Interpreta√ß√£o:**  
Esse meme faz refer√™ncia ao cl√°ssico da cultura pop (Senhor dos Aneis) para lembrar que estat√≠stica n√£o √© terra sem lei: n√£o basta encontrar um p < 0,05 e sair comemorando. Relatar apenas o valor de p √© igual a contar s√≥ metade da fofoca: falta o contexto! O tamanho do efeito √© quem diz se a diferen√ßa √© daquelas que mudam a vida ou se √© s√≥ uma diferen√ßa microsc√≥pica e irrelevante. Em outras palavras, estat√≠stica de verdade combina significado estat√≠stico (p-value) com significado pr√°tico (effect size). N√£o fa√ßa estat√≠stica ‚Äúpela metade‚Äù!

---

## Pobi do gatinho

![Fonte: https://x.com/Jente_O/status/1698942647493153251](p-value8.jpg)

**Tradu√ß√£o:**  
Primeira cena: Pessoa abra√ßa um cachorro chamado ‚ÄúP-VALUES‚Äù. Atr√°s, um gato (effect sizes) observa, exclu√≠do.  
Demais cenas: Close no gato ‚Äúeffect sizes‚Äù, visivelmente triste, segurando um brinquedo, ignorado.

**Interpreta√ß√£o:**  
O meme mostra o drama dos tamanhos de efeito: sempre deixados de lado, enquanto os p-values recebem todo o carinho e aten√ß√£o. √â como se o cachorro (p-value) ganhasse petiscos s√≥ por latir, enquanto o gato (effect size), que realmente entrega o conte√∫do, s√≥ observa de longe. Estatisticamente, √© como celebrar um resultado significativo sem saber se ele realmente importa no mundo real. O gato chora, e o revisor do artigo tamb√©m!

---

Esses memes ilustram, com bom humor, que o p-valor sozinho n√£o conta toda a hist√≥ria. Um resultado estatisticamente significativo n√£o garante relev√¢ncia pr√°tica. O tamanho do efeito √© fundamental para avaliar se uma diferen√ßa observada tem impacto real, e n√£o apenas estat√≠stico. Ao analisar dados, valorize tanto o p-valor quanto o tamanho do efeito para conclus√µes mais robustas e informativas.

<!--chapter:end:16-Memes.Rmd-->

# Pacotes `pwr`, `rstatix` e `effsize`

Nesse cap√≠tulo, abordaremos como calcular tamanho de amostra, poder estat√≠stico e tamanho do efeito em diferentes testes estat√≠sticos usando os pacotes `pwr`, `rstatix` e `effsize`. O foco ser√° nos testes t (pareado e n√£o pareado) e Wilcoxon (pareado e n√£o pareado), com exemplos pr√°ticos e orienta√ß√µes sobre interpreta√ß√£o dos resultados.

> **Importante:** Antes de come√ßar, certifique-se de instalar o pacote `pwr`, `rstatix` e `effsize`:
```r
install.packages(c("pwr", "rstatix", "effsize"))
```

## C√°lculos de tamanho de amostra, poder e efeito com o pacote `pwr`

O pacote `pwr` permite calcular:

- **Tamanho de amostra** necess√°rio para detectar um determinado efeito;
- **Poder estat√≠stico** de um teste para amostras de tamanho fixo;
- **Menor tamanho de efeito** que pode ser detectado para um dado poder e amostra.

### Exerc√≠cio 1: Tamanho da amostra para teste t n√£o pareado

Calcule o tamanho da amostra necess√°rio para detectar um efeito moderado (d = 0.5), com poder de 0.8 e n√≠vel de signific√¢ncia de 0.05, em um teste t bilateral para duas amostras independentes.

```{r n-tnpcal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t n√£o pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```

---

### Exerc√≠cio 2: Poder do teste t n√£o pareado para n fixo

Se voc√™ disp√µe de 26 observa√ß√µes em cada grupo, qual √© o poder do teste para detectar um efeito de 0.5, com sig.level = 0.05?

```{r p-tnpcal, message=FALSE,  warning=FALSE}
# Poder do teste t n√£o pareado para n = 26 por grupo
pwr.t.test(n = 26, d = 0.5, sig.level = 0.05, type = "two.sample")
```

---

### Exerc√≠cio 3: Menor efeito detect√°vel no teste t n√£o pareado

Com 26 observa√ß√µes por grupo, poder de 0.8 e sig.level de 0.05, qual o menor tamanho de efeito detect√°vel?

```{r d-tnpcal, message=FALSE,  warning=FALSE}
# Tamanho do efeito detect√°vel
pwr.t.test(n = 26, power = 0.8, sig.level = 0.05, type = "two.sample")
```

---

### Exerc√≠cio 4: Repita para outros testes

#### a) Teste t pareado

```{r n-tpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")

# Poder para n = 26 pares
pwr.t.test(n = 26, d = 0.5, sig.level = 0.05, type = "paired")

# Tamanho do efeito detect√°vel
pwr.t.test(n = 26, power = 0.8, sig.level = 0.05, type = "paired")
```

#### b) Wilcoxon n√£o pareado

```{r n-wnpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para Wilcoxon n√£o pareado (aproxima√ß√£o pelo teste t)
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```

> **Dica:** O pacote `pwr` n√£o possui fun√ß√µes espec√≠ficas para testes n√£o-param√©tricos como Wilcoxon. Por isso, costuma-se usar o c√°lculo para teste t como aproxima√ß√£o, aumentando o tamanho da amostra em cerca de 15% (multiplique o valor obtido por 1,15), j√° que testes n√£o-param√©tricos geralmente requerem amostras maiores para o mesmo poder estat√≠stico.

```{r p-wnpcal, message=FALSE,  warning=FALSE}
# Recalculando o tamanho da amostra
63.76561*1.15
```

> O *tamanho do efeito para o teste de Wilcoxon* pode ser aproximado *por d √ó 0,86*, sendo d o tamanho do efeito de Cohen, desde que as distribui√ß√µes dos grupos sejam aproximadamente normais e com vari√¢ncias semelhantes (Lehmann, 2006; Noether, 1987).

```{r e-wnpcal, message=FALSE,  warning=FALSE}
# Poder da amostra para Wilcoxon n√£o pareado (aproxima√ß√£o pelo teste t)
pwr.t.test(n = 26, d = 0.5*0.86, sig.level = 0.05, type = "two.sample")
```

#### c) Wilcoxon pareado

```{r n-wpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para Wilcoxon pareado (aproxima√ß√£o pelo teste t pareado)
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
```

```{r p-wpcal, message=FALSE,  warning=FALSE}
# Poder da amostra para Wilcoxon n√£o pareado (aproxima√ß√£o pelo teste t)
pwr.t.test(n = 26, d = 0.5*0.86, sig.level = 0.05, type = "two.sample")
```

> **Aten√ß√£o:** O **d de Cohen** foi criado para testes param√©tricos, como o teste t. Para testes n√£o param√©tricos (Wilcoxon), utilize medidas espec√≠ficas, pois a interpreta√ß√£o do d n√£o se aplica ao contexto de ranks.

---

### Argumentos principais da fun√ß√£o `pwr.t.test()`

A fun√ß√£o `pwr.t.test()` possui os seguintes argumentos principais:

- `n`: tamanho da amostra em cada grupo (ou n√∫mero de pares, para teste pareado)
- `d`: tamanho do efeito (diferen√ßa padronizada entre grupos)
- `power`: poder estat√≠stico desejado
- `sig.level`: n√≠vel de signific√¢ncia (geralmente 0.05)
- `type`: tipo de teste t: `"two.sample"`, `"paired"` ou `"one.sample"`

> **Dica:** Deixe como `NULL` o par√¢metro que voc√™ deseja calcular.
> - Para calcular o tamanho do efeito: `d = NULL`
> - Para calcular o poder: `power = NULL`
> - Para calcular o tamanho da amostra: `n = NULL`

**Exemplo para calcular o tamanho do efeito:**
```r
pwr.t.test(n = 26, d = NULL, power = 0.8, sig.level = 0.05, type = "two.sample")
```
Neste exemplo, o argumento `d` √© o valor a ser calculado.

---

### Grupos Desbalanceados: usando `pwr.t2n.test()`

Quando os grupos t√™m tamanhos diferentes, use `pwr.t2n.test()` para calcular o poder.

```{r pwr-2ncal, message=FALSE,  warning=FALSE}
# Exemplo: grupo 1 com 95, grupo 2 com 30 observa√ß√µes
library(pwr)
pwr.t2n.test(n1 = 95, n2 = 30, d = 0.5, sig.level = 0.05)
```

- **n1**: tamanho do primeiro grupo
- **n2**: tamanho do segundo grupo

**Aten√ß√£o:** Grupos desbalanceados podem comprometer o poder do teste, aumentar a vari√¢ncia e dificultar a interpreta√ß√£o dos resultados. Sempre que poss√≠vel, busque amostras equilibradas.

---

## Tamanho do efeito em testes de Wilcoxon

O tamanho do efeito complementa a an√°lise estat√≠stica, indicando a magnitude da diferen√ßa entre grupos. Para testes param√©tricos (como o t), usa-se o **d de Cohen**. Para testes n√£o param√©tricos (Wilcoxon), utilize medidas apropriadas, como **r de Wilcoxon** e **Delta de Cliff**.

### Por que N√ÉO usar d de Cohen no Wilcoxon?

- O d de Cohen pressup√µe distribui√ß√£o normal e compara√ß√£o direta de m√©dias/desvios.
- O Wilcoxon compara **ranks**, n√£o m√©dias.
- Aplicar o d de Cohen em dados de Wilcoxon pode gerar interpreta√ß√µes erradas.

### Medidas recomendadas para Wilcoxon:

- **r de Wilcoxon:** Calculado com o pacote `rstatix`.
- **Cliff‚Äôs Delta:** Dispon√≠vel no pacote `effsize`.

---

#### r de Wilcoxon (Wilcoxon rank-sum, n√£o pareado)

```{r rWilcoxcal, eval=TRUE, message=FALSE,  warning=FALSE}
library(rstatix)
library(readr)

# Importe o banco de dados Pokemon
Pokemon <- read_csv("Pokemon.csv")

# Subconjunto com Pok√©mons verdes ou amarelos
dados_filtrados <- subset(Pokemon, Color %in% c("Green", "Yellow"))

# Verifique os dados ap√≥s o filtro
print(table(dados_filtrados$Color))

# Boxplot
boxplot(dados_filtrados$Speed ~ dados_filtrados$Color)

# Teste de Wilcoxon n√£o pareado
wilcox.test(dados_filtrados$Speed ~ dados_filtrados$Color)

# Tamanho do efeito r de Wilcoxon para Green vs Yellow
wilcox_effsize(dados_filtrados, Speed ~ Color)

levels(dados_filtrados$Color)
```

A tabela apresentada √© resultado da fun√ß√£o `wilcox_effsize()` do pacote `rstatix` e resume o tamanho do efeito (r de Wilcoxon) para a compara√ß√£o entre dois grupos ("Green" e "Yellow") em rela√ß√£o √† vari√°vel "Speed". Veja como interpretar cada coluna:

- **.y.**: vari√°vel de interesse analisada, neste caso, "Speed" (velocidade dos Pok√©mons).
- **group1**: primeiro grupo comparado ("Green").
- **group2**: segundo grupo comparado ("Yellow").
- **effsize**: valor ABSOLUTO do tamanho de efeito calculado, aqui 0.206.  
- O resultado apresentado na coluna `effsize` √© sempre positivo, independentemente da ordem dos grupos definidos na vari√°vel categ√≥rica.
- **n1**: n√∫mero de observa√ß√µes no grupo 1 (79 Pok√©mons verdes).
- **n2**: n√∫mero de observa√ß√µes no grupo 2 (64 Pok√©mons amarelos).
- **magnitude**: classifica√ß√£o qualitativa do tamanho de efeito ("small", ou seja, efeito pequeno).

**Interpreta√ß√£o:**  
A diferen√ßa de velocidade entre Pok√©mons verdes e amarelos √© estatisticamente significativa (W = 1920.5, p-value = 0.01363), por√©m de **pequena magnitude** (r = 0.206). Isso indica que, embora exista uma diferen√ßa, ela √© discreta do ponto de vista pr√°tico.



> No caso de teste pareado, acrescente o argumento `paired = TRUE`:
> ```r
> wilcox_effsize(dados, antes ~ depois, paired = TRUE)
> ```

---

#### Delta de Cliff

```{r, DCliffcal, message=FALSE, warning=FALSE}
library(effsize)

# Calcule o Delta de Cliff
cliff.delta(dados_filtrados$Speed ~ dados_filtrados$Color)
```

O **Delta de Cliff** estimado foi de **-0,24**, classificado como efeito **pequeno** ("small"). O intervalo de confian√ßa de 95% vai de aproximadamente **-0,41** a **-0,05**, indicando que, com alta confian√ßa, o efeito verdadeiro √© negativo e pequeno.

- **Sinal negativo:** Indica que o grupo "Yellow" tende a apresentar velocidades maiores do que o grupo "Green". Ou seja, ao comparar aleatoriamente um Pok√©mon amarelo com um verde, √© mais prov√°vel que o amarelo tenha uma velocidade superior.
- **Magnitude pequena:** O valor absoluto de -0,24 mostra que a diferen√ßa entre os grupos existe, mas √© de pouca relev√¢ncia pr√°tica.
- **Intervalo de confian√ßa n√£o inclui zero:** Como o intervalo vai de -0,41 a -0,05, podemos afirmar que existe uma diferen√ßa real entre os grupos, embora seja pequena.
- **Interpreta√ß√£o pr√°tica:** Apesar de haver uma diferen√ßa estat√≠stica, ela n√£o √© marcante. √â importante avaliar se essa diferen√ßa tem relev√¢ncia biol√≥gica ou pr√°tica no contexto do seu estudo.

O Delta de Cliff indica que Pok√©mons amarelos tendem a ser um pouco mais r√°pidos do que os verdes, mas a diferen√ßa √© pequena do ponto de vista pr√°tico.


### Compara√ß√£o entre o r de Wilcoxon e o Delta de Cliff

Quando realizamos testes n√£o param√©tricos para comparar grupos, como o teste de Wilcoxon (Mann-Whitney ou Wilcoxon pareado), √© importante complementar o resultado do teste com uma medida de tamanho de efeito. As duas op√ß√µes mais comuns s√£o o **r de Wilcoxon** e o **Delta de Cliff**. Veja a seguir uma compara√ß√£o entre elas:

### r de Wilcoxon

- **Defini√ß√£o:** Mede a magnitude da diferen√ßa entre grupos com base nos postos (ranks) dos dados. O c√°lculo √© semelhante ao coeficiente de correla√ß√£o de Pearson, mas aplicado a dados n√£o param√©tricos.
- **Varia√ß√£o dos valores:** O r de Wilcoxon varia de -1 a 1.
  - Valores pr√≥ximos de 0 indicam pouca diferen√ßa entre grupos.
  - Valores pr√≥ximos de -1 ou 1 indicam diferen√ßas muito grandes.
  - O sinal indica a dire√ß√£o da diferen√ßa.

**Qualifica√ß√£o dos valores**, segundo Cohen (1988):

| Valor absoluto de $r$ | Interpreta√ß√£o    |
|:---------------------|:----------------|
| aproximadamente 0,10                | Pequeno         |
| aproximadamente 0,30                | Moderado        |
| maior ou igual 0,50                | Grande          |

**Exemplos:**

- **Efeito pequeno:**  
  Se o valor absoluto de r estiver pr√≥ximo de **0,10**, a diferen√ßa entre os grupos √© pequena.  
  _(Exemplo: |r| = 0,10 ‚Üí efeito pequeno)_

- **Efeito moderado:**  
  Se o valor absoluto de r estiver pr√≥ximo de **0,30**, a diferen√ßa entre os grupos √© moderada.  
  _(Exemplo: |r| = 0,30 ‚Üí efeito moderado)_

- **Efeito grande:**  
  Se o valor absoluto de r for igual ou superior a **0,50**, a diferen√ßa √© grande.  
  _(Exemplo: |r| = 0,55 ‚Üí efeito grande)_



### Delta de Cliff ($\delta$) 

- **Defini√ß√£o:** Mede a probabilidade de um valor de um grupo ser maior do que de outro grupo, subtra√≠da da probabilidade contr√°ria. √â totalmente n√£o param√©trico e n√£o depende de distribui√ß√£o, sendo adequado para vari√°veis ordinais ou dados assim√©tricos.
- **Varia√ß√£o dos valores:** O Delta de Cliff varia de -1 a 1.
    - Valor 0: n√£o h√° diferen√ßa entre os grupos.
    - Valor positivo: o grupo 1 tende a ter valores maiores que o grupo 2.
    - Valor negativo: o grupo 2 tende a ter valores maiores que o grupo 1.
- **Como interpretar os valores do Delta de Cliff?**  
  O **Delta de Cliff** mostra o tamanho da diferen√ßa entre dois grupos. O mais comum √© considerar o valor absoluto de $\delta$ (ou seja, ignorar se √© positivo ou negativo e olhar s√≥ para o tamanho do n√∫mero).

**Classifica√ß√£o da magnitude do efeito**, segundo Romano et al. (2006)

| Valor absoluto de $\delta$ | Interpreta√ß√£o    |
|:--------------------------|:----------------|
| menor que 0.147                    | Desprez√≠vel     |
| de 0.147 e menor que 0.33             | Pequeno         |
| de 0.33 e menor que 0.474             | M√©dio           |
| maior ou igual a 0.474                    | Grande          |

**Exemplos:**

- **Efeito desprez√≠vel:**  
  Se o valor absoluto do delta for menor que **0,147**, a diferen√ßa entre os grupos √© desprez√≠vel.  
  _(Exemplo: |$\delta$| = 0,10 ‚Üí efeito desprez√≠vel)_

- **Efeito pequeno:**  
  Se o valor absoluto do delta for igual ou maior que **0,147** e menor que **0,33**, a diferen√ßa √© pequena.  
  _(Exemplo: |$\delta$| = 0,20 ‚Üí efeito pequeno)_

- **Efeito m√©dio:**  
  Se o valor absoluto do delta for igual ou maior que **0,33** e menor que **0,474**, a diferen√ßa √© m√©dia.  
  _(Exemplo: |$\delta$| = 0,40 ‚Üí efeito m√©dio)_

- **Efeito grande:**  
  Se o valor absoluto do delta for igual ou maior que **0,474**, a diferen√ßa √© grande.  
  _(Exemplo: |$\delta$| = 0,50 ‚Üí efeito grande)_

**Resumindo:**  
Quanto mais pr√≥ximo de zero, menor a diferen√ßa. Quanto mais pr√≥ximo de 1 (ou -1), maior a diferen√ßa entre os grupos.

> **Dica:** Sempre use o valor absoluto, ou seja, olhe apenas para o tamanho do n√∫mero, sem se preocupar se ele √© positivo ou negativo.


### Qual √© melhor usar?

- **Ambos** s√£o v√°lidos e amplamente aceitos para dados n√£o param√©tricos.
- O **r de Wilcoxon** √© intuitivo se voc√™ j√° est√° acostumado com o coeficiente de correla√ß√£o, e √© facilmente interpret√°vel em contextos onde se deseja uma analogia ao r de Pearson.
- O **Delta de Cliff** √© mais robusto em situa√ß√µes com muitos empates, diferentes tamanhos de grupo ou dados ordinais, e fornece uma interpreta√ß√£o mais direta da diferen√ßa de probabilidades entre grupos.
- **Recomenda√ß√£o pr√°tica:**  
  - Para estudos com dados ordenados, amostras desbalanceadas ou muitos empates, o Delta de Cliff pode ser preferido.
  - Se voc√™ busca uma medida an√°loga ao r de Pearson para facilitar compara√ß√µes, use o r de Wilcoxon.
  - Em muitos casos, apresentar ambos os valores enriquece a interpreta√ß√£o dos resultados.

N√£o existe uma medida "melhor" de forma absoluta; a escolha depende do contexto do estudo e das caracter√≠sticas dos dados. Ambas s√£o √∫teis para interpretar a relev√¢ncia pr√°tica das diferen√ßas identificadas em testes n√£o param√©tricos.


> **Nota:** Para a compara√ß√£o entre os grupos *Green* e *Yellow* na vari√°vel *Speed*, o tamanho de efeito calculado pelo **r de Wilcoxon** foi **0,206** (efeito pequeno), enquanto o **delta de Cliff** foi **-0,240** (efeito pequeno, IC 95%: -0,414 a -0,050). √â esperado que os valores num√©ricos dessas m√©tricas diferem, pois s√£o baseados em c√°lculos estat√≠sticos distintos, mas ambos apontam para uma diferen√ßa de pequena magnitude entre os grupos.

No entanto, √© importante destacar que, neste caso, o valor negativo do delta de Cliff est√° condizente com o observado no boxplot: o grupo *Yellow* tende a apresentar valores de *Speed* ligeiramente maiores que o grupo *Green*, o que √© evidenciado pela dire√ß√£o negativa do delta. 

Esse alinhamento entre o resultado num√©rico do delta de Cliff e a visualiza√ß√£o gr√°fica refor√ßa a import√¢ncia de sempre analisar os dados de forma complementar, utilizando tanto medidas estat√≠sticas quanto representa√ß√µes visuais (como boxplots). A visualiza√ß√£o gr√°fica pode revelar padr√µes, tend√™ncias e assimetrias que enriquecem a interpreta√ß√£o do tamanho de efeito e facilitam a comunica√ß√£o dos resultados.

<!--chapter:end:17-Exercicios-pwr.Rmd-->

# Teste de Normalidade

Antes de aplicar muitos testes estat√≠sticos, √© importante verificar se os dados seguem uma distribui√ß√£o normal (ou "distribui√ß√£o gaussiana"). Essa etapa √© fundamental porque v√°rios testes param√©tricos (como o teste t de Student e a ANOVA) assumem a normalidade dos dados. Quando essa condi√ß√£o n√£o √© atendida, a escolha do teste estat√≠stico pode mudar para op√ß√µes n√£o param√©tricas.

## Hip√≥teses nos Testes de Normalidade

Todo teste de normalidade avalia as seguintes hip√≥teses:

- **Hip√≥tese Nula (H‚ÇÄ):** Os dados seguem uma distribui√ß√£o normal.
- **Hip√≥tese Alternativa (H‚ÇÅ):** Os dados **n√£o** seguem uma distribui√ß√£o normal.

- Se o valor de p for menor que 0,05: **Rejeitamos** a hip√≥tese nula.
 
- Se o valor de p for maior ou igual 0,05: **N√£o rejeitamos** a hip√≥tese nula. 

## Principais Testes de Normalidade

Abaixo est√£o os testes de normalidade mais conhecidos, quando s√£o mais recomendados e os pacotes em R:

| Teste             | Quando Usar                                      | Pacote no R    |
|-------------------|--------------------------------------------------|----------------|
| **Shapiro-Wilk**  | Amostras pequenas e m√©dias (n < 50 at√© ~ 2000)   | `stats`        |
| **Kolmogorov-Smirnov (K-S)** | Amostras maiores; pode comparar duas distribui√ß√µes, mas menos potente para normalidade | `stats`        |
| **Lilliefors**    | Vers√£o do K-S ajustado para m√©dia e desvio amostrais | `nortest`      |
| **Anderson-Darling** | Mais sens√≠vel nas caudas da distribui√ß√£o; recomendado para m√©dias e grandes amostras | `nortest`      |
| **Jarque-Bera**   | Teste baseado em assimetria (skewness) e curtose (kurtosis); comum em econometria | `tseries`      |
| **D‚ÄôAgostino-Pearson** | Avalia assimetria e curtose em conjunto; recomendado para m√©dias e grandes amostras | `moments`      |

### Dicas de Uso

- Para **amostras pequenas** (n < 50): prefira o **Shapiro-Wilk** (fun√ß√£o `shapiro.test()` do pacote base `stats`).
- Para **amostras m√©dias a grandes**: considere **Anderson-Darling** (`ad.test()` do pacote `nortest`) ou **D‚ÄôAgostino-Pearson** (`agostino.test()` do pacote `moments`).
- O **Kolmogorov-Smirnov** (`ks.test()`) √© mais geral, mas menos recomendado quando a m√©dia e desvio padr√£o s√£o estimados dos pr√≥prios dados.
- O **Lilliefors** (`lillie.test()` do pacote `nortest`) √© uma boa alternativa ao K-S para dados amostrais.
- Para an√°lises em econometria ou s√©ries temporais, o **Jarque-Bera** (`jarque.bera.test()` do pacote `tseries`) √© bastante utilizado.

### Exemplo Pr√°tico em R

```{r, testenormex, message=FALSE, warning=FALSE}

#install.packages("nortest")
#install.packages("moments")

# Importe o banco de dados Pokemon
library(readr)
Pokemon <- read_csv("Pokemon.csv")

# Veja o QQ
qqnorm(Pokemon$Speed)
qqline(Pokemon$Speed)


# Shapiro-Wilk
shapiro.test(Pokemon$Speed)

# Anderson-Darling
library(nortest)
ad.test(Pokemon$Speed)

# Lilliefors
lillie.test(Pokemon$Speed)

# D'Agostino
library(moments)
agostino.test(Pokemon$Speed)

```

**Resumo**

- Sempre comece analisando a normalidade dos seus dados.
- Escolha o teste de acordo com o tamanho da amostra e o objetivo da an√°lise.
- **Use gr√°ficos (histograma, boxplot e principalmente o QQ) junto com testes estat√≠sticos para uma an√°lise mais completa.**

> **Importante:** Testes de normalidade s√£o sens√≠veis ao tamanho da amostra. Em amostras muito grandes, pequenas desvios podem resultar em p-valores baixos; em amostras pequenas, a pot√™ncia dos testes √© baixa.


## Assimetria e Curtose: O que s√£o e por que s√£o importantes?

Quando analisamos dados, √© importante entender n√£o s√≥ a m√©dia e o desvio padr√£o, mas tamb√©m o **formato da distribui√ß√£o** dos valores. Duas medidas ajudam muito nisso: **assimetria** e **curtose**. Vamos entender cada uma de forma simples:

---

### O que √© Assimetria (Skewness)?

A **assimetria** mostra se os dados est√£o ‚Äúpuxados‚Äù para algum lado, ou seja, se a distribui√ß√£o tem uma cauda maior para a direita ou para a esquerda.

- **Assimetria zero:** Os dados est√£o distribu√≠dos de forma equilibrada ao redor da m√©dia (exemplo: distribui√ß√£o normal perfeita).
- **Assimetria positiva (√† direita):** A cauda √© mais longa √† direita, ou seja, h√° mais valores extremos acima da m√©dia.
- **Assimetria negativa (√† esquerda):** A cauda √© mais longa √† esquerda, h√° mais valores extremos abaixo da m√©dia.

**Por que isso importa?**  
A distribui√ß√£o Normal √© um exemplo de distribui√ß√£o sim√©trica.

### O que √© Curtose (Kurtosis)?

A **curtose** indica o quanto a distribui√ß√£o √© ‚Äúpontuda‚Äù ou ‚Äúachatada‚Äù em rela√ß√£o √† Distribui√ß√£o Normal.

- **Curtose alta (leptoc√∫rtica):** Distribui√ß√£o muito ‚Äúpontuda‚Äù, com muitas observa√ß√µes pr√≥ximas da m√©dia, mas tamb√©m mais valores extremos (outliers).
- **Curtose baixa (platic√∫rtica):** Distribui√ß√£o mais achatada, com menos valores extremos.
- **Curtose m√©dia (mesoc√∫rtica):** Parecida com a distribui√ß√£o normal.

**Por que isso importa?**  
A presen√ßa de muita curtose (valores muito altos ou baixos) pode indicar que h√° mais outliers do que o esperado, o que tamb√©m pode afetar os resultados de testes estat√≠sticos.

- **Assimetria:** mostra se a distribui√ß√£o ‚Äúpende‚Äù para um lado.
- **Curtose:** mostra se a distribui√ß√£o √© ‚Äúpontuda‚Äù e cheia de extremos, ou mais ‚Äúachatada‚Äù.

Essas duas medidas ajudam a entender melhor o comportamento dos seus dados e garantem que voc√™ escolha os testes estat√≠sticos mais adequados para a sua an√°lise!

<!--chapter:end:18-testedenormalidade.Rmd-->

# Compara√ß√£o de mais de dois grupos

Assim como na compara√ß√£o entre dois grupos, ao desejarmos comparar mais de dois grupos em uma an√°lise estat√≠stica, √© fundamental selecionar o teste mais adequado de acordo com as caracter√≠sticas dos dados. Os testes podem ser **param√©tricos** ou **n√£o param√©tricos**, e a escolha correta depende da verifica√ß√£o pr√©via de alguns pressupostos, como normalidade, homogeneidade de vari√¢ncias e independ√™ncia das observa√ß√µes.

## Revisando as hip√≥teses da compara√ß√£o entre dois grupos

- **Param√©trico (Teste t)**
  - **N√£o pareado (t de Student):**
    - H‚ÇÄ: As m√©dias dos dois grupos s√£o iguais (Œº‚ÇÅ = Œº‚ÇÇ)
    - H‚ÇÅ: As m√©dias dos dois grupos s√£o diferentes (Œº‚ÇÅ ‚â† Œº‚ÇÇ)
  - **Pareado (t pareado):**
    - H‚ÇÄ: A m√©dia das diferen√ßas entre os pares √© igual a zero (Œº_d = 0)
    - H‚ÇÅ: A m√©dia das diferen√ßas entre os pares √© diferente de zero (Œº_d ‚â† 0)

- **N√£o param√©trico**
  - **N√£o pareado (Mann-Whitney/Wilcoxon rank-sum):**
    - H‚ÇÄ: As distribui√ß√µes dos dois grupos s√£o iguais
    - H‚ÇÅ: As distribui√ß√µes dos dois grupos s√£o diferentes
  - **Pareado (Wilcoxon signed-rank):**
    - H‚ÇÄ: A distribui√ß√£o das diferen√ßas entre os pares √© sim√©trica em torno de zero
    - H‚ÇÅ: A distribui√ß√£o das diferen√ßas entre os pares n√£o √© sim√©trica em torno de zero
  
Na compara√ß√£o entre **dois grupos**, tanto nos testes param√©tricos quanto nos n√£o param√©tricos, a hip√≥tese nula (H‚ÇÄ) geralmente afirma que as m√©dias (ou distribui√ß√µes) dos dois grupos s√£o iguais, enquanto a hip√≥tese alternativa (H‚ÇÅ) aponta que elas s√£o diferentes. Ou seja, o teste busca identificar uma diferen√ßa espec√≠fica entre os dois grupos analisados.

## Hip√≥teses para a compara√ß√£o entre mais de dois grupos

- **Param√©trico (ANOVA)**
  - **N√£o pareado (ANOVA one-way):**
    - H‚ÇÄ: As m√©dias dos grupos s√£o todas iguais (Œº‚ÇÅ = Œº‚ÇÇ = ... = Œº_k)
    - H‚ÇÅ: Pelo menos uma m√©dia de grupo √© diferente das outras
  - **Pareado (ANOVA de medidas repetidas):**
    - H‚ÇÄ: As m√©dias dos tratamentos (ou condi√ß√µes) s√£o iguais
    - H‚ÇÅ: Pelo menos uma m√©dia de tratamento √© diferente das outras

- **N√£o param√©trico**
  - **N√£o pareado (Kruskal-Wallis):**
    - H‚ÇÄ: As distribui√ß√µes dos grupos s√£o todas iguais
    - H‚ÇÅ: Pelo menos uma distribui√ß√£o de grupo √© diferente das outras
  - **Pareado (Friedman):**
    - H‚ÇÄ: As distribui√ß√µes dos tratamentos (ou condi√ß√µes) s√£o todas iguais
    - H‚ÇÅ: Pelo menos uma distribui√ß√£o de tratamento √© diferente das outras
    
Na compara√ß√£o entre **mais de dois grupos** (por exemplo, usando ANOVA ou Kruskal-Wallis), a hip√≥tese nula (H‚ÇÄ) √© que **todas** as m√©dias (ou distribui√ß√µes) dos grupos s√£o iguais. Por outro lado, a hip√≥tese alternativa (H‚ÇÅ) n√£o especifica qual grupo √© diferente, mas sim que **pelo menos um dos grupos se difere dos demais**. Ou seja, a rejei√ß√£o da hip√≥tese nula indica que existe pelo menos uma diferen√ßa, mas n√£o revela imediatamente entre quais grupos essa diferen√ßa ocorre.

> **Aten√ß√£o:** √â importante notar que, no contexto de mais de dois grupos, a hip√≥tese alternativa n√£o identifica quais grupos s√£o diferentes, apenas aponta que existe pelo menos uma diferen√ßa.

## Testes Param√©tricos

- **N√£o Pareados:**  O teste mais utilizado √© a **ANOVA de uma via**, que compara as m√©dias de tr√™s ou mais grupos independentes.
- **Pareados:** Utiliza-se a **ANOVA para medidas repetidas** quando as medi√ß√µes s√£o feitas nos mesmos indiv√≠duos em diferentes condi√ß√µes ou tempos.

### Pr√©-requisitos para ANOVA (dados pareados ou n√£o)

1. **Normalidade dos res√≠duos:** Os res√≠duos do modelo devem seguir uma distribui√ß√£o normal.
2. **Homogeneidade de vari√¢ncias:** As vari√¢ncias dos grupos devem ser semelhantes.
3. **Esfericidade** (apenas para medidas repetidas): A vari√¢ncia das diferen√ßas entre todas as combina√ß√µes de pares de grupos deve ser semelhante.
4. **Independ√™ncia das observa√ß√µes:** Para grupos independentes.

Se algum desses pr√©-requisitos n√£o for atendido, √© recomendado utilizar testes n√£o param√©tricos.

## Testes N√£o Param√©tricos

- **N√£o Pareados:** O teste de **Kruskal-Wallis** √© utilizado para comparar mais de dois grupos independentes.
- **Pareados:** O teste de **Friedman** √© usado para comparar tr√™s ou mais grupos pareados.


## ANOVA de uma via no R

A seguir, apresentamos um exemplo de ANOVA de uma via e do teste de Kruskal-Wallis, incluindo a verifica√ß√£o dos pr√©-requisitos.

### Simula√ß√£o de Dados

```{r dadosAnovatest, message=FALSE,  warning=FALSE}
set.seed(123)
grupo <- factor(rep(c("A", "B", "C"), each = 10))
valor <- c(rnorm(10, mean = 5, sd = 1),
           rnorm(10, mean = 6, sd = 1),
           rnorm(10, mean = 7, sd = 1))
dados <- data.frame(grupo, valor)
```

### Visualiza√ß√£o dos Dados

```{r boxplotAnovabp, message=FALSE,  warning=FALSE}
boxplot(valor ~ grupo, data = dados, main = "Boxplot dos Grupos", ylab = "Valor")
```

### Verifica√ß√£o dos Pr√©-requisitos para ANOVA

#### Normalidade dos res√≠duos

```{r residuosAnovatest, message=FALSE,  warning=FALSE}
modelo_aov <- aov(valor ~ grupo, data = dados)
residuos <- residuals(modelo_aov)

shapiro.test(residuos)
qqnorm(residuos)
qqline(residuos)
```

- A fun√ß√£o `aov` no R √© utilizada para realizar **an√°lise de vari√¢ncia (ANOVA)**.

- **modelo_aov <- aov(valor ~ grupo, data = dados)**  
  Esta linha ajusta um modelo de ANOVA de uma via, avaliando se a m√©dia da vari√°vel `valor` difere entre os diferentes n√≠veis do fator `grupo`, usando os dados do data frame `dados`.

- **residuos <- residuals(modelo_aov)**  
  Esta linha extrai os res√≠duos do modelo ajustado, ou seja, as diferen√ßas entre os valores observados e os valores previstos pelo modelo. A an√°lise dos res√≠duos √© fundamental para verificar os pressupostos da ANOVA, como a normalidade.
  
> Neste exemplo, tanto o teste de normalidade quanto a inspe√ß√£o visual do gr√°fico QQ sugerem que os res√≠duos seguem uma distribui√ß√£o normal.

#### Homogeneidade de vari√¢ncias

```{r leveneAnovatest, message=FALSE,  warning=FALSE}
# Instale 'car' se necess√°rio: install.packages("car")
library(car)
leveneTest(valor ~ grupo, data = dados)
```

- O *teste de Levene* avalia a homogeneidade das vari√¢ncias entre os grupos, que √© um dos pr√©-requisitos para a ANOVA.

- **Valor de p (Pr(>F)) = 0.9995:** O valor de p √© muito maior que 0,05, indicando que **n√£o h√° evid√™ncias para rejeitar a hip√≥tese nula de igualdade das vari√¢ncias**.

> Nesse exemplo, as vari√¢ncias dos grupos podem ser consideradas homog√™neas. Portanto, o pr√©-requisito de homogeneidade de vari√¢ncias para a ANOVA foi atendido.

### ANOVA de Uma Via

```{r Anovatest, message=FALSE,  warning=FALSE}
summary(modelo_aov)
```

- **Valor de p (Pr(>F)) = 0.00518:** O valor de p √© menor que 0,05, indicando que existem diferen√ßas estatisticamente significativas entre as m√©dias dos grupos analisados.

- Rejeita-se a hip√≥tese nula de igualdade das m√©dias. Isso significa que pelo menos um dos grupos difere significativamente dos demais. Recomenda-se realizar *testes post hoc (por exemplo, Tukey)* para identificar quais grupos apresentam diferen√ßas entre si.

#### Teste Post Hoc (se ANOVA for significativa)

```{r TukeyHSDtest, message=FALSE,  warning=FALSE}
TukeyHSD(modelo_aov)
```

O teste de Tukey compara as m√©dias dos grupos dois a dois, ap√≥s a ANOVA indicar diferen√ßa significativa entre eles. Os resultados mostram as diferen√ßas entre as m√©dias dos grupos (`diff`), os limites inferior (`lwr`) e superior (`upr`) do intervalo de confian√ßa de 95%, e o valor de p ajustado (`p adj`).

**Resultados:**

- **B vs A:**  
  Diferen√ßa = 1.13; IC 95% = [0.05, 2.22]; p = 0.038  
  ‚Üí O grupo B tem m√©dia significativamente maior que o grupo A.

- **C vs A:**  
  Diferen√ßa = 1.50; IC 95% = [0.42, 2.58]; p = 0.005  
  ‚Üí O grupo C tem m√©dia significativamente maior que o grupo A.

- **C vs B:**  
  Diferen√ßa = 0.37; IC 95% = [-0.71, 1.45]; p = 0.681  
  ‚Üí N√£o h√° diferen√ßa significativa entre os grupos C e B.

> Os grupos B e C apresentam m√©dias significativamente maiores do que o grupo A. N√£o foi observada diferen√ßa significativa entre os grupos B e C.

## Kruskal-Wallis no R

Se os pr√©-requisitos da ANOVA n√£o forem atendidos, utilize o Kruskal-Wallis:

```{r KWtest, message=FALSE,  warning=FALSE}
kruskal.test(valor ~ grupo, data = dados)
```

- **Valor de p (p-value) = 0.01669:** O valor de p √© menor que 0,05, indicando que h√° diferen√ßa estatisticamente significativa entre pelo menos dois dos grupos analisados.

- Rejeita-se a hip√≥tese nula de que as distribui√ß√µes dos grupos s√£o todas iguais. Ou seja, pelo menos um dos grupos apresenta distribui√ß√£o diferente dos demais. Para identificar especificamente quais grupos diferem entre si, √© recomendada a realiza√ß√£o de testes post hoc apropriados (por exemplo, Dunn ou pairwise Wilcoxon com ajuste para m√∫ltiplas compara√ß√µes).
  
### Teste Post Hoc para Kruskal-Wallis

```{r KWphtest, message=FALSE,  warning=FALSE}
# Instale PMCMRplus se necess√°rio: install.packages("PMCMRplus")
library(PMCMRplus)
kwAllPairsDunnTest(valor ~ grupo, data = dados)
```

O teste de Dunn √© um teste p√≥s-hoc n√£o-param√©trico, utilizado ap√≥s o teste de Kruskal-Wallis para identificar quais pares de grupos diferem significativamente entre si.

Os _p-valores_ apresentados pelo teste compara todos os pares poss√≠veis entre os grupos (neste exemplo: A, B e C):

- **A vs. B**: p = 0.058
- **A vs. C**: p = 0.021
- **B vs. C**: p = 0.611

> Portanto, os resultados sugerem que apenas os grupos A e C, para a vari√°vel analisada, s√£o estatisticamente diferentes entre si.

## Por que n√£o √© indicado comparar os grupos dois a dois diretamente?

Quando se tem mais de dois grupos, pode parecer tentador realizar m√∫ltiplos testes de compara√ß√£o entre pares de grupos (por exemplo, v√°rios testes t para todos os pares poss√≠veis). No entanto, esse procedimento **n√£o √© recomendado**, pois aumenta significativamente o risco de cometer um **erro do tipo I** (falso positivo).

Cada teste realizado tem uma determinada probabilidade de indicar uma diferen√ßa por acaso (erro tipo I), geralmente 5% se Œ± = 0,05. Ao fazer muitos testes independentes, a probabilidade de encontrar pelo menos um resultado "significativo" apenas por acaso aumenta. Esse fen√¥meno √© chamado de **inflacionamento da taxa de erro tipo I**.

Por isso, para compara√ß√£o de mais de dois grupos, utiliza-se primeiro um teste global (como ANOVA ou Kruskal-Wallis). Se o resultado for significativo, a√≠ sim s√£o realizados testes post hoc, que j√° incluem corre√ß√µes para m√∫ltiplas compara√ß√µes (como o teste de Tukey), controlando o risco de erro tipo I.


## ANOVA para Dados Repetidos no R

Vamos analisar o desempenho de 6 alunos em 3 provas diferentes (Prova 1, Prova 2 e Prova 3). Cada aluno fez todas as provas, ou seja, temos medidas repetidas!

### Gerar dados simulados

```{r AnovaRtest, message=FALSE,  warning=FALSE}
set.seed(123)
n <- 20
dados <- data.frame(
  aluno = factor(1:n),
  prova1 = round(rnorm(n, mean = 7, sd = 1), 1),
  prova2 = round(rnorm(n, mean = 7.5, sd = 1), 1),
  prova3 = round(rnorm(n, mean = 8, sd = 1), 1)
)
head(dados)
```

### Converter para formato longo

```{r AnovaRltest, message=FALSE,  warning=FALSE}
library(tidyr)
dados_long <- pivot_longer(
  dados,
  cols = c("prova1", "prova2", "prova3"),
  names_to = "prova",
  values_to = "nota"
)
head(dados_long)
```

> Transformar os dados para o formato longo √© fundamental para an√°lises de medidas repetidas porque permite que o R identifique corretamente as repeti√ß√µes de cada aluno ao longo das diferentes provas. Sem isso, n√£o √© poss√≠vel fazer ANOVA de medidas repetidas de forma adequada!

### Visualiza√ß√£o (opcional)

```{r AnovaRgtest, message=FALSE,  warning=FALSE}
library(ggplot2)
library(RColorBrewer)

# Use uma paleta de cores apropriada para at√© 20 alunos
cores <- colorRampPalette(brewer.pal(9, "Set1"))(20)

ggplot(dados_long, aes(x = prova, y = nota, group = aluno, color = aluno)) +
  geom_line(alpha = 0.7, size = 1) +
  geom_point(size = 2) +
  labs(x = "Avalia√ß√µes", y = "Pontua√ß√£o") +
  scale_color_manual(values = cores) +
  labs(title = "Notas dos Alunos nas Tr√™s Provas", color = "Aluno") +
  theme_minimal() +
  theme(legend.position = "right")
```


### Teste de normalidade das diferen√ßas (pr√©-requisito)

```{r AnovaRnormtest, message=FALSE,  warning=FALSE}
dif12 <- dados$prova1 - dados$prova2
dif13 <- dados$prova1 - dados$prova3
dif23 <- dados$prova2 - dados$prova3

qqnorm(dif12)
qqline(dif12)
shapiro.test(dif12)

qqnorm(dif13)
qqline(dif13)
shapiro.test(dif13)

qqnorm(dif23)
qqline(dif23)
shapiro.test(dif23)
```

> As diferen√ßas seguem distribui√ß√£o normal.

### ANOVA de medidas repetidas com afex (testa e corrige esfericidade)

A fun√ß√£o `aov_ez()`, do pacote `afex` realiza toda a ANOVA de medidas repetidas de forma pr√°tica e autom√°tica.

```{r AnovaRetest, message=FALSE,  warning=FALSE}
# Instale se necess√°rio: install.packages("afex")
library(afex)
modelo_afex <- aov_ez(
  id = "aluno",
  dv = "nota",
  within = "prova",
  data = dados_long
)
modelo_afex
```

- **Effect**: O fator analisado (`prova`), ou seja, se as notas variam entre as provas.
- **df**: Graus de liberdade. Note que aparecem valores decimais (1.91, 36.27) porque foi aplicada a corre√ß√£o de Greenhouse-Geisser (GG), devido √† viola√ß√£o da esfericidade.
- **MSE**: Erro quadr√°tico m√©dio.
- **F**: Estat√≠stica F da ANOVA.
- **ges**: Generalized Eta Squared, uma medida de tamanho de efeito.
- **p.value**: Valor de p associado ao teste F. Neste caso, p = 0.009 indica que h√° diferen√ßa significativa entre as m√©dias das provas (p < 0.05).
- **Observa√ß√£o sobre esfericidade:** A linha `Sphericity correction method: GG` informa que o pressuposto de esfericidade foi violado (teste de Mauchly p < 0.05) e, por isso, os graus de liberdade e o valor de p foram corrigidos automaticamente pelo m√©todo de Greenhouse-Geisser.

> A an√°lise de vari√¢ncia (ANOVA) mostrou que o fator "prova" teve um efeito significativo sobre as notas (F(1.91, 36.27) = 5.53, p = 0.009, ges = 0.168), indicando que as m√©dias das notas diferem entre as provas.

### P√≥s-hoc: Compara√ß√µes m√∫ltiplas entre as provas

```{r AnovaRphtest, message=FALSE,  warning=FALSE}
# Instale se necess√°rio: install.packages("emmeans")
library(emmeans)
emm <- emmeans(modelo_afex, ~ prova)
pairs(emm, adjust = "bonferroni") # ou "holm", "sidak", etc.
```

- **prova1 vs prova2:** N√£o h√° diferen√ßa significativa (p = 0.9212).
- **prova1 vs prova3:** Diferen√ßa significativa (p = 0.0225). As m√©dias dessas provas s√£o estatisticamente diferentes.
- **prova2 vs prova3:** N√£o h√° diferen√ßa significativa (p = 0.0717).

> A an√°lise revelou que existe diferen√ßa significativa nas notas entre as provas. Especificamente, a √∫nica diferen√ßa significativa foi entre as provas 1 e 3, indicando que as m√©dias dessas avalia√ß√µes diferem estatisticamente. Entre as demais provas, n√£o foram observadas diferen√ßas significativas ap√≥s o ajuste de Bonferroni.

 
## Teste de Friedman

```{r Friedmantest, message=FALSE,  warning=FALSE}
# O teste de Friedman compara as tr√™s provas considerando a repeti√ß√£o por aluno
friedman.test(as.matrix(dados[, c("prova1", "prova2", "prova3")]))
```

### P√≥s-teste: Compara√ß√µes M√∫ltiplas (Wilcoxon pareado)

```{r Friedmanphtest, message=FALSE,  warning=FALSE}
pairwise.wilcox.test(
  dados_long$nota,
  dados_long$prova,
  paired = TRUE,
  p.adjust.method = "bonferroni"
)
```

Ap√≥s o teste de Friedman indicar que h√° diferen√ßa nas notas das provas, fazemos um p√≥s-teste para descobrir entre quais provas h√° diferen√ßa.

- Apenas **entre Prova 1 e Prova 3 existe diferen√ßa significativa** (0.033 < 0.05).
- Entre Prova 1 e 2, e entre Prova 2 e 3, n√£o h√° diferen√ßa significativa (valores maiores que 0.05).

<!--chapter:end:19-Comparacao-mais-de-2grupos.Rmd-->

# Correla√ß√£o entre vari√°veis

A correla√ß√£o √© uma forma de medir o grau de rela√ß√£o entre duas vari√°veis. Quando duas vari√°veis est√£o correlacionadas, significa que podemos esperar que, ao mudar uma delas, a outra tamb√©m sofra alguma altera√ß√£o. Se ambas aumentam juntas, dizemos que a correla√ß√£o √© positiva; se uma aumenta enquanto a outra diminui, a correla√ß√£o √© negativa.

√â importante destacar que a correla√ß√£o indica apenas que as vari√°veis variam juntas, mas n√£o prova que uma causa a mudan√ßa na outra. Outros fatores podem estar influenciando essa rela√ß√£o, ou pode ser apenas uma coincid√™ncia. Por isso, correla√ß√£o mostra como as vari√°veis est√£o relacionadas, mas n√£o estabelece uma rela√ß√£o de causa e efeito.


> Na medicina, um exemplo cl√°ssico √© investigar a correla√ß√£o entre o √≠ndice de massa corporal (IMC) e a press√£o arterial sist√≥lica. Pesquisadores podem avaliar se pessoas com IMC mais elevado tendem a ter press√£o arterial mais alta, o que ajuda a entender riscos cardiovasculares.

> Na psicologia, pode-se analisar a correla√ß√£o entre a pontua√ß√£o em uma escala de ansiedade (por exemplo, a pontua√ß√£o total em um question√°rio) e o n√∫mero de horas de sono por noite. Essa rela√ß√£o ajuda a compreender como o sono influencia o n√≠vel de ansiedade.

> Na educa√ß√£o f√≠sica, um exemplo √© estudar a correla√ß√£o entre o tempo gasto em atividade f√≠sica semanal (em horas) e a porcentagem de gordura corporal. Isso auxilia na avalia√ß√£o do impacto do exerc√≠cio sobre a composi√ß√£o corporal.

## Tipos de Vari√°veis
Para analisar correla√ß√£o, usamos vari√°veis num√©ricas (quantitativas ou qualitativas ordinais).

## Diagrama de Dispers√£o
O diagrama de dispers√£o √© um gr√°fico que permite visualizar a rela√ß√£o entre duas vari√°veis. A seguir, exemplos de diferentes padr√µes de correla√ß√£o:

```{r exemplo-correlacoes, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(2025)
df_cor <- data.frame(
  x = rnorm(100)
)
df_cor$y_pos_forte <- df_cor$x + rnorm(100, 0, 0.3)
df_cor$y_neg_forte <- -df_cor$x + rnorm(100, 0, 0.3)
df_cor$y_moderada <- 0.5*df_cor$x + rnorm(100, 0, 0.7)
df_cor$y_fraca <- df_cor$x + rnorm(100, 0, 3)
df_cor$y_sem <- rnorm(100,0,10)
df_cor$y_nlinear <- (df_cor$x)^2 + rnorm(100)

par(mfrow = c(2, 3), mgp = c(1.1, 0.1, 0)) # mgp aproxima xlab/ylab do gr√°fico

plot(df_cor$x, df_cor$y_pos_forte, 
     main = "Correla√ß√£o Positiva Forte", 
     xlab = expression("vari√°vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("vari√°vel 2" ~ "\u2192"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_moderada, 
     main = "Correla√ß√£o Positiva Moderada", 
     xlab = expression("vari√°vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("vari√°vel 2" ~ "\u2192"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_fraca, 
     main = "Correla√ß√£o Positiva Fraca", 
     xlab = expression("vari√°vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("vari√°vel 2" ~ "\u2192"), # seta para a direita 
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_neg_forte, 
     main = "Correla√ß√£o Negativa Forte", 
     xlab = expression("vari√°vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("vari√°vel 2" ~ "\u2190"), # seta para a esquerda
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_sem, 
     main = "Sem Correla√ß√£o", 
     xlab = expression("vari√°vel 1"), # seta para a direita
     ylab = expression("vari√°vel 2"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_nlinear, 
     main = "Correla√ß√£o N√£o Linear", 
     xlab = expression("vari√°vel 1"), # seta para a direita
     ylab = expression("vari√°vel 2"), # seta para a direita 
     xaxt = "n", yaxt = "n")
```

Para criar um gr√°fico de dispers√£o no R, voc√™ pode usar a fun√ß√£o `plot()`. Os argumentos b√°sicos que voc√™ deve fornecer entre os par√™nteses s√£o:

- "x": um vetor num√©rico com os valores do eixo x (vari√°vel independente).
- "y": um vetor num√©rico com os valores do eixo y (vari√°vel dependente).

> Ou seja, algo como: `plot(x,y)`  

## Coeficientes de Correla√ß√£o

Existem diferentes m√©todos para medir a correla√ß√£o entre vari√°veis, cada um adequado a tipos espec√≠ficos de dados e rela√ß√µes. Os tr√™s tipos mais comuns s√£o: a **correla√ß√£o de Pearson**, que avalia a rela√ß√£o linear entre vari√°veis num√©ricas cont√≠nuas; a **correla√ß√£o de Spearman**, que mede associa√ß√µes monot√¥nicas usando postos, sendo indicada para dados ordinais ou quando a rela√ß√£o n√£o √© estritamente linear; e a **correla√ß√£o de Kendall**, tamb√©m baseada em postos, que √© especialmente √∫til em amostras pequenas ou com muitos empates nos dados. Conhecer essas diferen√ßas √© fundamental para escolher o m√©todo mais apropriado em cada situa√ß√£o.

### Coeficiente de Correla√ß√£o de Pearson

O coeficiente de correla√ß√£o de **Pearson** ($r$) √© utilizado quando se deseja avaliar a rela√ß√£o linear entre duas vari√°veis quantitativas cont√≠nuas. Ele pressup√µe que os dados de ambas as vari√°veis seguem uma **distribui√ß√£o normal** (ou aproximadamente normal) e que a rela√ß√£o entre elas √© linear, ou seja, uma linha reta pode descrever bem o padr√£o dos dados em um gr√°fico de dispers√£o. √â sens√≠vel a outliers.

### Coeficiente de Correla√ß√£o de Spearman

O coeficiente de **Spearman** ($\rho$) avalia a for√ßa e a dire√ß√£o da associa√ß√£o entre duas vari√°veis com base em seus **ranks** (postos) em vez dos valores originais. Ele √© indicado quando a rela√ß√£o entre as vari√°veis √© **monot√¥nica**, ou seja, conforme uma vari√°vel aumenta, a outra tamb√©m aumenta ou diminui, mas n√£o necessariamente de maneira linear. O Spearman √© apropriado para dados que n√£o seguem a normalidade ou para situa√ß√µes em que a rela√ß√£o n√£o pode ser descrita por uma linha reta. Al√©m disso, √© menos sens√≠vel a outliers do que o Pearson.


### Coeficiente de Correla√ß√£o de Kendall

O coeficiente de **Kendall** ($\tau$) tamb√©m se baseia nos postos dos dados, sendo utilizado para medir a for√ßa da associa√ß√£o entre duas vari√°veis. √â especialmente √∫til em situa√ß√µes com **pequenas amostras** ou quando h√° muitos **empates** nos valores dos dados (valores iguais). Assim como o Spearman, o Kendall n√£o exige normalidade dos dados e √© apropriado para rela√ß√µes monot√¥nicas. Em geral, o tau de Kendall √© visto como mais robusto em amostras pequenas ou com muitos empates.

### Interpreta√ß√£o dos Coeficientes

O valor a correla√ß√£o varia de -1 (correla√ß√£o negativa perfeita) a +1 (correla√ß√£o positiva perfeita), sendo 0 a aus√™ncia de correla√ß√£o linear. 

| Faixa de valores     | Interpreta√ß√£o    |
|:-------------------------:|:-------------:|
| 0,00 ‚Äì 0,10          | Desprez√≠vel      |
| 0,10 ‚Äì 0,30          | Fraca            |
| 0,30 ‚Äì 0,50          | Moderada         |
| 0,50 ‚Äì 0,70          | Forte            |
| 0,70 ‚Äì 1,00          | Muito forte      |

### Exemplo no R

Vamos supor que temos os dados de 18 alunos: a quantidade de aulas frequentadas (de um total de 20) e suas notas finais na disciplina de Estat√≠stica (de 0 a 10).

```{r}
# Vetor de presen√ßas (n√∫mero de aulas frequentadas)
presencas <- c(20, 18, 17, 19, 15, 16, 20, 18, 17, 19, 14, 15, 12, 16, 20, 13, 17, 18)

# Vetor de notas finais em Estat√≠stica
notas <- c(9.8, 9.0, 8.5, 9.5, 7.0, 7.5, 10.0, 8.7, 8.0, 9.2, 6.5, 7.2, 5.0, 7.8, 9.7, 6.0, 8.2, 8.8)
```

```{r correlation-matrix}
# Para calcular o r de Pearson
cor(presencas, notas, method = "pearson")
# Para calcular o rho de Spearman
cor(presencas, notas, method = "spearman")
# Para calular o tau de Kendall
cor(presencas, notas, method = "kendall")

# Dica: d√° para abreviar o nome de cada m√©todo
# Para calcular o r de Pearson
cor(presencas, notas, method = "p")
# Para calcular o rho de Spearman
cor(presencas, notas, method = "s")
#para calular o tau de Kendall
cor(presencas, notas, method = "k")

```

## Testes de Correla√ß√£o

### Pearson
- H0: $r = 0$ (n√£o h√° correla√ß√£o linear entre as vari√°veis "x" e "y")
- H1: $r \neq 0$ (existe correla√ß√£o)
```{r pearson-test}
cor.test(presencas, notas, method = "pearson")
```

O teste de correla√ß√£o de Pearson realizado entre as vari√°veis `presencas` e `notas` apresentou os seguintes resultados:

- **t = 32.615**:  
  Este √© o valor do teste t calculado, que indica uma diferen√ßa extremamente significativa entre a correla√ß√£o observada e a hip√≥tese nula (correla√ß√£o igual a zero). Quanto maior o valor de t, maior a evid√™ncia contra a hip√≥tese nula.

- **df = 16**:  
  Refere-se aos graus de liberdade do teste, calculados por (n - 2), onde n √© o n√∫mero de pares de dados analisados. Neste caso, indica que havia 18 observa√ß√µes.

- **p-value = 4.597e-16**:  
  O valor-p extremamente baixo mostra que a probabilidade de obter uma correla√ß√£o t√£o forte por acaso √© praticamente nula. Portanto, a correla√ß√£o √© estatisticamente significativa.

- **alternative hypothesis: true correlation is not equal to 0**:  
  A hip√≥tese alternativa testada √© de que existe alguma correla√ß√£o (positiva ou negativa) diferente de zero entre as vari√°veis.

- **95 percent confidence interval: 0.9796700 a 0.9972906**:  
  O intervalo de confian√ßa indica que, com 95% de certeza, o valor real da correla√ß√£o populacional entre `presencas` e `notas` est√° entre aproximadamente 0,98 e 0,997. Isso √© considerado uma correla√ß√£o extremamente forte.

- **sample estimates: cor = 0.992563**:  
  O coeficiente de correla√ß√£o de Pearson ($r$) observado foi de 0,99, indicando uma rela√ß√£o positiva, muito forte e praticamente perfeita: quanto maior o n√∫mero de presen√ßas, maior tende a ser a nota.

**Resumo:**  
Os resultados mostram uma associa√ß√£o positiva fort√≠ssima e estatisticamente significativa entre presen√ßas e notas, sugerindo que alunos que frequentam mais tendem a obter notas mais altas.

### Spearman
- H0: $\rho = 0$ (n√£o h√° correla√ß√£o entre as vari√°veis "x" e "y")
- H1: $\rho \neq 0$ (existe correla√ß√£o)
```{r spearman-test, warning=FALSE}
cor.test(presencas, notas, method = "spearman")
```

O teste de correla√ß√£o de Spearman realizado entre as vari√°veis `presencas` e `notas` apresentou os seguintes resultados:

- **S = 7.5293**:  
  Este √© o valor da estat√≠stica de teste S, usada no c√°lculo da correla√ß√£o de Spearman. Ele reflete as diferen√ßas nas posi√ß√µes (ranks) entre as duas vari√°veis analisadas.

- **p-value = 6.52e-16**:  
  O valor-p extremamente baixo indica que a probabilidade de observar uma correla√ß√£o t√£o alta por acaso, caso n√£o exista correla√ß√£o real, √© praticamente nula. Portanto, a correla√ß√£o encontrada √© estatisticamente significativa.

- **alternative hypothesis: true rho is not equal to 0**:  
  A hip√≥tese alternativa do teste √© de que o coeficiente de Spearman ($\rho$) √© diferente de zero, ou seja, existe uma associa√ß√£o monot√¥nica entre as vari√°veis.

- **sample estimates: rho = 0.9922299**:  
  O coeficiente de correla√ß√£o de Spearman observado foi de 0,99, indicando uma rela√ß√£o positiva, extremamente forte, entre `presencas` e `notas`. Isso significa que, √† medida que o n√∫mero de presen√ßas aumenta, as notas tendem a aumentar de forma consistente, mesmo que a rela√ß√£o n√£o seja perfeitamente linear.

**Resumo:**  
Os resultados demonstram uma associa√ß√£o positiva e muito forte entre presen√ßas e notas, estatisticamente significativa. Isso sugere que alunos com mais presen√ßas tendem a obter notas mais altas, mesmo considerando poss√≠veis varia√ß√µes n√£o lineares na rela√ß√£o entre as vari√°veis.

### Kendall
- H0: $\tau = 0$ (n√£o h√° correla√ß√£o entre as vari√°veis "x" e "y")
- H1: $\tau \neq 0$ (existe correla√ß√£o)
```{r kendall-test, warning=FALSE }
cor.test(presencas, notas, method = "kendall")
```

O teste de correla√ß√£o de Kendall realizado entre as vari√°veis `presencas` e `notas` apresentou os seguintes resultados:

- **z = 5.3952**:  
  Este √© o valor da estat√≠stica z calculado para o teste de Kendall. Valores de z elevados indicam forte evid√™ncia contra a hip√≥tese nula de aus√™ncia de associa√ß√£o entre as vari√°veis.

- **p-value = 6.844e-08**:  
  O valor-p extremamente baixo indica que a probabilidade de obter uma correla√ß√£o t√£o alta por acaso √© praticamente nula. Portanto, a associa√ß√£o observada entre as vari√°veis √© estatisticamente significativa.

- **alternative hypothesis: true tau is not equal to 0**:  
  A hip√≥tese alternativa do teste √© de que o coeficiente de Kendall ($\tau$) √© diferente de zero, ou seja, existe uma associa√ß√£o monot√¥nica entre as vari√°veis.

- **sample estimates: tau = 0.9599837**:  
  O coeficiente de correla√ß√£o de Kendall ($\tau$) encontrado foi de 0,96, indicando uma associa√ß√£o positiva, muito forte, entre `presencas` e `notas`. Isso significa que, √† medida que o n√∫mero de presen√ßas aumenta, as notas tamb√©m tendem a aumentar de forma consistente, mesmo considerando poss√≠veis empates (valores iguais) entre as observa√ß√µes.

**Resumo:**  
Os resultados mostram uma associa√ß√£o positiva e extremamente forte entre presen√ßas e notas, estatisticamente significativa. Isso sugere que alunos com mais presen√ßas tendem a obter notas mais altas, mesmo considerando a ordem dos dados e poss√≠veis empates nas avalia√ß√µes.

## Tamanho do Efeito (Effect Size)

Em estudos de correla√ß√£o, o **tamanho do efeito** √© representado pelo valor absoluto do coeficiente de correla√ß√£o (por exemplo, Pearson, Spearman ou Kendall). Isso significa que consideramos apenas a intensidade da rela√ß√£o entre as vari√°veis, independentemente de ser positiva ou negativa.

Por exemplo, tanto um coeficiente de +0,65 quanto de -0,65 indicam um tamanho de efeito de 0,65. Quanto mais pr√≥ximo de 1 (ou -1), mais forte √© a correla√ß√£o; quanto mais pr√≥ximo de 0, mais fraca.

## C√°lculo do Tamanho da Amostra e Poder Estat√≠stico

### Exemplo com `pwr`
Calcular o tamanho da amostra necess√°rio para detectar uma correla√ß√£o de 0,4 com poder de 80% e Œ± = 0,05:

```{r power-analysis, message=FALSE, warning=FALSE}
library(pwr)
pwr.r.test(r = 0.4, power = 0.8, sig.level = 0.05, alternative = "two.sided")
```

### Verificar o poder para uma amostra de tamanho 30:

```{r power-given-n}
pwr.r.test(n = 30, r = 0.4, sig.level = 0.05, alternative = "two.sided")
```

## Outros recursos 

```{r setup2, include=FALSE}
# Instalar pacotes, se necess√°rio:
# install.packages(c("tidyverse", "GGally"))
library(tidyverse)
library(GGally)
```
Para explorar um pouco mais o estudo de correla√ß√£o, vamos usar o banco de dados `iris`, que j√° vem instalado por padr√£o no R.

O dataset `iris` √© um conjunto de dados cl√°ssico em estat√≠stica e aprendizado de m√°quina (*machine learning*). Ele cont√©m 150 observa√ß√µes de flores de √≠ris de tr√™s esp√©cies diferentes: *setosa*, *versicolor* e *virginica*. As vari√°veis num√©ricas s√£o:

- **Sepal.Length:** comprimento da s√©pala (em cent√≠metros), a s√©pala √© a parte externa da flor, que protege os bot√µes florais.

- **Sepal.Width:** largura da s√©pala (em cent√≠metros).

- **Petal.Length:** comprimento da p√©tala (em cent√≠metros), as p√©talas s√£o as partes geralmente coloridas da flor.

- **Petal.Width:** largura da p√©tala (em cent√≠metros).

Estas medidas s√£o √∫teis para estudar rela√ß√µes entre caracter√≠sticas morfol√≥gicas das flores.

### Visualiza√ß√£o com `pairs()`

A fun√ß√£o `pairs()` mostra uma matriz de gr√°ficos de dispers√£o, √∫til para observar visualmente correla√ß√µes entre todas as vari√°veis num√©ricas.

```{r pairs-plot}
pairs(iris[, 1:4])
```

A fun√ß√£o `pairs` no R gera uma matriz de gr√°ficos de dispers√£o mostrando a rela√ß√£o entre todas as vari√°veis num√©ricas de um conjunto de dados. Cada gr√°fico da matriz compara duas vari√°veis diferentes:

- Cada linha e cada coluna representam uma vari√°vel.
- Os gr√°ficos mostram como cada vari√°vel se relaciona com as outras: por exemplo, a rela√ß√£o entre Sepal.Length e Petal.Length.
- Quando os pontos formam uma linha inclinada, isso indica uma correla√ß√£o (positiva ou negativa) entre as vari√°veis.
- Se os pontos est√£o espalhados, sem padr√£o, indica pouca ou nenhuma rela√ß√£o.
- A diagonal mostra o nome de cada vari√°vel.

Assim, ao olhar para a matriz, voc√™ consegue visualizar rapidamente quais vari√°veis t√™m rela√ß√£o entre si e qual √© o tipo dessa rela√ß√£o (mais forte, mais fraca, positiva ou negativa).

### Matriz de Correla√ß√£o com `cor()`

A fun√ß√£o `cor()` calcula a matriz de correla√ß√£o entre vari√°veis num√©ricas. A seguir, uma matriz com correla√ß√£o de Pearson:

```{r cor-matrix}
# use o m√©todo adequado method = "pearson";  method = "spearman" ou method = "kendall"
cor(iris[, 1:4], method = "pearson")
```

A matriz de correla√ß√£o √© uma tabela que mostra os coeficientes de correla√ß√£o entre todas as combina√ß√µes poss√≠veis de vari√°veis num√©ricas em um conjunto de dados. Cada valor da matriz indica o grau de associa√ß√£o linear entre um par de vari√°veis. A diagonal principal sempre apresenta o valor 1, pois cada vari√°vel √© perfeitamente correlacionada com ela mesma. Assim, a matriz de correla√ß√£o permite identificar rapidamente quais vari√°veis est√£o mais relacionadas entre si, facilitando a an√°lise explorat√≥ria dos dados. Observe que essa matriz √© sim√©trica


### Matriz Visual com `GGally::ggcorr()`

O `ggcorr()` do pacote `GGally` mostra graficamente os coeficientes de correla√ß√£o, com intensidade e dire√ß√£o representadas por cor.

```{r ggcorr-matrix}
# Instale os pacotes se necess√°rio:
# install.packages("GGally")
# install.packages("ggplot2")

# Matriz de correla√ß√£o tipo heatmap com valores destacados
ggcorr(
  data = iris[, 1:4],
  method = c("everything", "pearson"), # calcula todas as correla√ß√µes de Pearson
  label = TRUE,             # mostra os coeficientes nas c√©lulas
  label_round = 2,          # arredonda os valores para 2 casas decimais
  label_size = 5,           # tamanho do texto dos coeficientes
  hjust = 0.5,              # centraliza os r√≥tulos nas c√©lulas
  layout.exp = 2,           # expande o tamanho das c√©lulas
  low = "#D73027",          # cor para correla√ß√£o negativa forte
  mid = "white",            # cor para correla√ß√£o nula
  high = "#3366CC"          # cor para correla√ß√£o positiva forte
) +
  ggtitle("Matriz de Correla√ß√£o de Pearson - iris (Heatmap)") +
  theme_minimal(base_size = 14) + # visual minimalista e tamanho de fonte maior
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # centraliza e destaca o t√≠tulo
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1) # gira r√≥tulos do eixo x para melhor leitura
  )
```

A fun√ß√£o `ggpairs()` combina histogramas, correla√ß√µes e gr√°ficos de dispers√£o em uma visualiza√ß√£o integrada.

Este comando cria uma matriz de gr√°ficos que facilita visualizar a distribui√ß√£o e a rela√ß√£o entre as vari√°veis num√©ricas do conjunto. √â muito √∫til para identificar padr√µes, tend√™ncias, outliers e poss√≠veis correla√ß√µes antes de uma an√°lise estat√≠stica mais aprofundada.

- **Considerando todos os dados:**
```{r ggpairs-plot0, message=FALSE, warning=FALSE}
GGally::ggpairs(iris, columns = 1:4)
```

- **Considerando as categorias de especies (vari√°vel Species)**
```{r ggpairs-plot, message=FALSE, warning=FALSE}
GGally::ggpairs(iris, columns = 1:4, aes(color = Species))
```

**O que a figura mostra?**

Esta figura √© uma **matriz de gr√°ficos de pares** (pairs) das vari√°veis num√©ricas do conjunto de dados, nesse caso, `Sepal.Length`, `Sepal.Width`, `Petal.Length` e `Petal.Width`.

- **Diagonal principal**: exibe a distribui√ß√£o de cada vari√°vel individualmente, usando histogramas ou curvas de densidade. Quando os dados est√£o divididos por categoria (como diferentes esp√©cies no exemplo do iris), cada cor representa uma categoria distinta, permitindo visualizar e comparar facilmente como os valores da vari√°vel se distribuem em cada grupo.

- **Abaixo da diagonal**: mostra gr√°ficos de dispers√£o, permitindo observar visualmente as rela√ß√µes entre os pares de vari√°veis para cada esp√©cie.

- **Acima da diagonal**: apresenta os **coeficientes de correla√ß√£o** para cada par de vari√°veis:
  - O valor principal (exemplo: Corr: 0.872***) corresponde √† correla√ß√£o considerando todas as esp√©cies juntas.
  - Abaixo, aparecem as correla√ß√µes **por esp√©cie**:
    - setosa (vermelho)
    - versicolor (verde)
    - virginica (azul)
  - Os valores s√£o coloridos conforme a esp√©cie correspondente.

- **Sobre os asteriscos**: os asteriscos ap√≥s os valores de correla√ß√£o indicam o **n√≠vel de signific√¢ncia estat√≠stica** do coeficiente calculado, ou seja, qu√£o prov√°vel √© que a correla√ß√£o observada seja diferente de zero apenas pelo acaso. A conven√ß√£o usual √©:

- `*` : p < 0,05 
- `**` : p < 0,01 
- `***` : p < 0,001
- Sem asteriscos: correla√ß√£o **n√£o** significativa

<!--chapter:end:20-Correlacao.Rmd-->

# Regress√£o

A **regress√£o** √© uma t√©cnica estat√≠stica usada para estudar a rela√ß√£o entre uma vari√°vel de interesse (chamada de vari√°vel dependente ou resposta) e uma ou mais vari√°veis que podem influenci√°-la (chamadas de vari√°veis independentes ou preditoras). O objetivo principal √© **prever** ou **explicar** o comportamento da vari√°vel resposta a partir das informa√ß√µes das vari√°veis preditoras.

**Regress√£o Linear Simples:**  
√â o tipo mais b√°sico de regress√£o, analisando a rela√ß√£o entre duas vari√°veis: uma resposta (por exemplo, peso) e uma preditora (por exemplo, altura). A rela√ß√£o √© representada por uma linha reta:  
\[
\text{Resposta} = a + b \times \text{Preditora}
\]  
Exemplo: Prever o peso de uma pessoa a partir de sua altura. O modelo estima qual seria o peso esperado para cada altura.

**Regress√£o Linear M√∫ltipla:**  
Quando queremos analisar o efeito de duas ou mais vari√°veis preditoras sobre a vari√°vel resposta, usamos a regress√£o linear m√∫ltipla. A equa√ß√£o fica:  
\[
\text{Resposta} = a + b_1 \times \text{Preditora}_1 + b_2 \times \text{Preditora}_2 + \ldots
\]  
Exemplo: Prever o pre√ßo de uma casa considerando √°rea, n√∫mero de quartos e localiza√ß√£o.

**Regress√£o Log√≠stica:**  
√â usada quando a resposta √© categ√≥rica, por exemplo: sim/n√£o, doente/sadio, aprovado/reprovado. Em vez de prever um n√∫mero, ela estima a probabilidade de um determinado evento ocorrer. Exemplo: Prever a chance de um paciente ter uma certa doen√ßa com base em exames. O resultado √© sempre um valor entre 0 e 1 (uma probabilidade).

**Outros Modelos de Regress√£o:**  
Al√©m dos modelos acima, existem outros tipos de regress√£o para diferentes situa√ß√µes, como:  
- Regress√£o de Poisson: para contagem de eventos (exemplo: n√∫mero de acidentes por m√™s);
- Regress√£o de Prais-Winsten: utilizada em s√©ries temporais, especialmente quando os dados t√™m depend√™ncia ao longo do tempo (como dados econ√¥micos mensais);
- Regress√£o polinomial: ajusta curvas em vez de retas, para rela√ß√µes n√£o-lineares;
- Regress√£o robusta, Ridge, Lasso: abordam problemas espec√≠ficos como dados com valores extremos ou quando h√° muitas vari√°veis preditoras.

Em resumo, a regress√£o √© uma ferramenta poderosa e vers√°til, √∫til em diferentes √°reas como sa√∫de, economia, educa√ß√£o e ci√™ncias sociais. Ela nos ajuda a compreender rela√ß√µes, prever resultados e tomar decis√µes baseadas em dados, mesmo sem precisar de conhecimentos avan√ßados em matem√°tica.

## Regress√£o Linear Simples 

A correla√ß√£o responde √† pergunta: **"Existe rela√ß√£o linear? Qual a for√ßa e o sentido dessa rela√ß√£o?"**

A **regress√£o linear simples** vai al√©m: al√©m de indicar se existe rela√ß√£o, ela fornece uma equa√ß√£o que **quantifica e permite prever** uma vari√°vel a partir da outra.  
A equa√ß√£o tem a forma:

\[
Y = a + bX
\]

onde:
- **Y**: vari√°vel resposta (dependente)
- **X**: vari√°vel explicativa (independente)
- **a**: intercepto (valor esperado de Y quando X = 0)
- **b**: inclina√ß√£o (quanto Y varia, em m√©dia, a cada unidade de X)

A regress√£o responde √† pergunta: **"Como prever Y a partir de X?"**

√â comum estudar primeiro a correla√ß√£o, pois ela mostra se vale a pena tentar ajustar um modelo de regress√£o linear.


### Regress√£o Linear Simples no R

Como exemplo, vamos estudar a rela√ß√£o entre a **frequ√™ncia card√≠aca** (x, em batimentos por minuto - bpm) e o **comprimento do intervalo QT** (y, em milissegundos) de um eletrocardiograma (ECG). O intervalo QT representa o tempo que o cora√ß√£o leva para se despolarizar e repolarizar, sendo um importante marcador cl√≠nico.

Vamos considerar a seguinte amostra: 

```{r}
# Frequ√™ncia card√≠aca (bpm)
x <- c(60,75,62,68,84,97,66,65,86,78,93,75,88)
# Intervalo QT (ms)
y <- c(403,363,381,367,341,317,401,384,342,377,329,377,349)
```

Vamos, primeiro, verificar o comportamento das vari√°veis pelo gr√°fio de dispers√£o:

```{r}
plot(x, y, 
     xlab = "Frequ√™ncia Card√≠aca (bpm)", 
     ylab = "Intervalo QT (ms)", 
     pch = 19, col = "blue")
grid()
```

O teste de correla√ß√£o nos fornece:

```{r}
# antes, verifique a normalidade das vari√°veis 
cor.test(x, y) # Teste estat√≠stico da correla√ß√£o
```

- **Coeficiente de correla√ß√£o (r):** -0,93
- **Valor de t:** -8,29
- **Graus de liberdade (df):** 11
- **Valor-p:** 0,0000046
- **Intervalo de confian√ßa (95%):** de -0,98 a -0,77

O que isso significa?

- **For√ßa e dire√ß√£o:** O coeficiente de correla√ß√£o de Pearson (**r = -0,93**) indica uma **correla√ß√£o negativa muito forte** entre as vari√°veis x e y. Isso significa que, √† medida que uma vari√°vel aumenta, a outra tende a diminuir de forma bastante consistente.
- **Signific√¢ncia estat√≠stica:** O valor-p (**p < 0,001**) mostra que essa correla√ß√£o √© **estatisticamente significativa**. Ou seja, √© extremamente improv√°vel que essa rela√ß√£o forte e negativa tenha ocorrido por acaso.
- **Intervalo de confian√ßa:** O intervalo de -0,98 a -0,77 indica que, com 95% de confian√ßa, a verdadeira correla√ß√£o na popula√ß√£o est√° dentro desse intervalo ‚Äî sempre indicando uma rela√ß√£o negativa forte.
- **Hip√≥tese nula:** Como o valor-p √© muito pequeno, rejeitamos a hip√≥tese nula de que n√£o existe correla√ß√£o linear entre x e y.

Como h√° uma correla√ß√£o linear forte e significativa, **faz sentido estudar um modelo de regress√£o linear** para quantificar e prever a rela√ß√£o entre essas vari√°veis.


Para ajustarmos um modelo onde o intervalo QT √© explicado pela frequ√™ncia card√≠aca no R, usamos a fun√ß√£o `lm()`, onde lm significa *linear model*.

```{r}
regressao <- lm(y ~ x)
regressao
```
O modelo ajustado de regress√£o linear simples foi:

\[
\text{Intervalo QT} = 520,67 - 2,04 \times \text{Frequ√™ncia Card√≠aca}
\]

**Interpreta√ß√£o dos coeficientes:**

- **Intercepto (520,67):**  
  Este valor representa a estimativa do intervalo QT (em milissegundos) quando a frequ√™ncia card√≠aca (x) √© zero. Embora uma frequ√™ncia card√≠aca de zero n√£o fa√ßa sentido fisiol√≥gico, o intercepto √© necess√°rio para construir a reta de regress√£o e serve como refer√™ncia matem√°tica.

- **Inclina√ß√£o (-2,04):**  
  Esse coeficiente indica que, para cada aumento de 1 batimento por minuto (bpm) na frequ√™ncia card√≠aca, o intervalo QT diminui, em m√©dia, cerca de 2,04 milissegundos.  
  Ou seja, existe uma rela√ß√£o negativa: quanto maior a frequ√™ncia card√≠aca, menor tende a ser o intervalo QT.

O resumo da regress√£o √© obtido a partir da fun√ß√£o `summary()`

```{r}
summary(regressao)
```

- **Valor-p para ambos os coeficientes (p < 0,001):** Os dois coeficientes s√£o  significativos, ou seja, existe evid√™ncia estat√≠stica muito forte de que ambos s√£o diferentes de zero.

- **R¬≤ (Multiple R-squared): 0,86:** Aproximadamente 86% da varia√ß√£o do intervalo QT √© explicada pela frequ√™ncia card√≠aca. √â um valor alto, indicando que o modelo ajusta bem os dados.
- **R¬≤ Ajustado (0,85):** Leva em conta o n√∫mero de vari√°veis e tamanho da amostra, e tamb√©m √© alto.
- **Erro padr√£o residual (Residual standard error: 10,38):** Mede o desvio m√©dio dos pontos em rela√ß√£o √† reta ajustada (quanto menor, melhor).

- **Res√≠duos:** Representam a diferen√ßa entre os valores observados e os previstos pelo modelo. Os valores m√≠nimos e m√°ximos indicam a dispers√£o dos erros.

- **F-statistic: 68,8, p-value: 4,6e-06:** Teste global do modelo, confirma que a rela√ß√£o encontrada √© altamente significativa.

O modelo de regress√£o linear simples mostra que existe uma **forte rela√ß√£o linear negativa** e estatisticamente significativa entre a frequ√™ncia card√≠aca e o intervalo QT: quanto maior a frequ√™ncia card√≠aca, menor tende a ser o intervalo QT. O modelo explica a maior parte da varia√ß√£o dos dados, sendo √∫til para previs√µes e interpreta√ß√µes cl√≠nicas dessa rela√ß√£o.

O intervalos de confian√ßa para os coeficientes da reta √© dado por: 

```{r}
confint(regressao)
```

- **Intercepto (a):**  
  O intervalo de confian√ßa de 95% para o intercepto vai de **478,59** a **562,74**. Isso significa que, com 95% de confian√ßa, o verdadeiro valor do intercepto est√° dentro desse intervalo. O intercepto representa o valor estimado do intervalo QT quando a frequ√™ncia card√≠aca √© zero (valor te√≥rico/matem√°tico).

- **Inclina√ß√£o (b):**  
  O intervalo de confian√ßa de 95% para a inclina√ß√£o vai de **-2,59** a **-1,50**. Como o intervalo √© totalmente negativo, refor√ßa que a rela√ß√£o entre frequ√™ncia card√≠aca e intervalo QT √© negativa: a cada aumento de 1 bpm na frequ√™ncia card√≠aca, o intervalo QT diminui, em m√©dia, entre 1,50 e 2,59 ms.
  

**Limita√ß√µes e Cuidados na Regress√£o Linear**

Apesar do modelo indicar uma associa√ß√£o significativa, √© importante considerar algumas limita√ß√µes e pontos de aten√ß√£o:

- **Extrapola√ß√£o:** O modelo √© v√°lido apenas para a faixa de dados observados. Prever valores de QT para frequ√™ncias card√≠acas muito fora do intervalo observado pode gerar resultados sem sentido.
- **Suposi√ß√µes do modelo:**  
  - **Linearidade:** A rela√ß√£o entre as vari√°veis deve ser aproximadamente linear.
  - **Normalidade dos res√≠duos:** Os res√≠duos (erros) devem ser aproximadamente distribu√≠dos normalmente.
  - **Homoscedasticidade:** A vari√¢ncia dos res√≠duos deve ser constante ao longo dos valores previstos.
  - **Independ√™ncia:** As observa√ß√µes devem ser independentes entre si.
  Recomenda-se sempre checar essas suposi√ß√µes usando gr√°ficos de res√≠duos e testes estat√≠sticos.
- **Poss√≠veis valores extremos (outliers):** Valores muito diferentes dos demais podem influenciar fortemente o ajuste, distorcendo os resultados.
- **Correla√ß√£o n√£o implica causalidade:** A regress√£o mostra associa√ß√£o, mas n√£o garante que uma vari√°vel causa a outra.

### O que deve ser checado ao ajustar uma regress√£o linear?

- **Gr√°fico de res√≠duos:** Para avaliar linearidade, homoscedasticidade e detectar outliers.
- **Histograma/QQ-plot dos res√≠duos:** Para verificar a normalidade dos res√≠duos.
- **Verificar influ√™ncias:** Avaliar se algum ponto influencia demais o resultado (diagn√≥stico de outliers/influ√™ncia).
- **Intervalos de confian√ßa:** Analisar a precis√£o das estimativas dos par√¢metros.
- **R¬≤ e R¬≤ ajustado:** Avaliar o quanto do comportamento da vari√°vel resposta √© explicado pelo modelo.

## Regress√£o Linear M√∫ltipla

Depois de entender a regress√£o linear simples, √© f√°cil expandir para a **regress√£o linear m√∫ltipla**, onde podemos incluir mais de uma vari√°vel preditora para explicar a vari√°vel resposta. No nosso exemplo, al√©m da **frequ√™ncia card√≠aca (x)**, vamos acrescentar a **idade dos indiv√≠duos (z)**, que tamb√©m pode influenciar o intervalo QT do eletrocardiograma (y).

Vamos supor os seguintes valores de idade para os mesmos indiv√≠duos:

```{r}
# Frequ√™ncia card√≠aca (bpm)
x <- c(60,75,62,68,84,97,66,65,86,78,93,75,88)
# Intervalo QT (ms)
y <- c(403,363,381,367,341,317,401,384,342,377,329,377,349)
# Idade (anos) - exemplo hipot√©tico
z <- c(25,40,30,22,53,60,28,27,50,35,59,41,55)
```

Vamos ajustar agora um modelo que considera tanto a frequ√™ncia card√≠aca quanto a idade como preditoras do intervalo QT:

- O modelo ajustado tem a forma:
  \[
  \text{QT} = a + b_1 \times \text{Frequ√™ncia Card√≠aca (x)} + b_2 \times \text{Idade (z)}
  \]

```{r}
regressao_multipla <- lm(y ~ x + z)
summary(regressao_multipla)
```

**Modelo ajustado:**  
\[
\text{QT} = 514,39 - 1,88 \times \text{Frequ√™ncia Card√≠aca (x)} - 0,15 \times \text{Idade (z)}
\]

- **Intercepto (514,39):**  
  Valor estimado do QT quando frequ√™ncia card√≠aca e idade s√£o zero (valor te√≥rico, apenas refer√™ncia matem√°tica).

- **Frequ√™ncia Card√≠aca (x):**  
  O coeficiente √© -1,88, ou seja, para cada aumento de 1 bpm, o QT diminui em m√©dia 1,88 ms, mantendo a idade constante.  
  O valor-p (0,0504) √© lim√≠trofe, indicando que a influ√™ncia da frequ√™ncia card√≠aca sobre o QT **ainda √© significativa**, mas no limite do n√≠vel de signific√¢ncia tradicional (5%).

- **Idade (z):**  
  O coeficiente √© -0,15, ou seja, para cada aumento de 1 ano de idade, o QT diminui, em m√©dia, 0,15 ms, mantendo a frequ√™ncia card√≠aca constante.  
  No entanto, o valor-p (0,8457) mostra que essa associa√ß√£o **n√£o √© estatisticamente significativa** ‚Äî ou seja, n√£o h√° evid√™ncia de que a idade tenha efeito relevante sobre o QT neste conjunto de dados.

> Qualidade do ajuste

- **R¬≤ (0,86):**  
  Aproximadamente 86% da varia√ß√£o do QT √© explicada pelo modelo com as duas vari√°veis preditoras, indicando bom ajuste.
- **R¬≤ ajustado (0,83):**  
  Leva em conta o n√∫mero de vari√°veis, tamb√©m indicando bom ajuste.
- **Erro padr√£o residual (10,87):**  
  M√©dia dos desvios dos pontos em rela√ß√£o √† reta ajustada, semelhante ao modelo simples.

> An√°lise dos res√≠duos

- A distribui√ß√£o dos res√≠duos sugere que o modelo est√° adequado, mas sempre √© recomendado visualizar os gr√°ficos de res√≠duos para avaliar poss√≠veis viola√ß√µes das suposi√ß√µes.

> Teste F

- **F-statistic: 31,42, p-value: 4,88e-05:**  
  O modelo como um todo √© altamente significativo, ou seja, pelo menos uma das vari√°veis preditoras est√° relacionada ao QT.

> Conclus√£o

- O modelo de **regress√£o m√∫ltipla** mostra que, **mantendo a idade constante**, a frequ√™ncia card√≠aca segue sendo um preditor importante e significativo para o intervalo QT.
- A idade, por outro lado, **n√£o contribuiu de forma significativa** para explicar o QT nesse exemplo.
- O ajuste da regress√£o m√∫ltipla no R √© simples e a interpreta√ß√£o amplia a compreens√£o das rela√ß√µes entre v√°rias vari√°veis e a resposta.  
- **Importante:** Sempre verifique as suposi√ß√µes do modelo e a signific√¢ncia de cada preditor.

## No R √© f√°cil

A sintaxe para ajustar a regress√£o m√∫ltipla √© muito parecida com a da simples, basta acrescentar as vari√°veis ao modelo:

```r
lm(y ~ x + z, data = dados)
```
Se quiser incluir ainda mais vari√°veis, basta adicion√°-las na f√≥rmula, separadas por `+`.

> Visualiza√ß√£o dos res√≠duos

√â importante, como sempre, checar os res√≠duos para garantir que as suposi√ß√µes do modelo continuam v√°lidas:

```{r}
plot(regressao_multipla)
```

> Res√≠duos vs Valores Ajustados

- **Objetivo:** Avaliar linearidade e homocedasticidade (vari√¢ncia constante dos res√≠duos).
- **Interpreta√ß√£o:** Os res√≠duos est√£o distribu√≠dos de forma aproximadamente aleat√≥ria ao redor de zero, sem padr√µes claros. Isso sugere que a rela√ß√£o linear √© adequada e que a vari√¢ncia dos res√≠duos √© razoavelmente constante. N√£o h√° grandes evid√™ncias de problemas de ajuste, ainda que um ou outro ponto se afaste mais do centro (poss√≠veis outliers).

> Q-Q Plot dos Res√≠duos

- **Objetivo:** Verificar se os res√≠duos seguem uma distribui√ß√£o normal (suposi√ß√£o importante para testes de hip√≥teses na regress√£o).
- **Interpreta√ß√£o:** Os pontos seguem bem a linha reta, indicando que a normalidade dos res√≠duos √© atendida na maior parte dos casos. Pequenos desvios nas extremidades s√£o toler√°veis, especialmente com amostras pequenas, como neste exemplo.

> Scale-Location (Homocedasticidade)

- **Objetivo:** Avaliar se a vari√¢ncia dos res√≠duos √© constante para todos os valores ajustados (homocedasticidade).
- **Interpreta√ß√£o:** Os pontos est√£o relativamente dispersos de forma homog√™nea ao longo do eixo dos valores ajustados, sem formar um funil ou padr√£o crescente/decrescente marcante. Isso refor√ßa que a suposi√ß√£o de homocedasticidade est√° sendo atendida.

> Res√≠duos Padronizados vs Leverage

- **Objetivo:** Identificar pontos com alto potencial de influ√™ncia no modelo (outliers ou observa√ß√µes influentes).
- **Interpreta√ß√£o:** A maioria dos pontos est√° dentro dos limites aceit√°veis de leverage e res√≠duos. Apenas um ou dois pontos apresentam valores de leverage mais altos, mas sem exceder drasticamente os limites de dist√¢ncia de Cook. Isso sugere que n√£o h√° observa√ß√µes extremamente influentes comprometendo o modelo.

Os diagn√≥sticos gr√°ficos indicam que:
- **As suposi√ß√µes do modelo de regress√£o m√∫ltipla est√£o razoavelmente bem atendidas:** linearidade, normalidade dos res√≠duos, homocedasticidade e aus√™ncia de pontos influentes extremos.
- **O modelo √© adequado para os dados analisados**, com apenas leves ind√≠cios de poss√≠veis outliers, mas sem comprometer as conclus√µes.

## Exerc√≠cio

O exerc√≠cio "nutrientes em cereais matinais" foi retirado do livro Estat√≠stica B√°sica de Larson & Farber. 

A *U.S. Food and Drug Administration* (FDA) exige a rotulagem nutricional para a maioria dos alimentos. Sob os regulamentos da FDA, os produtores s√£o obrigados a listar as quantidades de certos nutrientes em seus alimentos, tais como: calorias, a√ß√∫car, gordura e carboidratos. Essa informa√ß√£o nutricional √© exibida em uma tabela na embalagem do alimento.

A Tabela mostra o teor nutricional para uma x√≠cara de 21 cereais matinais diferentes.

*C* = calorias  
*S* = a√ß√∫car em gramas  
*F* = gordura em gramas  
*R* = carboidratos em gramas  

| C   | S  | F   | R  |
|-----:|:----:|:-----:|:----|
| 100 | 12 | 0.5 | 25 |
| 130 | 11 | 1.5 | 29 |
| 110 | 10 | 1.0 | 29 |
| 130 | 15 | 2.0 | 31 |
| 130 | 13 | 1.5 | 29 |
| 120 |  3 | 0.5 | 26 |
| 100 |  2 | 0.0 | 24 |
| 120 |  0 | 0.0 | 29 |
| 150 | 16 | 1.5 | 31 |
| 110 |  4 | 0.0 | 25 |
| 110 | 12 | 1.0 | 23 |
| 160 | 15 | 1.5 | 35 |
| 150 | 12 | 2.0 | 36 |
| 150 | 15 | 1.5 | 29 |
| 110 | 15 | 0.0 | 29 |
| 190 | 13 | 1.5 | 45 |
| 100 |  3 | 0.0 | 23 |
| 120 |  4 | 0.5 | 23 |
| 120 | 11 | 1.5 | 28 |
| 120 | 11 | 1.0 | 29 |
| 130 |  5 | 0.5 | 29 |


**1.** Use o R para obter um diagrama de dispers√£o dos seguintes pares \((x, y)\) no conjunto de dados.

(a) (Calorias, a√ß√∫car.)  
(b) (Calorias, gordura.)  
(c) (Calorias, carboidratos.)  
(d) (A√ß√∫car, gordura.)  
(e) (A√ß√∫car, carboidratos.)  
(f) (Gordura, carboidratos.)


**2.** Dos diagramas de dispers√£o no Exerc√≠cio 1, quais pares de vari√°veis parecem ter uma correla√ß√£o linear forte?


**3.** Use o R para encontrar o coeficiente de correla√ß√£o para cada par de vari√°veis no Exerc√≠cio 1. Qual tem a correla√ß√£o linear mais forte?


**4.** Use tecnologia para encontrar a equa√ß√£o de uma reta de regress√£o para os seguintes pares de vari√°veis.

(a) (Calorias, a√ß√∫car.)  
(b) (Calorias, carboidratos.)


**5.** Use os resultados do Exerc√≠cio 4 para prever o seguinte:

(a) O teor de a√ß√∫car de uma x√≠cara de cereal que tem 120 calorias.  
(b) O teor de carboidrato de uma x√≠cara de cereal que tem 120 calorias.


**6.** Use tecnologia para encontrar as equa√ß√µes de regress√£o m√∫ltipla dos seguintes modelos:

(a) \( C = b + m_1S + m_2F + m_3R \)  
(b) \( C = b + m_1S + m_2R \)


**7.** Use as equa√ß√µes do Exerc√≠cio 6 para prever as calorias em 1 x√≠cara de cereal que tem 7 gramas de a√ß√∫car; 0,5 grama de gordura e 31 gramas de carboidratos.

<!--chapter:end:21-Regressao.Rmd-->

```{r setup, include=FALSE}
# Instale os pacotes se necess√°rio:
# install.packages(c("tidyverse", "pwr", "epitools"))

library(tidyverse)
library(pwr)
library(epitools)
```

# Associa√ß√£o entre vari√°veis

Testes de associa√ß√£o s√£o usados para verificar se existe uma rela√ß√£o estatisticamente significativa entre duas vari√°veis categ√≥ricas. A escolha do teste depende do tipo de vari√°vel e do tamanho da amostra.

A aplica√ß√£o desses testes √© fundamental em diversas √°reas do conhecimento. 

## Tipos de Vari√°veis Envolvidas

Os testes de associa√ß√£o s√£o aplicados principalmente a **vari√°veis qualitativas nominais**, como:

- Sexo (Masculino, Feminino)
- Presen√ßa de Doen√ßa (Sim, N√£o)

## Tabela de Conting√™ncia

Uma **tabela de conting√™ncia** √© uma ferramenta estat√≠stica utilizada para organizar e analisar a rela√ß√£o entre duas (ou mais) vari√°veis categ√≥ricas. Ela apresenta a distribui√ß√£o conjunta das frequ√™ncias observadas de cada combina√ß√£o poss√≠vel dos n√≠veis das vari√°veis, facilitando a identifica√ß√£o de poss√≠veis associa√ß√µes entre elas.

**Exemplo:**

Considere uma pesquisa em que se investiga a associa√ß√£o entre sexo e presen√ßa de uma determinada doen√ßa em uma amostra de pessoas:

|              | Doen√ßa: Sim | Doen√ßa: N√£o | Total |
|--------------|:-------------:|:-------------:|:-------:|
| Masculino    |      8      |      7      |  15   |
| Feminino     |      5      |     10      |  15   |
| **Total**    |     13      |     17      |  30   |

Cada c√©lula da tabela mostra o n√∫mero de pessoas de cada sexo que t√™m ou n√£o t√™m a doen√ßa, permitindo analisar se existe associa√ß√£o entre essas vari√°veis.

### C√°lculo das Frequ√™ncias Esperadas

As **frequ√™ncias esperadas** s√£o valores te√≥ricos que indicam quantas ocorr√™ncias seriam esperadas em cada c√©lula de uma tabela de conting√™ncia caso n√£o houvesse associa√ß√£o entre as vari√°veis (ou seja, se fossem independentes). Elas s√£o fundamentais para a realiza√ß√£o do teste qui-quadrado de independ√™ncia.

**Como calcular?**

Para cada c√©lula da tabela de contig√™ncia (frequ√™ncias observadas), usamos a seguinte conta:

\[
\text{Frequ√™ncia Esperada} = \frac{\text{Total da Linha} \times \text{Total da Coluna}}{\text{Total Geral}}
\]


- O ‚ÄúTotal da Linha‚Äù √© o total de pessoas daquela linha (por exemplo, todos os homens).

- O ‚ÄúTotal da Coluna‚Äù √© o total de pessoas daquela coluna (por exemplo, todos que t√™m a doen√ßa).

- O ‚ÄúTotal Geral‚Äù √© o total de pessoas da tabela toda.


**Da tabela de contig√™ncia do exemplo anterior, podemos efetuar os c√°lculos**

1. **Masculino, Doen√ßa: Sim**
   \[
   \frac{15 \times 13}{30} = \frac{195}{30} = 6,5
   \]

2. **Masculino, Doen√ßa: N√£o**
   \[
   \frac{15 \times 17}{30} = \frac{255}{30} = 8,5
   \]

3. **Feminino, Doen√ßa: Sim**
   \[
   \frac{15 \times 13}{30} = 6,5
   \]

4. **Feminino, Doen√ßa: N√£o**
   \[
   \frac{15 \times 17}{30} = 8,5
   \]

Ent√£o, nesse caso a tabela de frequ√™ncias esperadas √© dada por:

|              | Doen√ßa: Sim | Doen√ßa: N√£o | Total da linha |
|--------------|:-------------:|:-------------:|:---------------:|
| Masculino    |     6,5     |     8,5     |      15       |
| Feminino     |     6,5     |     8,5     |      15       |
| **Total da coluna** |   13       |    17       |      30       |

A tabela acima mostra as frequ√™ncias que seriam esperadas em cada c√©lula caso n√£o existisse associa√ß√£o entre sexo e presen√ßa de doen√ßa.

A ess√™ncia dos testes de associa√ß√£o √© comparar a tabela de frequ√™ncias observadas (com os dados reais coletados) com a tabela de frequ√™ncias esperadas (calculada considerando que n√£o exista rela√ß√£o entre as vari√°veis, ou seja, que sejam independentes). A tabela observada mostra quantas vezes cada combina√ß√£o de categorias realmente aconteceu, enquanto a tabela esperada mostra quantas vezes cada combina√ß√£o seria esperada ao acaso. O teste avalia se as diferen√ßas entre o que foi observado e o que seria esperado s√£o grandes o suficiente para indicar uma associa√ß√£o entre as vari√°veis. Portanto, a compara√ß√£o entre essas duas tabelas est√° no centro da an√°lise para determinar se existe ou n√£o uma rela√ß√£o significativa entre as vari√°veis estudadas.

Na pr√°tica, todos esses c√°lculos acontecem nos bastidores, pois utilizamos ferramentas computacionais que realizam automaticamente tanto o c√°lculo das frequ√™ncias esperadas quanto a compara√ß√£o com os valores observados. Assim, normalmente n√£o precisamos calcular manualmente cada valor esperado ou montar todas as tabelas. No entanto, √© fundamental compreender o conceito central dos testes de associa√ß√£o: eles servem para comparar o que foi realmente observado com o que seria esperado caso n√£o houvesse rela√ß√£o entre as vari√°veis, ajudando a identificar se existe ou n√£o uma associa√ß√£o significativa entre elas.


## Principais Testes de Associa√ß√£o

√â importante destacar que existem diversos m√©todos estat√≠sticos para analisar a associa√ß√£o entre vari√°veis categ√≥ricas, dependendo do tipo de dados e da estrutura da tabela de conting√™ncia.

Al√©m dos tradicionais teste qui-quadrado e teste exato de Fisher, h√° outros m√©todos que podem ser aplicados conforme a situa√ß√£o:  
- O **teste G** (ou teste da raz√£o de verossimilhan√ßa) √© uma alternativa ao qui-quadrado, baseado em outra abordagem matem√°tica, mas com objetivo semelhante.  
- O **teste de McNemar** √© indicado para tabelas 2x2 com dados pareados, como em estudos antes e depois.  
- O **teste de Mantel-Haenszel** avalia a associa√ß√£o entre vari√°veis, controlando poss√≠veis fatores de confus√£o por meio da estratifica√ß√£o, sendo muito usado em estudos epidemiol√≥gicos.  
- O **teste de tend√™ncia linear de Cochran-Armitage** √© recomendado quando as categorias possuem uma ordem natural e se deseja avaliar a exist√™ncia de tend√™ncia linear entre elas.  
- Existem ainda o **teste de concord√¢ncia Kappa de Cohen**, que mede o grau de concord√¢ncia entre avaliadores, e o **teste exato de Barnard**, alternativa ao teste de Fisher em tabelas 2x2.

A escolha do teste adequado depende do tamanho da amostra, da distribui√ß√£o dos dados, do tipo de vari√°vel (nominal ou ordinal), da estrutura dos dados (independentes ou pareados) e do objetivo da an√°lise.


### Exemplos 

**Exemplo na Medicina:**  

Investigar se h√° associa√ß√£o entre o sexo do paciente (masculino/feminino) e a presen√ßa de hipertens√£o (sim/n√£o).  

- **Vari√°veis:** Sexo (masculino, feminino) e hipertens√£o (sim, n√£o)  

- **Aplica√ß√£o:** Monta-se uma tabela de conting√™ncia 2x2 e aplica-se o teste de associa√ß√£o para verificar se a propor√ß√£o de hipertensos difere entre os sexos.


**Exemplos na Psicologia**

Verificar se existe associa√ß√£o entre tipo de terapia utilizada (cognitivo-comportamental, psicanal√≠tica, humanista) e desfecho do tratamento (melhorou/n√£o melhorou) em pacientes.  

- **Vari√°veis:** Tipo de terapia (tr√™s categorias) e desfecho (melhorou, n√£o melhorou)  

- **Aplica√ß√£o:** Monta-se uma tabela de conting√™ncia 3x2 e aplica-se o teste associa√ß√£o para analisar se o tipo de terapia est√° associado ao desfecho.


**Exemplo na Educa√ß√£o F√≠sica** 

Analisar se h√° associa√ß√£o entre a participa√ß√£o em atividades extracurriculares (sim/n√£o) e o n√≠vel de aptid√£o f√≠sica (baixo/m√©dio/alto) em estudantes do ensino m√©dio.  

- **Vari√°veis:** Participa√ß√£o em atividades (sim, n√£o) e aptid√£o f√≠sica (baixo, m√©dio, alto)  

- **Aplica√ß√£o:** Cria-se uma tabela de conting√™ncia 2x3 e utiliza-se o teste de associa√ß√£o para verificar se a aptid√£o f√≠sica difere conforme a participa√ß√£o em atividades extracurriculares.


### Teste Qui-Quadrado

O teste **qui-quadrado** ($\chi^2$) √© um dos m√©todos mais utilizados para avaliar se existe associa√ß√£o entre duas vari√°veis categ√≥ricas. Ele funciona comparando as frequ√™ncias observadas nas c√©lulas de uma tabela de conting√™ncia com as frequ√™ncias que seriam esperadas caso n√£o houvesse rela√ß√£o entre as vari√°veis.

- **Hip√≥tese nula ($H_0$):** N√£o existe associa√ß√£o entre as vari√°veis ‚Äúx‚Äù e ‚Äúy‚Äù, ou seja, elas s√£o independentes.
- **Hip√≥tese alternativa ($H_1$):** Existe associa√ß√£o entre as vari√°veis.

**Principais requisitos:**

- A amostra deve ser aleat√≥ria.

- Pelo menos 80% das c√©lulas da tabela devem ter frequ√™ncia esperada igual ou superior a 5.

- Nenhuma c√©lula deve ter frequ√™ncia esperada igual a zero.

> **Observa√ß√£o:** Nenhuma c√©lula deve ter frequ√™ncia esperada igual a zero porque, no teste qui-quadrado, a f√≥rmula envolve dividir pela frequ√™ncia esperada. Se algum valor esperado for zero, n√£o √© poss√≠vel fazer a divis√£o, pois divis√£o por zero √© indefinida. Al√©m disso, uma frequ√™ncia esperada igual a zero indica que, teoricamente, aquela combina√ß√£o de categorias n√£o deveria ocorrer nunca, o que torna os c√°lculos e os resultados do teste estat√≠stico inv√°lidos ou sem sentido. Por isso, √© importante garantir que todas as c√©lulas tenham valores esperados maiores que zero para que o teste seja matematicamente correto e confi√°vel.

O teste qui-quadrado pode ser aplicado em tabelas maiores que 2x2.

### Teste Exato de Fisher

O **teste exato de Fisher** √© recomendado quando os tamanhos das amostras s√£o pequenos ou quando as frequ√™ncias esperadas em alguma c√©lula da tabela s√£o menores que 5, situa√ß√£o em que o teste qui-quadrado pode n√£o ser confi√°vel.

- **Hip√≥tese nula ($H_0$):** N√£o existe associa√ß√£o entre as vari√°veis ‚Äúx‚Äù e ‚Äúy‚Äù, ou seja, elas s√£o independentes.
- **Hip√≥tese alternativa ($H_1$):** Existe associa√ß√£o entre as vari√°veis.

- √â mais conservador do que o qui-quadrado, pois calcula a probabilidade exata de ocorr√™ncia das frequ√™ncias observadas.

- Tradicionalmente, √© utilizado para tabelas 2x2 (dois grupos e duas categorias), mas pode ser estendido a tabelas maiores com recursos computacionais.

- N√£o depende das condi√ß√µes de frequ√™ncia esperada m√≠nima.

### Exemplo no R

Vamos analisar se h√° associa√ß√£o entre sexo (Masculino/Feminino) e presen√ßa de doen√ßa (Sim/N√£o) com os seguintes dados, da tabela de conting√™ncia que foi mencionada anteriormente:

|              | Doen√ßa: Sim | Doen√ßa: N√£o |  
|--------------|:-----------:|:-----------:|  
| Masculino    |      8      |      7      |  
| Feminino     |      5      |     10      |  


Essa tabela pode ser repassada diretamente para o R:

```{r}
# Crie a matriz de dados
tabela <- matrix(c(8, 7,       # observe o uso de matrix() e c()
                   5, 10),     # observe os parentes  
                 nrow = 2,     # numero de linhas 
                 byrow = TRUE) # voc√™ est√° informando por linhas (by row)
                 
# √© opcional, mas ficar√° mais claro que se voc√™ nomear 
# as linhas (row) e colunas (col) da sua tabela
colnames(tabela) <- c("Doen√ßa: Sim", "Doen√ßa: N√£o")
rownames(tabela) <- c("Masculino", "Feminino")

# Veja como ficou a tabela
tabela
```

Para fazer o teste Qui-quadrado no R usamos `chisq.test()`:

```{r}
# Aplicando o teste qui-quadrado
resultado <- chisq.test(tabela)

# Veja o resultado
resultado
```

O resultado apresentado refere-se ao teste qui-quadrado de Pearson com a corre√ß√£o de continuidade de Yates, usada para tabelas 2x2:

A **corre√ß√£o de continuidade de Yates** √© um ajuste aplicado ao teste qui-quadrado em tabelas 2x2 para evitar superestima√ß√£o da signific√¢ncia estat√≠stica, especialmente em amostras pequenas. Ela consiste em diminuir a diferen√ßa entre os valores observados e esperados antes de calcular o qui-quadrado, tornando o teste mais conservador.

- **X-squared**: Valor do qui-quadrado calculado $\chi^2 = 0,543$.  
- **df**: Graus de liberdade (1), determinado pelo n√∫mero de linhas e colunas da tabela.  O c√°lculo √© feito pela f√≥rmula:  
  **df = (n√∫mero de linhas ‚Äì 1) √ó (n√∫mero de colunas ‚Äì 1)**.  
  No exemplo, temos 2 linhas e 2 colunas: (2‚Äì1) √ó (2‚Äì1) = 1.
- **p-value**: Valor de p (0,4612)

Como o valor de p √© 0,4612 (maior do que o n√≠vel de signific√¢ncia de 0,05), **n√£o h√° evid√™ncias suficientes para rejeitar a hip√≥tese nula**. Portanto, n√£o foi encontrada associa√ß√£o estatisticamente significativa entre sexo e presen√ßa de doen√ßa nessa amostra.


E, caso queira vizualizar as tabelas de valores observados e esperados basta fazer o seguinte: 

```{r}
# Exibir os valores observados
resultado$observed

# Exibir os valores esperados
resultado$expected
```

> **Observa√ß√£o:** Se alguma frequ√™ncia esperada for menor que 5, o R emitir√° um alerta. Nesses casos, considere usar o teste exato de Fisher:
>
> ```r
> fisher.test(tabela)
> ```

Por, exemplos se substituirmos o 7 por 1, teremos
```{r, echo=FALSE, message=FALSE, warning=TRUE}
# Crie a matriz de dados
tabela2 <- matrix(c(8, 1,       # observe o uso de matrix() e c()
                   5, 10),     # observe os parentes  
                 nrow = 2,     # numero de linhas 
                 byrow = TRUE) # voc√™ est√° informando por linhas (by row)
                 
# √© opcional, mas ficar√° mais claro que se voc√™ nomear 
# as linhas (row) e colunas (col) da sua tabela
colnames(tabela2) <- c("Doen√ßa: Sim", "Doen√ßa: N√£o")
rownames(tabela2) <- c("Masculino", "Feminino")

# Veja como ficou a tabela
tabela2

# Aplicando o teste qui-quadrado
resultado <- chisq.test(tabela2)

# Veja o resultado
resultado

# trocando por teste de Fisher 
fisher.test(tabela2)
```
- **p-value = 0.01306:** O valor de p √© menor que 0,05, indicando que existe uma associa√ß√£o estatisticamente significativa entre as duas vari√°veis analisadas. Isso significa que a chance de observarmos essa diferen√ßa (ou uma diferen√ßa maior) apenas por acaso √© de aproximadamente 1,3%.

- **Odds ratio = 14.07:** A raz√£o de chances estimada √© 14 vezes maior em um grupo do que no outro, sugerindo uma associa√ß√£o forte entre as categorias das vari√°veis.

- **Intervalo de confian√ßa (1,30 a 774,69):** O intervalo de confian√ßa de 95% mostra que a raz√£o de chances verdadeira, na popula√ß√£o, pode variar de cerca de 1,3 at√© 774,7. Como esse intervalo n√£o inclui o valor 1, refor√ßa-se a evid√™ncia de associa√ß√£o.

### Observa√ß√£o sobre tabelas de conting√™ncia em artigos cient√≠ficos

Quando lemos um artigo que apresenta uma **tabela de conting√™ncia** (por exemplo, uma tabela cruzando sexo e presen√ßa de doen√ßa), estamos vendo exatamente a amostra utilizada pelo autor, com a distribui√ß√£o real dos indiv√≠duos nos diferentes grupos. Isso √© diferente do que ocorre em testes de compara√ß√£o de m√©dias (como t-teste) ou correla√ß√£o, onde geralmente temos acesso apenas a medidas-resumo (como m√©dia, desvio-padr√£o, coeficiente de correla√ß√£o), e n√£o aos dados individuais.

Nesse sentido, **ter a tabela de conting√™ncia √© praticamente o mesmo que ter os dados brutos** dos autores, pois conhecemos exatamente a quantidade de participantes em cada combina√ß√£o de categorias. Isso possibilita que qualquer leitor possa refazer os c√°lculos dos testes estat√≠sticos (como o qui-quadrado ou Fisher) e, inclusive, explorar outras an√°lises categ√≥ricas de interesse.

Em resumo, a tabela de conting√™ncia oferece um grau de transpar√™ncia e reprodutibilidade muito maior do que apenas apresentar medidas-resumo, pois exp√µe toda a estrutura dos dados da amostra analisada.


## Tamanho do Efeito: Medidas de Associa√ß√£o

Ao realizar testes de independ√™ncia como o Qui-Quadrado ou o teste exato de Fisher para tabelas de conting√™ncia, √© importante n√£o apenas analisar o p-valor, mas tamb√©m quantificar o tamanho do efeito, ou seja, a for√ßa da associa√ß√£o entre as vari√°veis categ√≥ricas.

A seguir s√£o mostradas as principais medidas de tamanho de efeito. 

### V de Cramer

- **Descri√ß√£o**: mede a intensidade da associa√ß√£o entre duas vari√°veis categ√≥ricas. Varia de 0 (nenhuma associa√ß√£o) a 1 (associa√ß√£o perfeita).
- **Uso**: Indicado para tabelas de conting√™ncia de qualquer dimens√£o.

**F√≥rmula:**
\[
V = \sqrt{\frac{\chi^2}{n(k-1)}}
\]

- \(\chi^2\) = valor do teste Qui-Quadrado

- \(n\) = total de observa√ß√µes

- \(k\) = menor n√∫mero entre linhas ou colunas

**No R:**
```{r, message=FALSE, warning=FALSE}
library(rcompanion)
cramerV(tabela)
```
ou
```{r, message=FALSE, warning=FALSE}
library(DescTools)
CramerV(tabela)
```

###  Phi de Pearson $(\phi)$

- **Descri√ß√£o**: Medida de associa√ß√£o para tabelas 2x2. Varia de 0 a 1.
- **Uso**: Exclusivo para tabelas 2x2.

**F√≥rmula:**
\[
\phi = \sqrt{\frac{\chi^2}{n}}
\]

**No R:**
```{r, message=FALSE, warning=FALSE}
library(DescTools)
Phi(tabela)
```

Interpreta√ß√£o dos valores:

- **V de Cramer**:
  - Pequeno: ~ 0,1
  - Moderado: ~ 0,3
  - Forte: ~ 0,5 ou mais

- **Phi**: Interpreta√ß√£o semelhante ao V de Cramer para 2x2.

No exemplo, o valor obtido para o **V de Cramer** ou **Phi** foi de **0,20**. De acordo com os crit√©rios usuais para essa medida, valores em torno de 0,1 indicam associa√ß√£o pequena, valores pr√≥ximos de 0,3 associa√ß√£o moderada e valores a partir de 0,5 associa√ß√£o forte entre as vari√°veis analisadas.

Al√©m disso, como o teste estat√≠stico realizado (por exemplo, Qui-Quadrado ou Fisher) indicou que **n√£o h√° associa√ß√£o significativa** entre as vari√°veis (p>0,05), o resultado do V de Cramer refor√ßa essa conclus√£o. Um valor de 0,20 sugere uma associa√ß√£o fraca, e como n√£o h√° signific√¢ncia estat√≠stica, n√£o se pode afirmar que exista uma rela√ß√£o relevante entre as vari√°veis na popula√ß√£o estudada.

### Odds Ratio (Raz√£o de Chances)

- **Descri√ß√£o**: O Odds Ratio (OR) mede a for√ßa da associa√ß√£o entre dois eventos em tabelas 2x2, comparando as chances (odds) de um evento ocorrer em dois grupos diferentes. Ele indica se a ocorr√™ncia do evento em um grupo √© mais, menos ou igualmente prov√°vel em rela√ß√£o ao outro grupo.

- **Uso**: Teste de Fisher e tabelas 2x2.

Considere a estrutura da tabela 2x2:

|                   | Evento Presente | Evento Ausente |
|-------------------|:-----------------:|:---------------:|
| **Grupo 1**       | a               | b             |
| **Grupo 2**       | c               | d             |

Ent√£o odds ratio (OR), pode ser facilmente calculado: 

\[
OR = \frac{a \times d}{b \times c}
\]

Onde:

- **a** = n√∫mero de casos com o evento presente no Grupo 1  
- **b** = n√∫mero de casos com o evento ausente no Grupo 1  
- **c** = n√∫mero de casos com o evento presente no Grupo 2  
- **d** = n√∫mero de casos com o evento ausente no Grupo 2  

A interpreta√ß√£o do OR √© a seguinte:

- **OR = 1:**  
  N√£o h√° diferen√ßa entre os grupos. O evento tem a mesma chance de acontecer no Grupo 1 e no Grupo 2.  
  **Exemplo:** Se o OR for 1, os dois grupos t√™m risco igual para o evento.

- **OR > 1:**  
  O evento √© mais prov√°vel no **Grupo 1** do que no Grupo 2.  
  **Exemplo:** Se o OR for 2, o Grupo 1 tem o dobro de chance do evento comparado ao Grupo 2.

- **OR < 1:**  
  O evento √© menos prov√°vel no **Grupo 1** do que no Grupo 2.  
  **Exemplo:** Se o OR for 0,5, o Grupo 1 tem metade da chance do evento comparado ao Grupo 2.

  
**No R:**
```{r} 
fisher.test(tabela)$estimate
```


O **odds ratio (OR)** calculado foi de **2,22**.

- O OR compara as chances de ocorr√™ncia da doen√ßa entre os grupos "Masculino" e "Feminino".

- **OR = 2,22** indica que as chances de um indiv√≠duo do sexo masculino ter a doen√ßa s√£o aproximadamente **2,2 vezes maiores** do que as chances de um indiv√≠duo do sexo feminino.

- Em outras palavras, a doen√ßa √© mais prov√°vel entre os homens do que entre as mulheres neste conjunto de dados.


Ou usando o pacote `epitools`:
```{r} 
# install.packages("epitools")
library(epitools)
oddsratio(tabela)
```


- O odds ratio (OR) indica que as chances de "Doen√ßa: Sim" s√£o cerca de 2,2 vezes maiores no grupo **Masculino** em rela√ß√£o ao grupo **Feminino**.

- O intervalo de confian√ßa (IC) de 95% para o OR do grupo Feminino √© de 0,50 a 10,61, o que inclui o valor 1. Isso sugere que esta diferen√ßa **n√£o √© estatisticamente significativa**.

- Valores de p

| Grupo     | midp.exact | fisher.exact | chi.square |
|-----------|:------------:|:--------------:|:------------:|
| Feminino  |  0,3008    |   0,4621     |  0,2690    |

- Todos os valores de p s√£o **maiores do que 0,05**, indicando que n√£o h√° associa√ß√£o estatisticamente significativa entre sexo e presen√ßa de doen√ßa nesta amostra.

- O uso da fun√ß√£o `oddsratio()` do pacote `epitools` mostrou um OR de 2,2 para o grupo masculino, mas essa diferen√ßa (entre os grupos feminino e masculino) n√£o √© estatisticamente significativa. Isso significa que, com base nesses dados, n√£o se pode concluir que h√° uma associa√ß√£o real entre sexo e presen√ßa de doen√ßa.

## C√°lculo do Poder Estat√≠stico

O poder estat√≠stico pode ser estimado usando o pacote `pwr`, √∫til para calcular tamanho de efeito ou tamanho de amostra necess√°rio.

```{r poder-estatistico}
# Exemplo para efeito 0,2, alfa = 0.05 e N = 30 (OBSERVE o N em MAI√öSCULO, tamanho da amostra)
pwr.chisq.test(w = 0.2, df = 1, N = 30, sig.level = 0.05)
```

- **w (tamanho do efeito):**
  - Representa o tamanho do efeito, w √© igual ao V de Cramer

- **df (graus de liberdade):**
  - Indica o n√∫mero de graus de liberdade do teste.
  - Em uma tabela de conting√™ncia, √© calculado como:  
    (n√∫mero de linhas ‚Äì 1) √ó (n√∫mero de colunas ‚Äì 1)
  - Exemplo: Para uma tabela 2x2, df = (2-1) √ó (2-1) = 1

Com uma amostra de 30 indiv√≠duos, tentando detectar um efeito pequeno (w = 0,2) em um teste do qui-quadrado com 1 grau de liberdade e n√≠vel de signific√¢ncia de 5%, o poder do teste √© de apenas cerca de **19,5%**.

Isso significa que, se realmente existir uma associa√ß√£o do tamanho especificado entre as vari√°veis, o teste s√≥ ter√° cerca de 19,5% de chance de detectar essa associa√ß√£o (ou seja, rejeitar a hip√≥tese nula corretamente).

**Em geral, recomenda-se um poder estat√≠stico de pelo menos 80%** (0,8) para que o teste tenha boa chance de detectar uma associa√ß√£o real. Portanto, **com essa configura√ß√£o, o teste est√° subdimensionado (pouco poder)** para detectar efeitos pequenos.

<!--chapter:end:22-Associacao.Rmd-->

`r if (knitr:::is_html_output()) '
# Refer√™ncias {-}
'`

<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/private_files/lf30_rklapo5f.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>



- **Cohen, J. (1988).** Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Lawrence Erlbaum Associates.

- **Field, A. (2013).** Discovering Statistics Using IBM SPSS Statistics (4th ed.). Sage.

- **Romano, J., Kromrey, J. D., Coraggio, J., & Skowronek, J. (2006).** Appropriate statistics for ordinal level data: Should we really be using t-test and Cohen‚Äôs d for evaluating group differences on the NSSE and other surveys? *Annual Meeting of the Florida Association of Institutional Research*, Jacksonville, FL, USA.

- **Cliff, N. (1993).** Dominance statistics: Ordinal analyses to answer ordinal questions. *Psychological Bulletin, 114*(3), 494-509. https://doi.org/10.1037/0033-2909.114.3.494

<!--chapter:end:23-Referencias.Rmd-->

