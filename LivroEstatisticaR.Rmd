---
title: "EstatÃ­stica + R"
author: "Ana Paula Fernandes (DESCO/ICS/UFTM)"
date: "Atualizado em: `r format(Sys.time(), '%d/%m/%Y')`"
site: bookdown::bookdown_site
documentclass: book
bibliography: referencias.bib
biblio-style: apalike
link-citations: true
csl: "https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl"
language: "pt-BR"
---

# Bem-vindos!

<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/8e0b4579-4516-47c6-a45a-6e6744211efc/WpKBlZ2U4F.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>

</center>

Esse livro *online* tem como propÃ³sito principal ser um guia para as aulas de estatÃ­stica, referente as disciplinas de **BioestatÃ­stica** para os cursos de Medicina e EducaÃ§Ã£o FÃ­sica e **EstatÃ­stica Aplicada** para o curso de Psicologia da [Universidade Federal do TriÃ¢ngulo Mineiro - UFTM](http://www.uftm.edu.br). E como objetivo secundÃ¡rio, ser uma referÃªncia de consulta para todos os discentes que passaram por essas disciplinas, bem como, para todos que estÃ£o interessados em realizar anÃ¡lises de dados por meio da linguagem R e o ambiente de desenvolvimento RStudio.

SugestÃµes, correÃ§Ãµes ou qualquer outra forma de interaÃ§Ã£o sÃ£o sempre bem-vindas! EntÃ£o, por favor, nÃ£o hesite em me escrever ([anapaula.fernandes\@uftm.edu.br](mailto:anapaula.fernandes@uftm.edu.br){.email}).

Para mais informaÃ§Ãµes sobre minha trajetÃ³ria acadÃªmica e profissional, acesse meu [CurrÃ­culo Lattes](https://lattes.cnpq.br/5582801060910261).

> Esta obra, registrada sob o **ISBN 978-65-01-56980-2**, traz conteÃºdos atualizados e essenciais para estudantes e profissionais interessados no tema.


```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(magick)
img <- image_read_pdf("ficha-284399.pdf", density = 150)
image_write(img, path = "ficha.svg", format = "svg")
cat('<center><img src="ficha.svg" width="50%" heigth="10px"/></center>')

```

<!--chapter:end:index.Rmd-->

---
output:
  html_document: default
  pdf_document: default
---
# IntroduÃ§Ã£o 

Ao longo de algum tempo ministrando aulas de estatÃ­stica, concluÃ­ que estudar estatÃ­stica com auxÃ­lio de recursos computacionais Ã© bem mais eficaz.  Quero dizer, Ã© mais fÃ¡cil entender os conceitos teÃ³ricos, lidar com recursos visuais (grÃ¡ficos) e, de fato, transformar o conteÃºdo estudado na disciplina em uma ferramenta para pesquisas cientÃ­ficas, quando se trata de analisar dados.

## ğŸ’¥ Desconstruindo Mitos

Ministrando aulas para os cursos da Ã¡rea de **saÃºde**, **esporte** e **psicologia**, sempre ouvi dos discentes que "estatÃ­stica Ã© matemÃ¡tica", e sempre digo que **estatÃ­stica Ã© estatÃ­stica!** 

Ã‰ normal alguns discentes nÃ£o assimilarem, em princÃ­pio, a importÃ¢ncia da disciplina na grade do seu curso.  Alguns acham atÃ© que Ã© um assunto que deveria ficar restrito aos cursos das exatas.  Assim, a primeira tarefa Ã© sempre desconstruir essa ideia. 

### A EstatÃ­stica Ã© MULTIDISCIPLINAR

A estatÃ­stica estÃ¡ em tudo na verdade... e para dizer uma coisa "bem chique":  **a estatÃ­stica Ã© a base da InteligÃªncia Artificial**. 

Advinha quem estÃ¡ por trÃ¡s: 

- ğŸ¤– dos famosos algoritmos das redes sociais

- ğŸ¬ das sugestÃµes de filmes e mÃºsicas que aparecem no seu *streaming* favorito

- ğŸ” do ranqueamento de busca realizado por meio do *Google*?

- ğŸ’¬ dos agentes de IA

---

## ğŸ”§ AplicaÃ§Ãµes PrÃ¡ticas da EstatÃ­stica

E sendo um pouco mais "acadÃªmica", dentro do nosso propÃ³sito:

### ğŸƒ No Esporte

Qualquer competiÃ§Ã£o ou treinamento esportivo estÃ¡ recheado de estatÃ­stica.  Como medir o desempenho de um time ou atleta? 

**Exemplo:**

> **Uso de suplementos alimentares e acompanhamento nutricional por frequentadores de academias**  
> ğŸ“„ <https://www.rbne.com.br/index.php/rbne/article/view/2440>

### ğŸ¥ Na Medicina

Estudos epidemiolÃ³gicos e, claro, da medicina baseada em evidÃªncias tÃªm o suporte da estatÃ­stica. 

**Exemplo:**

> **SÃ­ndrome Coronariana Aguda no Brasil: Registro dos Fatores Predisponentes e Perfil Populacional em um Instituto CardiolÃ³gico PÃºblico de ReferÃªncia Nacional**  
> ğŸ“„ <https://www.scielo.br/j/abc/a/gPrBrwLpGxWgzjFCgLkJJLN/?format=html&lang=pt>

### ğŸ§  Na Psicologia

Na psicologia, a estatÃ­stica Ã© a ferramenta utilizada na psicometria. 

**Exemplo:**

> **AvaliaÃ§Ã£o do sofrimento psÃ­quico em estudantes do internato mÃ©dico**  
> ğŸ“„ <https://acervomais.com.br/index.php/cientifico/article/view/21295>

---

## ğŸ’¡ Desafio para VocÃª

Basta realizar uma busca com os termos **"estatÃ­stica"** + **um campo do seu curso que vocÃª se interessa**, que vocÃª encontrarÃ¡ um artigo cientÃ­fico. 

> **E se vocÃª nÃ£o encontrar, comece a escrever sobre o tema! ** ğŸš€

---

### ğŸ“š PeriÃ³dicos Recomendados por Ãrea

Para facilitar sua pesquisa, aqui estÃ£o alguns periÃ³dicos cientÃ­ficos organizados por Ã¡rea de conhecimento:

#### ğŸƒâ€â™‚ï¸ CiÃªncia dos Esportes

| PeriÃ³dico | Link |
|-----------|------|
| **RBFF** - Revista Brasileira de Futsal e Futebol | <http://www.rbff.com.br> |
| **RBME** - Revista Brasileira de Medicina do Esporte | <https://www.scielo.br/j/rbme> |
| **RBPE** - Revista Brasileira de Psicologia do Esporte | <http://pepsic.bvsalud.org> |

#### ğŸ¥ Medicina e SaÃºde

| PeriÃ³dico | Link |
|-----------|------|
| **RBC** - Revista Brasileira de Cancerologia | <https://rbc.inca.gov.br/index.php/revista> |
| **RBCMS** - Revista Brasileira de CiÃªncias MÃ©dicas e da SaÃºde | <http://www.rbcms.com.br> |
| **ABRASCO** - Revista da AssociaÃ§Ã£o Brasileira de SaÃºde Coletiva | <https://cienciaesaudecoletiva.com.br> |

#### ğŸ§  Psicologia

| PeriÃ³dico | Link |
|-----------|------|
| **Psicologia Argumento** | <https://periodicos.pucpr.br/psicologiaargumento> |
| **Estudos de Psicologia** (Campinas) | <https://www.scielo.br/j/estpsi/> |
| **Psicologia em Foco** | <https://revistas.fw.uri.br/index.php/psicologiaemfoco> |

---

### ğŸ” Outras Ferramentas de Busca AcadÃªmica

Expanda sua pesquisa utilizando estas bases de dados e ferramentas especializadas:

- ğŸ“š **[Mendeley](https://www.mendeley.com)** - Gerenciador de referÃªncias e descoberta de artigos cientÃ­ficos
- ğŸŒ **[SciELO](https://scielo.org)** - Scientific Electronic Library Online (foco em AmÃ©rica Latina)
- ğŸ” **[Google Scholar](https://scholar.google.com)** - Busca abrangente em literatura acadÃªmica
- ğŸ¥ **[PubMed](https://pubmed.ncbi.nlm.nih.gov)** - Especializada em ciÃªncias biomÃ©dicas e da saÃºde

**ğŸ’¡ Dica de busca avanÃ§ada:**
- Use `"aspas"` para termos exatos: `"anÃ¡lise estatÃ­stica"`
- Combine com operadores:  `estatÃ­stica AND psicologia`
- Filtre por perÃ­odo: adicione ano nas opÃ§Ãµes de busca

---

## ğŸ“Š Tipos de AnÃ¡lise EstatÃ­stica

Quando olhamos os artigos acima, podemos ver que todos eles tÃªm resultados **descritivos** e **inferenciais**: 

| Tipo | DescriÃ§Ã£o |
|------|-----------|
| **ğŸ“ˆ EstatÃ­stica Descritiva** | Descrever os dados amostrados para uma dada anÃ¡lise |
| **ğŸ”¬ EstatÃ­stica Inferencial** | Inferir - tirar conclusÃµes a partir dos dados amostrados |

Discutiremos sobre ambas ao longo do curso! 

---

## ğŸ¯ ConclusÃ£o

A estatÃ­stica nÃ£o Ã© apenas matemÃ¡tica abstrata - Ã© uma **ferramenta essencial** para transformar dados em conhecimento, independentemente da sua Ã¡rea de atuaÃ§Ã£o! 

---

<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>
</center>

## ğŸ“‹ Atividade 1: Explorando a EstatÃ­stica na Pesquisa CientÃ­fica

A metodologia cientÃ­fica Ã© composta por etapas estruturadas que guiam o processo de investigaÃ§Ã£o.   **A estatÃ­stica estÃ¡ presente em vÃ¡rias dessas etapas**, desde o planejamento da coleta de dados atÃ© a anÃ¡lise e interpretaÃ§Ã£o dos resultados.  Nesta atividade, vocÃª irÃ¡ identificar como a estatÃ­stica Ã© aplicada em um estudo real da sua Ã¡rea de interesse.

---

### ğŸ¯ Objetivo da Atividade

**Busque um artigo cientÃ­fico do campo de seu interesse que utiliza a estatÃ­stica.**

Ao analisar o artigo, vocÃª irÃ¡ mapear as principais etapas da metodologia cientÃ­fica e identificar onde e como a estatÃ­stica foi aplicada. 

---

### ğŸ“ Roteiro de AnÃ¡lise

 **1ï¸âƒ£ PROBLEMA DE PESQUISA - Qual Ã© o principal objetivo da pesquisa?**

> *Na metodologia cientÃ­fica, toda pesquisa comeÃ§a com uma pergunta ou problema a ser investigado.*

**Reflita:**

- â“ Qual Ã© a questÃ£o central que a pesquisa busca responder?

- ğŸ¯ Os autores apresentam claramente os objetivos do estudo? 

- ğŸ“Š O que se espera alcanÃ§ar com os resultados? 

- ğŸ’¡ Existem hipÃ³teses formuladas?  Se sim, quais sÃ£o?

---

 **2ï¸âƒ£ METODOLOGIA - Como a pesquisa foi conduzida?**

> *A metodologia descreve o "caminho" percorrido pelo pesquisador.   Ã‰ aqui que a estatÃ­stica comeÃ§a a aparecer no planejamento da pesquisa.*

**Analise os seguintes aspectos:**

| Aspecto | O que observar no artigo |
|---------|--------------------------|
| **ğŸ”¬ Tipo de pesquisa** | A pesquisa Ã© qualitativa, quantitativa ou mista? |
| **ğŸ‘¥ PopulaÃ§Ã£o e Amostra** | Qual Ã© a populaÃ§Ã£o-alvo? Quantos participantes compÃµem a amostra? |
| **ğŸ§® CÃ¡lculo Amostral** | Os autores justificam o tamanho da amostra? Foi realizado cÃ¡lculo amostral? |
| **ğŸ“Š TÃ©cnica de Amostragem** | Como os participantes foram selecionados? (aleatÃ³ria, por conveniÃªncia, estratificada, etc.) |
| **ğŸ“‹ Instrumentos de Coleta** | Quais instrumentos foram utilizados? (questionÃ¡rios, testes, mediÃ§Ãµes, observaÃ§Ãµes, etc.) |
| **ğŸ“ˆ AnÃ¡lise EstatÃ­stica** | Quais tÃ©cnicas estatÃ­sticas foram aplicadas para analisar os dados? |
| **ğŸ’» Software Utilizado** | Qual programa foi usado para as anÃ¡lises? (SPSS, R, Python, Excel, etc.) |

**ğŸ’­ Reflita:** *Por que essas escolhas metodolÃ³gicas sÃ£o importantes para a validade da pesquisa?*

---

 **3ï¸âƒ£ RESULTADOS - O que Ã© apresentado por meio de tabelas ou grÃ¡ficos?**

> *A estatÃ­stica descritiva organiza e resume os dados coletados, facilitando a visualizaÃ§Ã£o e interpretaÃ§Ã£o dos resultados.*

**Observe:**

- ğŸ“Š Quais informaÃ§Ãµes estÃ£o sendo representadas visualmente?

- âœ… Os grÃ¡ficos e tabelas sÃ£o claros e bem organizados? 

- ğŸ” Que tipo de grÃ¡ficos foram utilizados?  (barras, dispersÃ£o, boxplot, histograma, pizza, etc.)

- ğŸ“‰ Os dados apresentados respondem aos objetivos da pesquisa? 

- ğŸ’¬ Como os autores interpretam os resultados a partir dessas representaÃ§Ãµes?

**ğŸ’¡ Dica:** *Preste atenÃ§Ã£o nas legendas, tÃ­tulos e notas de rodapÃ© das tabelas e grÃ¡ficos - eles contÃªm informaÃ§Ãµes importantes! *

---

**4ï¸âƒ£ GLOSSÃRIO ESTATÃSTICO - Termos encontrados no artigo**

> *Familiarizar-se com a terminologia estatÃ­stica Ã© essencial para compreender e aplicar essas tÃ©cnicas em suas prÃ³prias pesquisas.*

**Crie uma lista dos termos e conceitos estatÃ­sticos mencionados no artigo.**

**Exemplos do que vocÃª pode encontrar:**

| Categoria | Exemplos de Termos |
|-----------|-------------------|
| **ğŸ“ Medidas Descritivas** | MÃ©dia, mediana, moda, desvio-padrÃ£o, variÃ¢ncia, percentis |
| **ğŸ“Š Tipos de VariÃ¡veis** | VariÃ¡vel dependente, independente, qualitativa, quantitativa |
| **ğŸ”¬ Testes de HipÃ³tese** | Teste t, ANOVA, qui-quadrado, Mann-Whitney, Kruskal-Wallis |
| **ğŸ“ˆ AnÃ¡lises de RelaÃ§Ã£o** | CorrelaÃ§Ã£o de Pearson, Spearman, regressÃ£o linear, regressÃ£o logÃ­stica |
| **ğŸ¯ Conceitos Inferenciais** | Intervalo de confianÃ§a, nÃ­vel de significÃ¢ncia, p-valor, poder do teste, tamanho do efeito |
| **ğŸ“ Outros** | Normalidade, homocedasticidade, distribuiÃ§Ã£o, outliers |

**âœï¸ Para cada termo identificado:**

- Anote a pÃ¡gina onde aparece

- Tente definir com suas prÃ³prias palavras

- Pesquise o significado caso nÃ£o conheÃ§a

---

### ğŸ“ ReflexÃ£o Final

ApÃ³s completar esta anÃ¡lise, vocÃª serÃ¡ capaz de: 

âœ… Reconhecer como a estatÃ­stica se integra Ã s etapas da metodologia cientÃ­fica  
âœ… Identificar as principais tÃ©cnicas estatÃ­sticas aplicadas na sua Ã¡rea  
âœ… Compreender a importÃ¢ncia do planejamento estatÃ­stico para a qualidade da pesquisa  
âœ… Desenvolver um olhar crÃ­tico sobre a apresentaÃ§Ã£o e interpretaÃ§Ã£o de dados  

**ğŸ’¬ QuestÃ£o BÃ´nus:** *Com base no artigo analisado, que decisÃµes metodolÃ³gicas vocÃª faria diferente se fosse conduzir uma pesquisa semelhante?*

---


# Conceitos Fundamentais

Antes de mergulharmos nas anÃ¡lises estatÃ­sticas, Ã© fundamental compreender dois conceitos essenciais que formam a base de qualquer estudo quantitativo:  **EstatÃ­stica Descritiva** e **EstatÃ­stica Inferencial**. 

Pense assim: a EstatÃ­stica Descritiva **organiza e resume** os dados que vocÃª coletou, enquanto a EstatÃ­stica Inferencial **tira conclusÃµes** sobre uma populaÃ§Ã£o maior a partir da amostra. 

Vamos entender cada uma com exemplos prÃ¡ticos! 

---

## ğŸ“Š EstatÃ­stica Descritiva

> **O que Ã©? **  
> A EstatÃ­stica Descritiva organiza, resume e apresenta dados de forma clara e compreensÃ­vel, usando tabelas, grÃ¡ficos e medidas numÃ©ricas.

### ğŸ’­ Exemplo 1: SaÃºde Mental dos Estudantes

Imagine que vocÃª deseja avaliar a **saÃºde mental dos estudantes da UFTM**, coletando informaÃ§Ãµes sobre: 

- NÃ­veis de **estresse**

- NÃ­veis de **ansiedade**  

- PresenÃ§a de **depressÃ£o**

- **Bem-estar geral**

> **Como esses dados sÃ£o coletados? **  
> Essas informaÃ§Ãµes sÃ£o obtidas por meio de **instrumentos psicomÃ©tricos** - questionÃ¡rios e escalas cientÃ­ficas padronizadas que medem caracterÃ­sticas psicolÃ³gicas de forma objetiva e confiÃ¡vel.  Esses instrumentos passam por rigorosos processos de validaÃ§Ã£o estatÃ­stica para garantir que realmente medem o que se propÃµem a medir.

**Exemplos de instrumentos que podem ser aplicados:**

| Aspecto Avaliado | Instrumento | DescriÃ§Ã£o |
|------------------|-------------|-----------|
| **Estresse** | **PSS-10** (Escala de Estresse Percebido) | Avalia o quanto situaÃ§Ãµes da vida sÃ£o percebidas como estressantes |
| **Ansiedade** | **BAI** (InventÃ¡rio de Ansiedade de Beck) ou **GAD-7** | Medem sintomas de ansiedade em diferentes intensidades |
| **DepressÃ£o** | **BDI-II** (InventÃ¡rio de DepressÃ£o de Beck) ou **PHQ-9** | Avaliam presenÃ§a e gravidade de sintomas depressivos |
| **Bem-estar** | **Escala de Bem-Estar Subjetivo** ou **WHO-5** | Medem qualidade de vida e satisfaÃ§Ã£o geral |

ğŸ’¡ **Importante:** Embora muitos desses instrumentos possam ser aplicados por pesquisadores de diferentes Ã¡reas (nÃ£o apenas psicÃ³logos), a **interpretaÃ§Ã£o clÃ­nica** e o **diagnÃ³stico** devem ser realizados exclusivamente por profissionais habilitados em psicologia ou psiquiatria. 


#### ğŸ”§ O que a EstatÃ­stica Descritiva faz com esses dados? 

| AÃ§Ã£o | Como ajuda?  | Exemplo prÃ¡tico |
|------|-------------|-----------------|
| **1. Organizar dados** | Cria tabelas sistemÃ¡ticas | Agrupar respostas por curso, perÃ­odo, faixa etÃ¡ria |
| **2. Calcular mÃ©dias** | Resume os dados em um nÃºmero | MÃ©dia de estresse = 6,5 (escala 0-10) |
| **3. Criar grÃ¡ficos** | Facilita a visualizaÃ§Ã£o | GrÃ¡fico de barras mostrando % de alunos com ansiedade baixa/mÃ©dia/alta |
| **4. Medir variabilidade** | Mostra o quanto os dados variam | Desvio padrÃ£o alto = muita diferenÃ§a entre os alunos |
| **5. Identificar padrÃµes** | Encontra relaÃ§Ãµes entre variÃ¡veis | Alunos que dormem menos tÃªm mais estresse?  |

#### ğŸ’¡ Por que isso Ã© importante? 

Essas anÃ¡lises criam um **panorama claro** da saÃºde mental dos estudantes, fornecendo base para:

- âœ… Programas de apoio psicolÃ³gico

- âœ… PolÃ­ticas institucionais de bem-estar

- âœ… IdentificaÃ§Ã£o de grupos que precisam de mais atenÃ§Ã£o

---

### ğŸƒâ€â™‚ï¸ Exemplo 2: PrÃ¡tica de Atividades FÃ­sicas

Agora, suponha que vocÃª quer entender **como os estudantes se exercitam**. 

#### ğŸ“‹ Dados que vocÃª pode coletar:

1. **FrequÃªncia semanal**
   - Quantos alunos praticam atividades **mais de 3x por semana**?
   - Resultado: 45% dos estudantes

2. **Tipos de atividade**
   - Use um **grÃ¡fico ou tabela** para mostrar a distribuiÃ§Ã£o: 
     - ğŸƒ Corrida: 30%
     - ğŸ’ª MusculaÃ§Ã£o: 25%
     - âš½ Futebol: 20%
     - ğŸ’ƒ DanÃ§a: 15%
     - ğŸ§˜ Yoga: 10%

3. **Intensidade da prÃ¡tica**
   - Crie categorias:  leve, moderada, intensa
   - Use um **grÃ¡fico ou tabela** para comparar

#### ğŸ¯ AplicaÃ§Ã£o prÃ¡tica:

Com essas informaÃ§Ãµes, a universidade pode:

- âœ… Criar campanhas direcionadas

- âœ… Oferecer novas modalidades esportivas

- âœ… Melhorar a infraestrutura de acordo com as preferÃªncias

---

## ğŸ”¬ EstatÃ­stica Inferencial

> **O que Ã©?**  
> A EstatÃ­stica Inferencial usa dados de uma **amostra** (grupo menor) para tirar conclusÃµes sobre a **populaÃ§Ã£o inteira**, com margem de confianÃ§a conhecida.

### ğŸ’­ Exemplo 1: SaÃºde Mental dos Estudantes

VocÃª pesquisou **200 estudantes** (amostra) e quer saber sobre **todos os 6.900 estudantes** da UFTM (populaÃ§Ã£o).

#### ğŸ¯ O que a EstatÃ­stica Inferencial permite fazer?

**SituaÃ§Ã£o 1: Estimar a mÃ©dia populacional**

| Da amostra...  | Para a populaÃ§Ã£o... |
|---------------|---------------------|
| MÃ©dia de ansiedade = 7,0 (escala 0-10) | Estimativa:  ansiedade mÃ©dia de todos os estudantes estÃ¡ entre **6,5 e 7,5** |
| Baseado em 200 alunos | Com **95% de confianÃ§a** |

**SituaÃ§Ã£o 2: Comparar grupos diferentes**

Pergunta: *"Estudantes de Medicina tÃªm mais ansiedade que estudantes de Engenharia?"*


ğŸ“Š **Teste de HipÃ³tese:**

- MÃ©dia Medicina: 7,8

- MÃ©dia Engenharia: 6,2

- DiferenÃ§a: 1,6 pontos

- Resultado do teste:  DiferenÃ§a Ã© estatisticamente significativa (p < 0,05)

- ConclusÃ£o: Sim, estudantes de Medicina apresentam nÃ­veis significativamente maiores de ansiedade


#### âœ… Vantagem: 

VocÃª **nÃ£o precisa pesquisar todos os 6.900 alunos** - com uma amostra bem planejada, pode fazer afirmaÃ§Ãµes confiÃ¡veis sobre toda a universidade! 

---

### ğŸƒâ€â™‚ï¸ Exemplo 2: PrÃ¡tica de Atividades FÃ­sicas

VocÃª pesquisou **300 estudantes** de diferentes cursos. 

#### ğŸ¯ Perguntas que a EstatÃ­stica Inferencial responde:

**1. Qual a proporÃ§Ã£o real de estudantes ativos? **

- ğŸ“Š Na amostra:  60% praticam exercÃ­cios regularmente

- ğŸ“ˆ Estimativa para toda UFTM: entre 55% e 65%

- ğŸ¯ ConfianÃ§a: 95%


**2. EducaÃ§Ã£o FÃ­sica vs. Medicina: quem se exercita mais?**

- ğŸ“ EducaÃ§Ã£o FÃ­sica: 85% ativos

- ğŸ¥ Medicina: 42% ativos

- ğŸ“Š Teste estatÃ­stico: DiferenÃ§a Ã© significativa

- ğŸ’¡ ConclusÃ£o: Estudantes de EducaÃ§Ã£o FÃ­sica sÃ£o mais ativos fisicamente


---

## ğŸ² ConexÃ£o com a Probabilidade

A **Teoria de Probabilidade** Ã© a ponte entre EstatÃ­stica Descritiva e Inferencial! 

### ğŸ”— Como funciona? 

```
EstatÃ­stica Descritiva
        â†“
   (Probabilidade)
        â†“
EstatÃ­stica Inferencial
```

**Exemplo prÃ¡tico:**

Com base nos dados descritivos, podemos calcular a **probabilidade** de: 

- Um estudante desenvolver sintomas de estresse durante o semestre

- Um aluno que dorme menos de 6h ter ansiedade alta

- Estudantes que praticam exercÃ­cios terem melhor bem-estar mental

Isso permite **prever** e **prevenir**, nÃ£o apenas descrever!

---

## ğŸ‘¥ PopulaÃ§Ã£o vs. Amostra

Entender essa diferenÃ§a Ã© **FUNDAMENTAL** para qualquer pesquisa!

### ğŸŒ PopulaÃ§Ã£o

> Ã‰ o **conjunto completo** de todos os indivÃ­duos que vocÃª quer estudar.

**Exemplo UFTM:**

- ğŸ‘¨â€ğŸ“ **6.900 estudantes** (dado:  DRCA, dezembro/2024 - Incluindo:  graduaÃ§Ã£o, cursos tÃ©cnicos e pÃ³s-graduaÃ§Ã£o)

### ğŸ¯ Amostra

> Ã‰ um **grupo menor e representativo** selecionado da populaÃ§Ã£o.

**Exemplo UFTM:**

- ğŸ‘¥ **364 estudantes** selecionados aleatoriamente

- Representa toda a populaÃ§Ã£o com **95% de confianÃ§a**

- Erro mÃ¡ximo de **5%**

---

### ğŸ“ Exemplo Aplicado Completo

Vamos juntar tudo em um exemplo real:

#### ğŸ¯ Objetivo da Pesquisa
Avaliar o **bem-estar emocional** dos estudantes da UFTM. 

#### ğŸ“Š Etapa 1: Coleta de Dados (EstatÃ­stica Descritiva)
- **PopulaÃ§Ã£o:** 6.900 estudantes
- **Amostra:** 364 estudantes (seleÃ§Ã£o aleatÃ³ria)
- **Instrumento:** QuestionÃ¡rio padronizado (escala 0-10)

#### ğŸ“ˆ Etapa 2: AnÃ¡lise Descritiva

Resultados da amostra (364 estudantes):

- MÃ©dia de bem-estar:  6,8

- Desvio padrÃ£o: 1,5

- MÃ­nimo: 2,0

- MÃ¡ximo: 10,0


#### ğŸ”¬ Etapa 3: InferÃªncia EstatÃ­stica

GeneralizaÃ§Ã£o para TODA a UFTM (6.900 estudantes):

-âœ… MÃ©dia estimada: 6,8

-ğŸ“ Intervalo de confianÃ§a (IC95%): 6,46 a 7,14

-âš ï¸ Margem de erro: Â±5%

-ğŸ¯ **InterpretaÃ§Ã£o:** 
Temos 95% de confianÃ§a de que o bem-estar emocional mÃ©dio de TODOS os estudantes da UFTM estÃ¡ entre 6,46 e 7,14.


#### ğŸ’¡ O que Ã© IC95%?

Se vocÃª repetisse essa pesquisa **100 vezes** com diferentes amostras aleatÃ³rias de 364 estudantes: 

- âœ… Em **95 vezes**, a mÃ©dia estaria entre 6,46 e 7,14

- âŒ Em **5 vezes**, poderia estar fora desse intervalo (erro amostral)

---

### âœ¨ Resumo Visual

```
POPULAÃ‡ÃƒO (6.900 estudantes)
        â†“
   SeleÃ§Ã£o aleatÃ³ria
        â†“
AMOSTRA (364 estudantes)
        â†“
   EstatÃ­stica Descritiva
   (organizar, calcular, visualizar)
        â†“
   EstatÃ­stica Inferencial
   (estimar, comparar, concluir)
        â†“
CONCLUSÃ•ES sobre a POPULAÃ‡ÃƒO INTEIRA
   (com margem de erro conhecida)
```

---

## ğŸ“ Recapitulando

| Conceito | O que faz?  | Quando usar? |
|----------|------------|--------------|
| **EstatÃ­stica Descritiva** | Organiza e resume os dados | Quando vocÃª quer **descrever** o que coletou |
| **EstatÃ­stica Inferencial** | Tira conclusÃµes sobre a populaÃ§Ã£o | Quando vocÃª quer **generalizar** da amostra para todos |
| **PopulaÃ§Ã£o** | Todos que vocÃª quer estudar | Define o **alcance** da sua pesquisa |
| **Amostra** | Grupo menor representativo | Torna a pesquisa **viÃ¡vel** |
| **Probabilidade** | Calcula chances e incertezas | **Conecta** descritiva e inferencial |

---


<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>
</center>

**ğŸ’­ Agora reflita:** *Em uma pesquisa sobre hÃ¡bitos alimentares dos estudantes, como vocÃª aplicaria esses conceitos?*


# Tamanho da Amostra

## ğŸ¯ Por Que Calcular o Tamanho da Amostra?

O cÃ¡lculo do **tamanho da amostra** Ã© uma etapa **fundamental** no planejamento de qualquer pesquisa cientÃ­fica. Ele determina quantos participantes precisamos incluir no estudo para que os resultados sejam:

- âœ… **Representativos** da populaÃ§Ã£o estudada
- âœ… **Estatisticamente confiÃ¡veis** 
- âœ… **Precisos** o suficiente para responder Ã  pergunta de pesquisa
- âœ… **ViÃ¡veis** em termos de tempo e recursos

### ğŸ’¡ O Que Acontece se Erramos no Tamanho da Amostra?

| Amostra Muito Pequena | Amostra Muito Grande |
|----------------------|---------------------|
| âŒ Resultados nÃ£o confiÃ¡veis | âš ï¸ DesperdÃ­cio de recursos |
| âŒ ConclusÃµes equivocadas | âš ï¸ Tempo excessivo de coleta |
| âŒ Baixo poder estatÃ­stico | âš ï¸ Custos desnecessÃ¡rios |
| âŒ Pesquisa pode ser invalidada | âš ï¸ QuestÃµes Ã©ticas (expor mais pessoas que o necessÃ¡rio) |

> **Em resumo:** Calcular corretamente o tamanho da amostra garante que sua pesquisa seja **cientificamente vÃ¡lida** e **eticamente responsÃ¡vel**.

---

## ğŸ”¢ Tipos de CÃ¡lculo Amostral Segundo o Objetivo EstatÃ­stico

O mÃ©todo de cÃ¡lculo amostral varia conforme o que vocÃª deseja estimar ou testar:

| Objetivo da Pesquisa | Tipo de CÃ¡lculo | Quando Usar | InformaÃ§Ãµes NecessÃ¡rias |
|---------------------|----------------|-------------|------------------------|
| **Estimar uma proporÃ§Ã£o** | CÃ¡lculo para proporÃ§Ã£o | Percentual de alunos com ansiedade | Margem de erro, nÃ­vel de confianÃ§a, proporÃ§Ã£o estimada |
| **Estimar uma mÃ©dia** | CÃ¡lculo para mÃ©dia | MÃ©dia de horas de estudo por dia | Desvio padrÃ£o, margem de erro, nÃ­vel de confianÃ§a |
| **Comparar dois grupos** | Teste t ou ANOVA | Comparar estresse entre cursos | Tamanho do efeito, poder estatÃ­stico, nÃ­vel de significÃ¢ncia |
| **Testar correlaÃ§Ã£o** | CÃ¡lculo para correlaÃ§Ã£o | RelaÃ§Ã£o entre sono e desempenho | Tamanho do efeito esperado, poder estatÃ­stico |
| **Estudos experimentais** | Ensaio clÃ­nico/experimento | Efeito de uma intervenÃ§Ã£o | Grupos controle/experimental, poder, efeito esperado |

ğŸ’­ **Importante:** Cada tipo de anÃ¡lise estatÃ­stica requer uma fÃ³rmula especÃ­fica para cÃ¡lculo amostral!

---

## ğŸ“Š CÃ¡lculo Para Estimar uma ProporÃ§Ã£o: Passo a Passo

Quando o **objetivo Ã© estimar uma proporÃ§Ã£o** (por exemplo, "Qual percentual de estudantes tem ansiedade?"), precisamos de algumas informaÃ§Ãµes:

### ğŸ”‘ InformaÃ§Ãµes NecessÃ¡rias

| ParÃ¢metro | O que Ã©? | Exemplo UFTM |
|-----------|----------|--------------|
| **1. Tamanho da PopulaÃ§Ã£o (N)** | Total de indivÃ­duos que vocÃª quer estudar | 6.900 estudantes |
| **2. Margem de Erro (E)** | Quanto vocÃª aceita "errar" na estimativa | 5% (0,05) |
| **3. NÃ­vel de ConfianÃ§a** | QuÃ£o confiante vocÃª quer estar | 95% (padrÃ£o) |
| **4. ProporÃ§Ã£o Estimada (p)** | Estimativa inicial do fenÃ´meno | 50% (0,5) = pior cenÃ¡rio |

---

### ğŸ“ A FÃ³rmula

Para populaÃ§Ã£o **infinita** ou **muito grande**:

$$
n = \frac{Z^2 \cdot p \cdot (1 - p)}{E^2}
$$

**Onde:**

- $n$ = tamanho da amostra necessÃ¡rio

- $Z$ = valor da distribuiÃ§Ã£o normal padrÃ£o

  - Para 95% de confianÃ§a: **Z = 1,96**

  - Para 99% de confianÃ§a: **Z = 2,58**

- $p$ = proporÃ§Ã£o estimada (use 0,5 quando nÃ£o souber)

- $E$ = margem de erro (em decimal: 5% = 0,05)

---

### ğŸ§® Exemplo PrÃ¡tico: Pesquisa na UFTM

**SituaÃ§Ã£o:** Queremos estimar a proporÃ§Ã£o de estudantes com sintomas de ansiedade.

**Dados:**

- PopulaÃ§Ã£o: **6.900 estudantes**

- Margem de erro: **5%** (queremos estar "corretos" com Â±5%)

- NÃ­vel de confianÃ§a: **95%**

- ProporÃ§Ã£o estimada: **50%** (nÃ£o sabemos, entÃ£o usamos o pior cenÃ¡rio)

**CÃ¡lculo:**

$$
n = \frac{1,96^2 \cdot 0,5 \cdot (1 - 0,5)}{0,05^2}
$$

$$
n = \frac{3,8416 \cdot 0,5 \cdot 0,5}{0,0025}
$$

$$
n = \frac{0,9604}{0,0025} = 384,16
$$

**Resultado:** Precisamos de **384 estudantes** na amostra.

---

### ğŸ”„ Ajuste Para PopulaÃ§Ã£o Finita

Quando a populaÃ§Ã£o Ã© "pequena" (geralmente N < 10.000), aplicamos uma **correÃ§Ã£o**:

$$
n_{ajustado} = \frac{n}{1 + \frac{n-1}{N}}
$$

**Para nosso exemplo:**

$$
n_{ajustado} = \frac{384}{1 + \frac{384-1}{6900}} = \frac{384}{1 + 0,0555} = \frac{384}{1,0555} = 364
$$

**Resultado final:** Com a correÃ§Ã£o, precisamos de **364 estudantes**.

---

### ğŸ’­ Interpretando os Resultados

```
Com uma amostra de 364 estudantes:

âœ… Temos 95% de confianÃ§a nos resultados
âœ… Nossa margem de erro Ã© de Â±5%
âœ… Os resultados representam bem toda a populaÃ§Ã£o (6.900 alunos)

Exemplo prÃ¡tico:
Se 60% da amostra relata ansiedade, podemos dizer que:
"Entre 55% e 65% de TODOS os estudantes da UFTM tÃªm ansiedade"
(com 95% de confianÃ§a)
```

---

## âš ï¸ AtenÃ§Ã£o: Diferentes Objetivos = Diferentes CÃ¡lculos!

AtÃ© agora, calculamos amostra apenas para **estimar proporÃ§Ã£o** (exemplo: "Qual % de alunos tem ansiedade?").

Mas o cÃ¡lculo **muda conforme seu objetivo**. Veja:

---

### ğŸ¯ Tipos de CÃ¡lculo Amostral

| Seu Objetivo | Quando Usar | Exemplo PrÃ¡tico | O Que Muda no CÃ¡lculo |
|--------------|-------------|-----------------|----------------------|
| **Estimar PROPORÃ‡ÃƒO** | Quer saber **quantos %** | "Qual % pratica exercÃ­cios?" | Usa margem de erro e proporÃ§Ã£o estimada |
| **Estimar MÃ‰DIA** | Quer saber **valor mÃ©dio** | "Quantas horas de sono em mÃ©dia?" | Precisa do **desvio padrÃ£o** (variabilidade) |
| **Comparar GRUPOS** | Quer ver se hÃ¡ **diferenÃ§a** | "Medicina tem mais estresse que Ed. FÃ­sica?" | Precisa do **tamanho do efeito** esperado |
| **Testar CORRELAÃ‡ÃƒO** | Quer ver se hÃ¡ **relaÃ§Ã£o** | "Sono afeta o desempenho?" | Precisa da **forÃ§a da correlaÃ§Ã£o** esperada |

---

## ğŸ¤” E Quando Tenho VÃRIOS Objetivos?

### Regra Simples:

> **Calcule CADA objetivo separadamente e use a MAIOR amostra!**

### Exemplo PrÃ¡tico:

Sua pesquisa tem 4 objetivos:

```
âœ“ Estimar % com ansiedade        â†’ precisa de 364 alunos
âœ“ Calcular mÃ©dia de bem-estar    â†’ precisa de 280 alunos  
âœ“ Comparar 3 cursos              â†’ precisa de 120 alunos
âœ“ Testar correlaÃ§Ã£o sonoÃ—stress  â†’ precisa de 85 alunos

DECISÃƒO: Use 364 alunos (o maior nÃºmero)
```

**Por quÃª?** Porque 364 alunos sÃ£o suficientes para **todos** os objetivos!

---

### ğŸ’¡ Dica Extra: Ajuste para Perdas

Nem todos vÃ£o participar ou responder. Adicione uma margem de seguranÃ§a:

```
Amostra final = Amostra calculada / (1 - % de perda esperada)

Exemplo:
364 / (1 - 0,20) = 364 / 0,80 = 455 alunos

Alcance 455 amostras para garantir 364 respostas vÃ¡lidas
```

---


## ğŸ› ï¸ Ferramentas Para CÃ¡lculo de Amostra

Nosso foco aqui **nÃ£o Ã© fazer cÃ¡lculos manualmente**, mas sim **compreender os conceitos** e saber **onde buscar ajuda**. 

Hoje existem ferramentas gratuitas que fazem todo o trabalho para vocÃª!

---

### ğŸ’» Calculadoras Online (Gratuitas)

| Ferramenta | Melhor Para | Vantagens | Link |
|------------|-------------|-----------|------|
| **Calculadora USP Bauru** | ProporÃ§Ãµes e mÃ©dias simples | âœ… RÃ¡pida e intuitiva<br>âœ… Em portuguÃªs<br>âœ… NÃ£o precisa instalar | [Acessar](http://estatistica.bauru.usp.br/calculoamostral/) |
| **OpenEpi** | Estudos em saÃºde e epidemiologia | âœ… Diversos tipos de cÃ¡lculo<br>âœ… Estudos caso-controle, coorte<br>âœ… Interface simples | [Acessar](https://www.openepi.com/SampleSize/SSMean.htm) |
| **G\*Power** | ComparaÃ§Ãµes e testes complexos | âœ… Muito completo<br>âœ… PadrÃ£o em pesquisas<br>âœ… Calcula poder estatÃ­stico | [Download](https://www.gpower.hhu.de/en.html) |

---

### ğŸ“Š No Software R (Para Quem JÃ¡ Usa)

**A ideia aqui Ã© simples:** em vez de calcular manualmente usando fÃ³rmulas matemÃ¡ticas, usamos **funÃ§Ãµes prontas** que fazem tudo para nÃ³s!

---

#### **Pacote `samplingbook`** - CÃ¡lculo de Amostra para ProporÃ§Ã£o

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Instalar o pacote (se ainda nÃ£o tiver)
# install.packages("samplingbook")

# Carregar
library(samplingbook)

# Calcular amostra para proporÃ§Ã£o (considerando a populaÃ§Ã£o infinita)
sample.size.prop(
  e = 0.05,          # Margem de erro (5%)
  P = 0.5,           # ProporÃ§Ã£o estimada (50%)
  N = Inf,           # Tamanho da populaÃ§Ã£o: infinita
  level = 0.95       # NÃ­vel de confianÃ§a (95%)
  )

# Calcular amostra para proporÃ§Ã£o (considerando a populaÃ§Ã£o finita)
sample.size.prop(
  e = 0.05, 
  P = 0.5, 
  N = 6900,           # Tamanho da populaÃ§Ã£o: finita 
  level = 0.95
  )

```

**Pronto!** VocÃª precisa de **364 estudantes**

> (Sample = amostra; size = tamanho; needed = necessÃ¡rio â†’ tamanho de amostra necessÃ¡rio)

---

#### **Alternativa: FÃ³rmula Direto no R**

```{r echo=TRUE}
# CÃ¡lculo direto
N <- 6900
Z <- 1.96
p <- 0.5
E <- 0.05

n <- (Z^2 * p * (1-p)) / E^2
n_final <- ceiling(n / (1 + (n-1) / N))
n_final
```

---

#### âœ… **Vantagens**

- âš¡ RÃ¡pido e sem erros
- ğŸ“ ReprodutÃ­vel (qualquer um pode rodar)
- ğŸ”„ FÃ¡cil testar diferentes cenÃ¡rios

---

### ğŸ¤– Usando InteligÃªncia Artificial

VocÃª tambÃ©m pode pedir ajuda a **ChatGPT**, **Copilot** ou outras IAs!

**ğŸ’¬ Exemplo de prompt:**

```
"Preciso calcular o tamanho da amostra para uma pesquisa 
com estudantes universitÃ¡rios (populaÃ§Ã£o de 6.900). 
Quero estimar a proporÃ§Ã£o de alunos com ansiedade, 
com 95% de confianÃ§a e margem de erro de 5%. 
Como faÃ§o e qual o resultado?"
```

**âš ï¸ Importante:** Sempre **valide** os resultados da IA usando uma das calculadoras acima!

---

### ğŸ¯ Qual Ferramenta Escolher?

```
VocÃª Ã© iniciante?
    â†’ Calculadora USP Bauru

Pesquisa na Ã¡rea da saÃºde?
    â†’ OpenEpi

Precisa comparar grupos ou correlaÃ§Ãµes?
    â†’ G*Power

JÃ¡ usa R para anÃ¡lises?
    â†’ Pacote pwr, samplingbook

Quer entender o conceito rapidamente?
    â†’ IA + validaÃ§Ã£o em calculadora
```

---

### ğŸ’¡ Dica PrÃ¡tica

**NÃ£o sabe qual usar?** FaÃ§a o seguinte:

1ï¸âƒ£ Use uma **IA** para entender o cÃ¡lculo  
2ï¸âƒ£ Valide em uma **calculadora online**  
3ï¸âƒ£ Documente qual ferramenta usou no seu projeto  

**Exemplo de como citar:**

> *"O tamanho amostral foi calculado utilizando a Calculadora Amostral da USP Bauru (http://estatistica.bauru.usp.br/calculoamostral/), considerando populaÃ§Ã£o de 6.900 estudantes, margem de erro de 5% e nÃ­vel de confianÃ§a de 95%."*

---

## ğŸ“ ConclusÃ£o

O cÃ¡lculo do **tamanho da amostra** Ã© essencial para garantir pesquisas **precisas e confiÃ¡veis**. 

A boa notÃ­cia? **VocÃª nÃ£o precisa ser expert em matemÃ¡tica!** 

Com as ferramentas certas, esse processo se torna simples e rÃ¡pido, permitindo que vocÃª foque no que realmente importa: **planejar e executar uma pesquisa de qualidade**.

---

<center>

```{=html}
<script src="https://unpkg.com/@lottiefiles/dotlottie-wc@0.8.11/dist/dotlottie-wc.js" type="module"></script>
```

<dotlottie-wc src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" style="width: 300px;height: 300px" autoplay loop></dotlottie-wc>
</center>


## ğŸ“ Atividade 2: AnÃ¡lise CrÃ­tica do Artigo

**Com base no artigo que vocÃª buscou na Atividade 1, responda:**

---

### ğŸ” AnÃ¡lise MetodolÃ³gica

**1. Os autores discutem o cÃ¡lculo do tamanho da amostra?**

Investigue:

- âœ… HÃ¡ explicaÃ§Ã£o sobre **como** o tamanho foi determinado?

- âœ… Mencionam **fÃ³rmula**, **software** ou **ferramenta** utilizada?

- âœ… Apresentam os **parÃ¢metros** (margem de erro, confianÃ§a)?

ğŸ’­ *Se nÃ£o houver essa informaÃ§Ã£o, isso Ã© uma limitaÃ§Ã£o do estudo?*

---

**2. A populaÃ§Ã£o da pesquisa foi claramente definida?**

Verifique:

- ğŸ‘¥ Quem compÃµe a populaÃ§Ã£o-alvo?

- ğŸ“‹ HÃ¡ critÃ©rios de **inclusÃ£o e exclusÃ£o**?

- ğŸŒ O contexto estÃ¡ bem delimitado (local, perÃ­odo)?

ğŸ’­ *Uma populaÃ§Ã£o mal definida compromete a validade dos resultados.*

---

**3. O tamanho da amostra utilizado foi adequado?**

Avalie criticamente:

- âœ… A amostra parece **grande o suficiente**?

- âš–ï¸ Ã‰ **representativa** da populaÃ§Ã£o?

- âš ï¸ Os autores discutem **limitaÃ§Ãµes** relacionadas ao tamanho da amostra?

---

### ğŸ§® CÃ¡lculo PrÃ¡tico

**4. RefaÃ§a o cÃ¡lculo do tamanho de amostra**

Use uma das ferramentas indicadas e preencha:

| Item | InformaÃ§Ã£o do Artigo | Seu CÃ¡lculo |
|------|---------------------|-------------|
| Tamanho da populaÃ§Ã£o (N) | | |
| Margem de erro | | |
| NÃ­vel de confianÃ§a | | |
| Tipo de cÃ¡lculo necessÃ¡rio | | |
| **Tamanho no artigo** | | |
| **Seu resultado** | | |
| **Coincidem?** | | â˜ Sim  â˜ NÃ£o |

ğŸ’­ *Se nÃ£o coincidem, quais podem ser as razÃµes?*

---

### âš–ï¸ Aspectos Ã‰ticos

**5. A pesquisa foi aprovada pelo ComitÃª de Ã‰tica?**

Procure no artigo:

- âœ… HÃ¡ menÃ§Ã£o Ã  aprovaÃ§Ã£o do **CEP**?

- ğŸ“‹ O **nÃºmero do parecer** estÃ¡ informado?

- ğŸ“ HÃ¡ referÃªncia ao **TCLE** (Termo de Consentimento)?

---

**6. Qual a importÃ¢ncia de submeter ao ComitÃª de Ã‰tica?**

Reflita sobre:

| Aspecto | Por Que Ã‰ Importante? |
|---------|----------------------|
| **ProteÃ§Ã£o dos participantes** | Garante que os direitos sejam respeitados |
| **Consentimento informado** | ParticipaÃ§Ã£o voluntÃ¡ria e esclarecida |
| **Confidencialidade** | ProteÃ§Ã£o dos dados pessoais |
| **Riscos e benefÃ­cios** | AvaliaÃ§Ã£o Ã©tica da relaÃ§Ã£o custo-benefÃ­cio |
| **Integridade cientÃ­fica** | Credibilidade da pesquisa |

**âš ï¸ ConsequÃªncias de NÃƒO submeter:**

- ViolaÃ§Ã£o de direitos dos participantes

- InfraÃ§Ã£o Ã s ResoluÃ§Ãµes CNS 466/2012 e 510/2016

- Artigo pode ser rejeitado ou retratado

- SanÃ§Ãµes ao pesquisador

---

### ğŸ“š Para Saber Mais

> **ConheÃ§a o ComitÃª de Ã‰tica em Pesquisa (CEP) da UFTM**
> 
> ğŸ”— <https://www.uftm.edu.br/comitesecomissoes/cep>

 **VocÃª encontrarÃ¡:**

 - Como submeter projetos

 - Documentos necessÃ¡rios

 - Prazos e tramitaÃ§Ã£o

 - RegulamentaÃ§Ãµes vigentes

---

**ğŸ’¬ QuestÃ£o bÃ´nus:** *Se vocÃª fosse revisor deste artigo, aprovaria a metodologia amostral? Justifique.*

---


## ğŸ§® ExercÃ­cio PrÃ¡tico: Calculadora USP Bauru

### ğŸ¯ SituaÃ§Ã£o-Problema

VocÃª Ã© pesquisador(a) e quer investigar a **adesÃ£o ao uso de equipamentos de proteÃ§Ã£o individual (EPIs)** entre profissionais de enfermagem de um hospital universitÃ¡rio.

**Dados da instituiÃ§Ã£o:**

- **PopulaÃ§Ã£o:** 450 profissionais de enfermagem (enfermeiros, tÃ©cnicos e auxiliares)

- **Estimativa inicial:** Estudos semelhantes mostram que cerca de **70%** dos profissionais utilizam EPIs corretamente

- **ParÃ¢metros desejados:** 95% de confianÃ§a e margem de erro de 5%

**Pergunta:** Quantos profissionais vocÃª precisa incluir na sua amostra?

---

### ğŸ“ Passo a Passo na Calculadora

**1. Acesse a calculadora:**

- ğŸ”— http://estatistica.bauru.usp.br/calculoamostral/

- Clique em **"CÃ¡lculos"** no menu

- Selecione **"1 - Intervalo de ConfianÃ§a de uma ProporÃ§Ã£o"**

**2. Preencha os campos conforme a imagem:**

<center>
![Calculadora USP Bauru](calc-usp-bauru.png)
</center>

| Campo | O que colocar | Valor |
|-------|---------------|:-------:|
| **NÃ­vel de ConfianÃ§a** | Deixe marcado 95% | ğŸ”µ 95% |
| **Erro (%)** | Margem de erro desejada | **5** |
| **ProporÃ§Ã£o Estimada na PopulaÃ§Ã£o (%)** | Uso correto de EPIs | **70** |
| **â˜‘ï¸ PopulaÃ§Ã£o finita** | âœ… Marque a caixa | **450** |

**3. Clique em "Calcular"**

---

### âœ… Anote Seus Resultados

**a) Quantos profissionais vocÃª precisa pesquisar?**  

> **R:** _______ profissionais

**b) Qual a diferenÃ§a do tamano da amostra considerando populaÃ§Ã£o finita e infinita?**  

> **R: sem considerar populaÃ§Ã£o finita (infinita):** _______ profissionais  

> **R: considerando populaÃ§Ã£o finita (450):** _______ profissionais  

> **DiferenÃ§a:** _______ profissionais

**c) Volte Ã s configuraÃ§Ãµes originais. Agora aumente o nÃ­vel de confianÃ§a para 99%. O que acontece?**  

> **R: com 99% de confianÃ§a:** _______ profissionais

**d) Retorne para 95% de confianÃ§a. Agora diminua a margem de erro para 3%. Qual o impacto?**  

> **R: com erro de 3%:** _______ profissionais

**e) Use o campo "Perda de elementos (%)" e considere 20% de perdas (profissionais de fÃ©rias, licenÃ§a, recusa). Quantas amostras vocÃª deveria ter?**  

>**R: ajustado para perdas:** _______ profissionais

---

### ğŸ“ QuestÃµes Para ReflexÃ£o

**1. Viabilidade prÃ¡tica:**  
Considerando que vocÃª precisa pesquisar _____ profissionais de um total de 450, isso representa aproximadamente _____% da populaÃ§Ã£o. Isso Ã© viÃ¡vel? Por quÃª?

**2. ComparaÃ§Ã£o:**  
Por que o tamanho da amostra Ã© MENOR quando consideramos populaÃ§Ã£o finita (450) em vez de infinita?

**3. DecisÃµes metodolÃ³gicas:**  
Se vocÃª tivesse que escolher entre:

- OpÃ§Ã£o A: Erro 5% e confianÃ§a 95%

- OpÃ§Ã£o B: Erro 3% e confianÃ§a 95%

Qual vocÃª escolheria considerando tempo e recursos limitados? Justifique.

---

### ğŸ’¡ Desafio Extra: Mude o Contexto

Agora imagine um cenÃ¡rio diferente:

**SituaÃ§Ã£o:** VocÃª nÃ£o tem ideia de qual a proporÃ§Ã£o de profissionais que usam EPIs corretamente.

**O que fazer?** Quando nÃ£o temos estimativa prÃ©via, usamos **50%** (pior cenÃ¡rio, que gera maior amostra).

**Teste:** Volte Ã  calculadora e mude a "ProporÃ§Ã£o Estimada" para **50%**. Recalcule.

**Qual o novo tamanho da amostra?** _______ profissionais

**Por que mudou?** _______________________________________

---

### âœ… Gabarito

<details>
<summary>ğŸ‘ï¸ Clique para ver as respostas</summary>

**PopulaÃ§Ã£o finita: 450 profissionais | ProporÃ§Ã£o: 70%**

**a) Amostra necessÃ¡ria (erro 5%, conf 95%):** 189 profissionais

**b) ComparaÃ§Ã£o:**

- Sem populaÃ§Ã£o finita (infinita): 323 profissionais

- Com populaÃ§Ã£o finita (450): 189 profissionais

- DiferenÃ§a: 134 profissionais (a correÃ§Ã£o reduz bastante!)

**c) Com 99% de confianÃ§a:** 

- pop. finita: 250 profissionais (aumenta!) 

- pop. infinita: 560 profissionais (nem faz sentido, por ser maior que a populaÃ§Ã£o)

**d) Com erro de 3%:** 

- pop. finita: 300 profissionais (pop finita)

- pop. infinita: 897 profissionais (nem faz sentido)

**e) Ajustado para 20% de perdas:** 

- pop. finita: 312 profissionais (250 Ã· 0,80)

**Desafio Extra (proporÃ§Ã£o 50%):** 

- pop. finita: 269 profissionais
- Mudou porque 50% Ã© o cenÃ¡rio mais conservador (gera maior variabilidade)

ğŸ¤” Entendendo a Variabilidade

Pense assim: quando calculamos o tamanho da amostra para proporÃ§Ã£o, usamos a fÃ³rmula que inclui **p Ã— (1 - p)**, onde **p** Ã© a proporÃ§Ã£o estimada.

Veja o que acontece com diferentes proporÃ§Ãµes:

| ProporÃ§Ã£o (p) | CÃ¡lculo p Ã— (1-p) | Variabilidade |
|---------------|-------------------|---------------|
| 10% (0,10) | 0,10 Ã— 0,90 = **0,09** | Baixa |
| 30% (0,30) | 0,30 Ã— 0,70 = **0,21** | MÃ©dia |
| **50% (0,50)** | **0,50 Ã— 0,50 = 0,25** | **MÃXIMA** âœ… |
| 70% (0,70) | 0,70 Ã— 0,30 = **0,21** | MÃ©dia |
| 90% (0,90) | 0,90 Ã— 0,10 = **0,09** | Baixa |

**ğŸ“Š Observe:** O valor **0,25 (quando p = 50%)** Ã© o **MAIOR POSSÃVEL!**


**ReflexÃ£o 1:** 189/450 = 42% da populaÃ§Ã£o - Ã© uma amostra grande, mas viÃ¡vel em um hospital.

**ReflexÃ£o 2:** A correÃ§Ã£o para populaÃ§Ã£o finita considera que estamos pegando uma fraÃ§Ã£o significativa do total (42%), entÃ£o precisamos de menos pessoas para ter precisÃ£o.

</details>

---

### ğŸ¯ O Que VocÃª Aprendeu

âœ… Como usar a Calculadora USP Bauru passo a passo  
âœ… A importÃ¢ncia da correÃ§Ã£o para populaÃ§Ã£o finita  
âœ… Como confianÃ§a e erro afetam o tamanho da amostra  
âœ… Por que usar 50% quando nÃ£o temos estimativa  
âœ… Como ajustar para perdas esperadas  

**ğŸ’¬ PrÃ³ximo passo:** Use esses conhecimentos para calcular a amostra da SUA pesquisa!

---




# TÃ©cnicas de Amostragem

Em pesquisas, uma das etapas mais importantes Ã© o **cÃ¡lculo amostral**, que determina quantos participantes serÃ£o necessÃ¡rios para garantir que os resultados sejam confiÃ¡veis. Depois, Ã© preciso escolher uma **tÃ©cnica de amostragem**, ou seja, como vamos selecionar as pessoas ou unidades que farÃ£o parte da pesquisa. Uma parte essencial disso Ã© garantir que o processo de amostragem evite **viÃ©s**, que ocorre quando a amostra nÃ£o representa adequadamente a populaÃ§Ã£o.

Existem vÃ¡rias tÃ©cnicas de amostragem, cada uma com suas caracterÃ­sticas, vantagens e desvantagens.

---

## Amostragem AleatÃ³ria Simples

Nesta tÃ©cnica, cada elemento da populaÃ§Ã£o tem a mesma chance de ser selecionado.

> **Exemplo:** Se quisermos estudar a saÃºde mental dos estudantes da UFTM, podemos utilizar uma lista completa dos alunos e, de maneira aleatÃ³ria (sorteio), selecionar os estudantes que farÃ£o parte da amostra, conforme o nÃºmero determinado pelo cÃ¡lculo amostral.

- **Vantagens:** Ã‰ simples de aplicar e garante que todos tÃªm a mesma chance de ser escolhidos, minimizando o viÃ©s.
- **Desvantagens:** Pode ser difÃ­cil de implementar se a populaÃ§Ã£o for muito grande ou se nÃ£o tivermos uma lista completa de todos os membros da populaÃ§Ã£o. 
- **Como evitar viÃ©s:** Garantir que a lista de onde serÃ£o sorteados os participantes seja completa e atualizada.

---

## Amostragem Estratificada

Aqui, a populaÃ§Ã£o Ã© dividida em grupos ou "estratos" (por exemplo, cursos ou faixas etÃ¡rias) e, em seguida, amostras sÃ£o selecionadas dentro de cada estrato.

> **Exemplo:** Suponha que queremos estudar a prÃ¡tica de atividade fÃ­sica entre os estudantes da UFTM. Podemos usar amostragem estratificada, dividindo os alunos por curso (estratos). Dentro de cada curso, selecionamos aleatoriamente um nÃºmero proporcional de alunos, garantindo que todos os cursos estejam representados de forma adequada na amostra, refletindo a diversidade da universidade.

- **Vantagens:** Melhora a representatividade da amostra, especialmente quando diferentes subgrupos podem ter comportamentos ou caracterÃ­sticas distintas. Ajuda a evitar viÃ©s ao garantir que todos os grupos da populaÃ§Ã£o estejam representados.
- **Desvantagens:** Ã‰ necessÃ¡rio conhecer a populaÃ§Ã£o e seus estratos de antemÃ£o, o que pode ser difÃ­cil em alguns casos.
- **Como evitar viÃ©s:** A definiÃ§Ã£o dos estratos deve ser precisa e relevante para a pesquisa.

---

## Amostragem SistemÃ¡tica

Na amostragem sistemÃ¡tica, escolhemos um ponto de partida aleatÃ³rio e, a partir daÃ­, selecionamos unidades a intervalos regulares de "n" unidades.

> **Exemplo:** Se quisermos estudar a prÃ¡tica de atividade esportiva entre os estudantes da UFTM e temos uma lista de todos os alunos, podemos selecionar a cada 10Âº aluno da lista para participar da pesquisa.

- **Vantagens:** FÃ¡cil de implementar, especialmente em populaÃ§Ãµes grandes, e garante uma distribuiÃ§Ã£o uniforme dos selecionados ao longo da lista.
- **Desvantagens:** Pode ocorrer viÃ©s caso haja algum padrÃ£o na ordem da lista (por exemplo, se alunos de cursos especÃ­ficos forem listados consecutivamente, a amostra pode nÃ£o ser representativa).
- **Como evitar viÃ©s:** A lista de seleÃ§Ã£o deve ser aleatÃ³ria e nÃ£o seguir um padrÃ£o que favoreÃ§a um grupo especÃ­fico.

---

## Amostragem por Conglomerados

Nessa tÃ©cnica, a populaÃ§Ã£o Ã© dividida em grupos (chamados de conglomerados) e, em seguida, seleciona-se aleatoriamente alguns desses grupos para fazer parte da amostra.

> **Exemplo:** Em vez de selecionar alunos aleatoriamente, selecionar alguns cursos especÃ­ficos da UFTM e estudar todos os alunos desses cursos. Essa tÃ©cnica Ã© Ãºtil quando a populaÃ§Ã£o Ã© muito grande e difÃ­cil de acessar como um todo.

- **Vantagens:** Mais fÃ¡cil de administrar em populaÃ§Ãµes grandes, quando nÃ£o se tem acesso a uma lista completa de todos os indivÃ­duos.
- **Desvantagens:** Pode nÃ£o ser tÃ£o representativa, pois estamos escolhendo grupos inteiros e nÃ£o indivÃ­duos aleatÃ³rios.
- **Como evitar viÃ©s:** Os conglomerados escolhidos devem representar adequadamente a diversidade da populaÃ§Ã£o.

---

## Amostragem por ConveniÃªncia

Na **amostragem por conveniÃªncia**, os participantes sÃ£o selecionados por serem mais fÃ¡ceis de acessar pelo pesquisador.

> **Exemplo:** O uso de formulÃ¡rios online, como o Google Forms, Ã© uma forma comum de amostragem por conveniÃªncia. O pesquisador compartilha o formulÃ¡rio em redes sociais, grupos de WhatsApp ou por e-mail, e os primeiros que responderem entram para a amostra.

- **Vantagens:** RÃ¡pida, prÃ¡tica, econÃ´mica e permite coletar dados de muitas pessoas em pouco tempo.
- **Desvantagens:** Forte risco de viÃ©s, pois a amostra pode nÃ£o representar a populaÃ§Ã£o como um todo, jÃ¡ que depende de quem tem acesso ao link, internet e interesse em responder.
- **Como evitar viÃ©s:** Embora nÃ£o seja possÃ­vel eliminar totalmente o viÃ©s, recomenda-se divulgar o formulÃ¡rio em diferentes canais e para pÃºblicos diversos, incentivando a participaÃ§Ã£o de vÃ¡rios grupos.

**AtenÃ§Ã£o aos Vieses no Uso de FormulÃ¡rios Online:**

- **ViÃ©s de acesso:** Apenas pessoas com acesso Ã  internet podem responder.
- **ViÃ©s de auto-seleÃ§Ã£o:** Aqueles mais motivados ou interessados no tema tendem a participar mais.
- **ViÃ©s de distribuiÃ§Ã£o:** Se o link for enviado apenas a determinados grupos, outros podem ser sub-representados.

Portanto, ao usar formulÃ¡rios online, Ã© importante considerar essas limitaÃ§Ãµes e, se possÃ­vel, adotar estratÃ©gias para ampliar o alcance e a diversidade dos respondentes.

---

## Combinando TÃ©cnicas na PrÃ¡tica

Na prÃ¡tica, Ã© comum que pesquisadores combinem diferentes tÃ©cnicas de amostragem para aumentar a representatividade e reduzir o viÃ©s da amostra, adaptando o processo Ã s caracterÃ­sticas especÃ­ficas da populaÃ§Ã£o e aos objetivos do estudo.

Por exemplo, pode-se aplicar a **amostragem estratificada** para garantir que todos os subgrupos relevantes (como cursos, faixas etÃ¡rias ou regiÃµes) estejam proporcionalmente representados na amostra. Em seguida, dentro de cada estrato, pode-se utilizar a **amostragem aleatÃ³ria simples** para selecionar os participantes de forma justa e imparcial.

AlÃ©m disso, em situaÃ§Ãµes em que o acesso Ã  populaÃ§Ã£o Ã© limitado, pode-se recorrer Ã  combinaÃ§Ã£o de tÃ©cnicas probabilÃ­sticas (como estratificada ou sistemÃ¡tica) com mÃ©todos nÃ£o probabilÃ­sticos (como conveniÃªncia), sempre buscando estratÃ©gias para minimizar possÃ­veis vieses e aumentar a diversidade dos participantes.

Ao combinar mÃ©todos, o pesquisador consegue contornar limitaÃ§Ãµes prÃ¡ticas (como listas incompletas ou dificuldades de acesso) e, ao mesmo tempo, assegurar que a amostra reflita com maior fidelidade a diversidade da populaÃ§Ã£o, tornando os resultados mais robustos e confiÃ¡veis.

---

## Evitar ViÃ©s na Amostragem

O **viÃ©s de amostragem** ocorre quando certos grupos da populaÃ§Ã£o tÃªm mais chance de ser selecionados do que outros, o que pode distorcer os resultados da pesquisa. Para evitar viÃ©s, Ã© essencial:

- Garantir que todos os grupos da populaÃ§Ã£o tenham uma chance igual ou proporcional de ser selecionados.
- Utilizar tÃ©cnicas que levem em consideraÃ§Ã£o as caracterÃ­sticas especÃ­ficas da populaÃ§Ã£o.
- Combinar diferentes mÃ©todos de amostragem para melhorar a representatividade.

---

## Resumindo

- **ProbabilÃ­stica:** amostragem aleatÃ³ria simples, sistemÃ¡tica, estratificada, por conglomerados.
- **NÃ£o probabilÃ­stica:** amostragem por conveniÃªncia (incluindo Google Forms), intencional, por cotas.

> A escolha da tÃ©cnica deve considerar os objetivos da pesquisa, os recursos disponÃ­veis e a necessidade de representatividade da amostra.





<!--chapter:end:01-Introducao.Rmd-->

# Ambiente Computacional {#ambiente-computacional}

Existem diversos softwares dedicados Ã  anÃ¡lise estatÃ­stica, que vÃ£o desde planilhas eletrÃ´nicas, como o Excel, atÃ© programas mais robustos, como o SPSS. Abaixo, listamos algumas das principais ferramentas utilizadas:

## Softwares pagos

- [SPSS (IBM)](https://www.ibm.com/br-pt/spss)
- [Stata](https://www.stata-brasil.com/software/stata.html)
- [SAS](https://www.sas.com/pt_br)
- [JMP](https://www.jmp.com/)
- [Prism](https://software.com.br/p/prism)
- [Minitab](https://osbsoftware.com.br/produto/minitab-statistical-software)
- Microsoft Excel

## Softwares livres

- [Jamovi](https://www.jamovi.org)
- [OpenStat](https://openstat.info)

## Linguagens computacionais

- [R](https://www.r-project.org)
- [Python](https://www.python.org/)

Neste curso, utilizaremos a linguagem **R**, desenvolvida especialmente para anÃ¡lise estatÃ­stica. Quer entender por que essa escolha? Recomendamos a leitura: [Por que usar R?](https://blog.curso-r.com/posts/2021-07-23-por-que-usar-r/)

## Preparando o Ambiente Computacional

Vamos preparar o ambiente computacional para realizar nossas anÃ¡lises com R.

> Para esclarecer:
> - **R** Ã© uma linguagem de programaÃ§Ã£o (mas nÃ£o se preocupe, nÃ£o vamos programar profundamente).
> - **RStudio** Ã© o software onde os cÃ³digos R serÃ£o executados. Ã‰ o que chamamos de IDE â€“ *Integrated Development Environment* (Ambiente de Desenvolvimento Integrado).

## Plano A: InstalaÃ§Ã£o do R e RStudio

Nos laboratÃ³rios da UFTM, o R e o RStudio jÃ¡ estÃ£o instalados. No entanto, sugerimos que vocÃª tambÃ©m os instale em seu computador pessoal, pois nem sempre conseguiremos realizar todas as atividades em sala.

Siga estes passos:

1. Instale o R: [https://cran.rstudio.com](https://cran.rstudio.com)
2. Instale o RStudio Desktop: [https://posit.co/download/rstudio-desktop](https://posit.co/download/rstudio-desktop)

> Certifique-se de baixar versÃµes compatÃ­veis com o sistema operacional do seu computador.

Se tudo estiver correto, ao abrir o RStudio, vocÃª verÃ¡ uma tela semelhante a esta:

<center>![Figura: Tela inicial do RStudio](telaRStudio.png)</center>

Caso enfrente dificuldades, siga para o Plano B.

## Plano B: R e RStudio na Nuvem

O Plano B Ã© utilizar o RStudio diretamente na nuvem, sem precisar instalar nada. Essa alternativa Ã© excelente, mas requer uma boa conexÃ£o com a internet.

Siga os passos:

1. Acesse: [https://posit.cloud](https://posit.cloud)
2. FaÃ§a login (vocÃª pode usar sua conta do Google, por exemplo)
3. ApÃ³s o login, vocÃª verÃ¡ esta tela:

<center>![Figura: Tela inicial na nuvem da Posit](telaPosit.png)</center>

4. Crie um novo projeto clicando em *New Project* e, depois, *New RStudio Project*:

<center>![Figura: BotÃ£o de criaÃ§Ã£o de um novo projeto](telaCriarProjetoRStudio.png){width=40%}</center>

5. Pronto! A interface do RStudio serÃ¡ carregada na nuvem:

<center>![Figura: Tela do RStudio online na Posit Cloud](telaRStudioPosit.png)</center>

> Vantagem: seus arquivos e anÃ¡lises ficam salvos na nuvem, em um local seguro e acessÃ­vel de qualquer lugar.

---

Com o ambiente configurado, estaremos prontos para explorar o mundo da estatÃ­stica com R!

<!--chapter:end:02-Ambiente-Computacional.Rmd-->

# Trabalhando no RStudio {#trabalhando-RStudio}

Seja na versÃ£o instalada no seu computador (plano A) ou na nuvem (plano B), conheÃ§a melhor as Ã¡reas do RStudio:

1. **Console:** local onde serÃ£o apresentadas as respostas para cÃ³digos executados;

2. **Ambiente de memÃ³ria (Environment):** Ã© o cÃ©rebro do R, onde ficam registrados os objetos que ele reconhece.

3. A Ã¡rea de **Arquivos (Files), GrÃ¡ficos (Plots), Pacotes (Packages), Ajuda (Help), VisualizaÃ§Ã£o (Viewer) e ApresentaÃ§Ã£o (Presentation)**: mostram, respectivamente, os arquivos do diretÃ³rio onde estÃ£o seus arquivos no computador, os grÃ¡ficos, os pacotes, a ajuda, a janela de visualizaÃ§Ã£o e a apresentaÃ§Ã£o.

A figura abaixo identifica cada uma dessas Ã¡reas:

<center>![<font size="2">Figura: IdentificaÃ§Ã£o das Ã¡reas do RStudio</font>](telaRStudio123.png)</center>

Digitaremos os cÃ³digos da linguagem R, em um arquivo que chamamos de **script**. Para abrir um arquivo do tipo script R, faÃ§a:

1. Acesse a opÃ§Ã£o **File** no menu principal do RStudio;
2. Escolha a opÃ§Ã£o **New File**;
3. E depois a opÃ§Ã£o **R Script**.

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](arquivoScript.png){width=40%}</center>

Assim, na tela da IDE RStudio aparecerÃ¡ uma nova Ã¡rea, que Ã© a Ã¡rea do arquivo script, como mostra a figura.

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](telaScript.png)</center>

Observe que o arquivo estÃ¡ sem um nome (**Untitled1**, sem tÃ­tulo). Salve o arquivo atribuindo-lhe um nome adequado. Para isso, no menu principal, escolha *File*, depois *Save*.

> Dica: O ideal seria criar um **Projeto**. Veja a opÃ§Ã£o _File > New Project_.

<!--chapter:end:03-RStudio.Rmd-->

# Primeiros exercÃ­cios no R

Nos capÃ­tulos  \@ref(ambiente-computacional) e \@ref(trabalhando-RStudio) vimos sobre o ambiente computacional (computador ou nuvem) e identificamos as 4 Ã¡reas da tela da interface do RStudio: **console**, **ambiente de memÃ³ria**, **arquivos, grÃ¡ficos, etc.** e **script**, assim estamos prontos para escrever alguns cÃ³digos e executÃ¡-los a partir da Ã¡rea de script.

> **AtenÃ§Ã£o:** TODOS os cÃ³gigos serÃ£o digitados no arquivo de script, seguindo uma sequÃªncia lÃ³gica de passos, ou seja, escreveremos um roteiro (*script*), como se fosse uma receita de bolo, isso Ã© o que o pessoal da computaÃ§Ã£o chama de algoritmo.


## Exemplo 1

* Observe o cÃ³digo escrito na linha 1 do arquivo de script e o botÃ£o **Run** (primeira seta verde):

<center>![<font size="2">Figura: Primeiro exemplo de cÃ³gigo R</font>](telaExemplo1.png)
</center>

* O sequÃªncia de caracteres **<-** Ã© o sÃ­mbolo de atribuiÃ§Ã£o no R.

> Pressionando as teclas ALT e - (menos) simultaneamente cria no script o sinal de atribuiÃ§Ã£o.

* O cÃ³digo significa que criamos um objeto chamado **x** e atribuimos a esse objeto o valor 2.

* No entanto, o R ainda nÃ£o sabe que o valor de x Ã© igual a 2! 

* Para registrar essa informaÃ§Ã£o na memÃ³ria do R, devemos executar essa linha.

> Para executar uma linha posicione o cursor na linha, e clique no botÃ£o **Run**

<center>![<font size="2">Figura: O objeto x Ã© registrado na memÃ³ria do R, armazenando o valor igual a 2</font>](telaValorMemoria.png){width=40%}
</center>

> Observe sempre o ambiente de memÃ³ria (bem como o console) quando executar uma linha.

## Exemplo 2

Execute o seguinte cÃ³gigo no R.

```{r}
idades <- c( 23, 18, 17, 25, 21, 19, 22, 24, 19, 19 )
```

* Esse cÃ³digo significa que foi criado um objeto chamado idade que armazena 10 valores: 23, 18, 17, 25, 21, 19, 22, 24, 19, 19, diferentemente do exemplo 1 em que x armazenava somente o valor 2. 

* Isso foi possÃ­vel pois usamos a funÃ§Ã£o **c( )**.

* observe que os valores foram colocado dentro dos parÃªnteses da funÃ§Ã£o **c( )**

> Com funÃ§Ã£o **c( )** podemos **combinar** vÃ¡rios valores em um objeto, esse objeto recebe o nome de vetor ou lista.


## Exemplo 3 

Observe nesse cÃ³digo as funÃ§Ãµes:

* **max( )**

* **min( )**

* **range( )**

* **mean( )**

* **sd( )**

```{r echo=TRUE}
# criando o vetor idades 
idades <- c( 23, 18, 17, 25, 21, 19, 22, 24, 19, 19 )

# maior valor
# funÃ§Ã£o max( )
max(idades)

# menor valor
# funÃ§Ã£o min( )
min(idades)

# faixa de valores
# funÃ§Ã£o range( )
range(idades)

# mÃ©dia (mean)
# funÃ§Ã£o mean( )
mean(idades)

# desvio padrÃ£o (standard deviation)
# funÃ§Ã£o sd() 
sd(idades)
```

> Copie o cÃ³digo e cole no seu arquivo script, selecione todo conteÃºdo (CRTL+A) e execute todo o cÃ³gigo de uma Ãºnica vez.

* Observe que as respostas apareceram no **console**, conforme mostrado na figura abaixo:

<center>![<font size="2">Figura: Como abrir um novo arquivo de script R</font>](telaRespostaConsole.png){width=40%}
</center>

> O sÃ­mbolo # Ã© o sÃ­mbolo de comentÃ¡rio, isso significa que podemos escrever qualquer texto diferente do que o R sabe interpretar, e mesmo executando o cÃ³digo nenhum erro acontece! 

> **IMPORTANTE**: Ã© uma boa prÃ¡tica comentar os trechos de cÃ³digos para deixar documentado qual Ã© o objetivo do cÃ³digo.


<!--chapter:end:04-Primeiros-Exercicios.Rmd-->

# Tipos de VariÃ¡veis

As variÃ¡veis podem ser classificadas de acordo com sua natureza:

## VariÃ¡veis Quantitativas
Expressam **quantidade** e podem ser divididas em:

- **Discreta**: Assume valores inteiros (contagem).
  - *Exemplo*: O nÃºmero de filhos de uma pessoa. VocÃª pode contar 0, 1, 2, 3 filhos, mas nÃ£o pode ter 2,5 filhos.
  
- **ContÃ­nua**: Assume qualquer valor dentro de um intervalo especÃ­fico (mensuraÃ§Ã£o).
  - *Exemplo*: A altura de uma pessoa, que pode ser 1,70 m, 1,71 m, 1,711 m, e assim por diante, com infinitas possibilidades entre os valores.

## VariÃ¡veis Qualitativas
Expressam **qualidade** e sÃ£o representadas por **categorias** ou **rÃ³tulos**. SÃ£o subdivididas em:

- **Nominal**: Categorias que nÃ£o podem ser ordenadas.
  - *Exemplo*: O tipo de fruta que vocÃª prefere, como maÃ§Ã£, banana, laranja. NÃ£o faz sentido ordenar essas categorias de maneira que uma seja "maior" que a outra.
  
- **Ordinal**: Categorias que podem ser ordenadas, com uma graduaÃ§Ã£o entre elas.
  - *Exemplo*: NÃ­veis de satisfaÃ§Ã£o de um serviÃ§o, como "satisfeito", "neutro" e "insatisfeito". Aqui, existe uma ordem em que "satisfeito" Ã© maior que "neutro", e "neutro" Ã© maior que "insatisfeito".

Uma aplicaÃ§Ã£o comum das variÃ¡veis ordinais Ã© a **Escala Likert**, que Ã© amplamente utilizada em pesquisas de opiniÃ£o para medir atitudes ou percepÃ§Ãµes. A escala Likert geralmente apresenta uma sÃ©rie de afirmativas, e o participante deve indicar seu nÃ­vel de concordÃ¢ncia com cada uma delas, com respostas em uma sequÃªncia ordenada.

*Exemplo*: Em uma pesquisa de satisfaÃ§Ã£o de clientes, a pergunta poderia ser: "Concordo que a alimentaÃ§Ã£o oferecida pelo hospital foi satisfatÃ³ria." As opÃ§Ãµes de resposta poderiam ser:

1. **Discordo totalmente**
2. **Discordo parcialmente**
3. **Neutro**
4. **Concordo parcialmente**
5. **Concordo totalmente**

Essas respostas formam uma escala ordinal, pois a ordem das categorias reflete um aumento no nÃ­vel de concordÃ¢ncia, mas as diferenÃ§as entre elas nÃ£o sÃ£o necessariamente iguais.

> **Dica**: Veja o vÃ­deo do Prof. Heitor no **Canal Pesquise**: [Assista aqui](https://youtu.be/_oc37Ea_tl8).

## AplicaÃ§Ã£o das VariÃ¡veis em EstatÃ­stica

A natureza da variÃ¡vel influencia o tipo de procedimento estatÃ­stico que serÃ¡ utilizado. Exemplos:

### EstatÃ­stica Descritiva:
- **VariÃ¡veis Qualitativas**: SÃ£o representadas por sua **frequÃªncia absoluta** ou **percentual**.
  - *Exemplo*: Em uma pesquisa de preferÃªncia de frutas, pode-se dizer que 40% das pessoas escolheram maÃ§Ã£, 35% escolheram banana, e 25% escolheram laranja.
  
- **VariÃ¡veis Quantitativas**: SÃ£o representadas por **medidas resumo**, como **mÃ©dia** e **desvio padrÃ£o**.
  - *Exemplo*: Se vocÃª calcular a mÃ©dia de altura de um grupo de pessoas, e o desvio padrÃ£o indicar que a altura das pessoas varia em torno de 5 cm da mÃ©dia.

### EstatÃ­stica Inferencial:
- **Teste Qui-Quadrado**: Usado para verificar se hÃ¡ associaÃ§Ã£o entre as categorias de duas variÃ¡veis qualitativas.
  - *Exemplo*: Um teste Qui-Quadrado poderia ser utilizado para verificar se a escolha de fruta (maÃ§Ã£, banana, laranja) tem relaÃ§Ã£o com o sexo (masculino, feminino) dos participantes.

- **Teste de CorrelaÃ§Ã£o de Pearson**: Mede a forÃ§a da correlaÃ§Ã£o linear entre duas variÃ¡veis quantitativas.
  - *Exemplo*: O teste de Pearson poderia ser utilizado para verificar se existe uma relaÃ§Ã£o entre a altura e o peso das pessoas. Quanto maior a altura, maior o peso? Esse teste nos diria a forÃ§a dessa relaÃ§Ã£o.


<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>

## Atividade 3

**Leia o artigo _Estado nutricional, tempo de internaÃ§Ã£o e mortalidade em pacientes submetidos Ã  cirurgia cardÃ­aca em um hospital na cidade de MaceiÃ³_**  
DisponÃ­vel em: [RASBRAN, Revista da AssociaÃ§Ã£o Brasileira de NutriÃ§Ã£o, 2023](https://www.rasbran.com.br/rasbran/article/view/1724/443)  
Acesse tambÃ©m o portal: [RASBRAN - Revista da AssociaÃ§Ã£o Brasileira de NutriÃ§Ã£o](https://www.rasbran.com.br/).

### AnÃ¡lise das Tabelas

- **Tabela 1 - CaracterÃ­sticas clÃ­nicas dos pacientes submetidos Ã  cirurgia cardÃ­aca**: Esta tabela apresenta as caracterÃ­sticas da amostra analisada na pesquisa. 
  - **Tarefa**: Classifique as variÃ¡veis (caracterÃ­sticas) em **qualitativas** e **quantitativas**.
  - **ObservaÃ§Ã£o**: Verifique como as variÃ¡veis foram resumidas. Elas foram apresentadas em **porcentagens**? Ou foram calculadas medidas de **mÃ©dia** e **desvio padrÃ£o**?

- **Tabela 2 - AssociaÃ§Ã£o entre estado nutricional, sexo, idade e tempo de internaÃ§Ã£o hospitalar entre os pacientes submetidos Ã  cirurgia cardÃ­aca**  
- **Tabela 3 - AssociaÃ§Ã£o entre evoluÃ§Ã£o clÃ­nica, sexo, idade, tempo de internaÃ§Ã£o hospitalar e estado nutricional entre os pacientes submetidos Ã  cirurgia cardÃ­aca**: Estas tabelas mostram os resultados de um **teste de hipÃ³tese** (parte da estatÃ­stica inferencial).
  - **Tarefa**: Identifique qual **teste estatÃ­stico** foi aplicado.
  - **Objetivo**: Qual Ã© o objetivo deste teste?


<!--chapter:end:05-Tipos-Variaveis.Rmd-->

# EstatÃ­stica Descritiva

A estatÃ­stica descritiva permite **resumir, organizar e interpretar** dados de forma clara e objetiva. Para isso, utilizamos **medidas de tendÃªncia central**, **medidas de dispersÃ£o** e **medidas relativas de variabilidade**.

## Medidas de TendÃªncia Central (ou PosiÃ§Ã£o)

### MÃ©dia

- **DefiniÃ§Ã£o:** Soma de todos os valores dividida pelo nÃºmero de observaÃ§Ãµes.  
- **InterpretaÃ§Ã£o:** Representa o valor mÃ©dio ou tÃ­pico do conjunto de dados.  
- **Como reportar:**  

> A mÃ©dia dos batimentos cardÃ­acos foi de 58,6 bpm, indicando o valor mÃ©dio da amostra analisada.

### Mediana

- **DefiniÃ§Ã£o:** Valor central de um conjunto ordenado de dados.  
- **InterpretaÃ§Ã£o:** Divide o conjunto de dados ao meio, sendo Ãºtil quando hÃ¡ valores extremos (outliers).  
- **Como reportar:**  

> A mediana dos batimentos foi de 60,0 bpm, indicando que 50% dos indivÃ­duos apresentaram valores abaixo ou iguais a esse valor.

### Quartis

- **DefiniÃ§Ã£o:** Q1 (primeiro quartil) e Q3 (terceiro quartil) representam os valores que dividem os 25% e os 75% inferiores dos dados, respectivamente.  
- **InterpretaÃ§Ã£o:** Ajudam a entender a distribuiÃ§Ã£o dos dados e identificar a dispersÃ£o em torno da mediana.  
- **Como reportar:**  

> O primeiro e o terceiro quartis foram 54,0 bpm e 64,0 bpm, respectivamente, revelando que 50% dos batimentos ficaram entre esses dois valores.

### Moda

- **DefiniÃ§Ã£o:** Valor mais frequente do conjunto de dados.  
- **InterpretaÃ§Ã£o:** Indica o valor mais comum, embora possa nÃ£o existir ou haver mais de uma moda.  
- **Como reportar:**  

> A moda foi 62 bpm, valor que ocorreu com maior frequÃªncia na amostra.

**ObservaÃ§Ã£o importante:**  
- **MÃ©dia e desvio padrÃ£o** sÃ£o medidas que devem ser usadas juntas, especialmente para dados simÃ©tricos (distribuiÃ§Ã£o simÃ©trica) e sem valores extremos.
- **Mediana e quartis** formam outro conjunto de medidas, mais apropriado quando hÃ¡ assimetria ou presenÃ§a de outliers.

**SugestÃ£o de vÃ­deo:** Canal Pesquise - [TendÃªncia Central](https://youtu.be/ot0aDB-grDY)


## Medidas de DispersÃ£o (ou Variabilidade)

### Amplitude

- **DefiniÃ§Ã£o:** DiferenÃ§a entre o maior e o menor valor.  
- **InterpretaÃ§Ã£o:** Indica o intervalo total em que os dados variam.  
- **Como reportar:**  

> A amplitude foi de 36 bpm, com valores variando de 39 a 75 bpm.

### VariÃ¢ncia

- **DefiniÃ§Ã£o:** MÃ©dia dos quadrados das diferenÃ§as entre os valores e a mÃ©dia.  
- **InterpretaÃ§Ã£o:** Mede a dispersÃ£o, mas sua unidade Ã© o quadrado da unidade original.  
- **Como reportar:**  

> A variÃ¢ncia foi de 98,8 bpmÂ², indicando a variabilidade dos batimentos em relaÃ§Ã£o Ã  mÃ©dia.

**ObservaÃ§Ã£o:**  
A unidade da variÃ¢ncia Ã© expressa ao quadrado da unidade original dos dados (por exemplo, bpmÂ² no caso de batimentos por minuto), o que pode dificultar sua interpretaÃ§Ã£o direta.  
Por isso, costuma-se utilizar o **desvio padrÃ£o**, que tem a **mesma unidade dos dados originais** e fornece uma noÃ§Ã£o mais intuitiva da dispersÃ£o dos valores em torno da mÃ©dia.


### Desvio padrÃ£o (DP)

- **DefiniÃ§Ã£o:** Raiz quadrada da variÃ¢ncia.  
- **InterpretaÃ§Ã£o:** Expressa, em mÃ©dia, o quanto os dados se afastam da mÃ©dia.  
- **Como reportar:**  

**Como reportar:**  
O desvio padrÃ£o foi de 9,9 bpm, o que indica que, em mÃ©dia, os batimentos cardÃ­acos dos indivÃ­duos da amostra variam aproximadamente 9,9 unidades em relaÃ§Ã£o Ã  mÃ©dia.

### Amplitude interquartil (IQR)

- **DefiniÃ§Ã£o:** DiferenÃ§a entre o terceiro e o primeiro quartis (Q3 - Q1).  
- **InterpretaÃ§Ã£o:** Indica a dispersÃ£o dos 50% centrais dos dados.  
- **Como reportar:**  

> A amplitude interquartil foi de 10,0 bpm, mostrando a concentraÃ§Ã£o dos valores mÃ©dios.

**SugestÃ£o de vÃ­deo:** Canal Pesquise - [Variabilidade](https://youtu.be/sISPcOIcwXs)


## Medida Relativa de Variabilidade

### Coeficiente de VariaÃ§Ã£o (CV)

- **DefiniÃ§Ã£o:** Quociente entre o desvio padrÃ£o e a mÃ©dia, multiplicado por 100.  
- **InterpretaÃ§Ã£o:** Expressa a variabilidade dos dados em relaÃ§Ã£o Ã  mÃ©dia, permitindo comparar conjuntos com unidades diferentes.  
- **Como reportar:**  

> O coeficiente de variaÃ§Ã£o foi de 16,9%, indicando que os dados sÃ£o relativamente homogÃªneos.

**ObservaÃ§Ã£o:**  
Um CV inferior a 25% geralmente indica homogeneidade; valores muito altos indicam alta variabilidade.

## ApresentaÃ§Ã£o dos Resultados

Uma maneira eficiente de apresentar estatÃ­sticas descritivas Ã© organizar as variÃ¡veis em linhas, facilitando a visualizaÃ§Ã£o dos principais parÃ¢metros de cada variÃ¡vel estudada. Veja abaixo uma sugestÃ£o de tabela para esse formato:

| VariÃ¡vel           | n   | MÃ©dia Â± DP        | Mediana (Q1; Q3)   | MÃ­nimo | MÃ¡ximo |
|--------------------|-----|-------------------|--------------------|--------|--------|
| Idade (anos)       | 98  | 24,5 Â± 4,2        | 24,0 (21,0; 28,0)  | 18     | 35     |
| IMC (kg/mÂ²)        | 98  | 22,3 Â± 3,1        | 21,9 (20,3; 23,7)  | 17,0   | 31,5   |
| PressÃ£o SistÃ³lica  | 98  | 118,5 Â± 13,0      | 120 (110; 128)     | 90     | 145    |
| PressÃ£o DiastÃ³lica | 98  | 76,2 Â± 9,1        | 76 (70; 82)        | 60     | 98     |

> Reportar uma medida de tendÃªncia central (como mÃ©dia ou mediana) junto com uma medida de dispersÃ£o (como desvio padrÃ£o, intervalo interquartil ou amplitude) Ã© fundamental porque, isoladamente, a tendÃªncia central nÃ£o fornece informaÃ§Ãµes suficientes sobre o conjunto de dados.


Para variÃ¡veis qualitativas, a tabela pode ser organizada assim:

| VariÃ¡vel     | Categoria         | n   | %     |
|:--------------|:-------------------|:-----|:-------|
| Sexo         | Masculino         | 52  | 53,1% |
|              | Feminino          | 46  | 46,9% |
| Tabagismo    | Sim               | 18  | 18,4% |
|              | NÃ£o               | 80  | 81,6% |

Essas tabelas permitem uma apresentaÃ§Ã£o clara e objetiva das principais caracterÃ­sticas da amostra analisada.

## FunÃ§Ãµes no R

Com um vetor `x` contendo os dados, utilize:

| Medida                     | CÃ³digo R                    |
|----------------------------|-----------------------------|
| MÃ©dia                      | `mean(x)`                   |
| Mediana                    | `median(x)`                 |
| Primeiro quartil (Q1)      | `quantile(x, 0.25)`         |
| Terceiro quartil (Q3)      | `quantile(x, 0.75)`         |
| Moda                       | `sort(table(x))`            |
| Menor valor                | `min(x)`                    |
| Maior valor                | `max(x)`                    |
| Resumo geral               | `summary(x)`                |
| Amplitude                  | `range(x)`                  |
| VariÃ¢ncia                  | `var(x)`                    |
| Desvio padrÃ£o              | `sd(x)`                     |
| Amplitude interquartil     | `IQR(x)`                    |
| Coeficiente de variaÃ§Ã£o    | `sd(x)/mean(x)*100`         |


> Calcular Ã© importante, mas interpretar corretamente Ã© essencial. Ao elaborar suas interpretaÃ§Ãµes, descreva o que os nÃºmeros revelam sobre o fenÃ´meno analisado.

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 4

**Considere o objeto Batimentos, que Ã© uma amostra de batimentos cardÃ­acos de 20 homens.**

```{r}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54)
```

+ Obtenha as seguintes medidas:
   + Menor valor:
   + Maior valor:
   + MÃ©dia:
   + Mediana:
   + Primeiro quartil:
   + Terceiro quartil:
   + VariÃ¢ncia:
   + Desvio padrÃ£o:
   + Amplitude interquartil:
   + Coeficiente de variÃ§Ã£o:
   
+ Escreva sobre o conjunto media e desvio padrÃ£o: 

> A mÃ©dia dos dados foi de X (unidade), com um desvio padrÃ£o de Y (unidade), indicando que os valores estÃ£o, em geral, relativamente prÃ³ximos/espalhados em torno da mÃ©dia. O desvio padrÃ£o reflete a quantidade de variabilidade ou dispersÃ£o dos dados em relaÃ§Ã£o Ã  mÃ©dia, e neste caso, a dispersÃ£o Ã© baixa/mÃ©dia/alta, dependendo do valor de Y.

+ Escreva sobre conjunto mediana e quartis:

> A mediana foi Z (unidade), e o intervalo interquartil (IQR), que representa a diferenÃ§a entre o terceiro quartil (Q3) e o primeiro quartil (Q1), foi Q3 - Q1 (unidade). Isso indica que 50% dos dados estÃ£o concentrados nesse intervalo.

+ Escreva sobre o coeficiente de variaÃ§Ã£o: 

> O coeficiente de variaÃ§Ã£o (CV) foi calculado como X%, o que reflete a dispersÃ£o relativa dos dados em relaÃ§Ã£o Ã  mÃ©dia. Valores mais baixos de CV indicam que os dados estÃ£o mais concentrados em torno da mÃ©dia, enquanto valores mais altos indicam uma maior dispersÃ£o.

+ Acrescente mais uma amostra com valor de batimento igual a 120, recalcule as medidas acima. Qual conjunto vocÃª consideraria mais adequado para resumir sua amostra, na presenÃ§a desse valor discrepante (_outlier_)? A mÃ©dia (DP) ou mediana (1o.Q ; 3o.Q)? Explique.




<!--chapter:end:06-Estatistica-Descritiva.Rmd-->

# Importando banco de dados

Na prÃ¡tica, os dados que vamos analisar estarÃ£o armazenado em um **banco de dados**, um arquivo de banco de dados pode ser de diferentes tipos, por exemplo:

+ Arquivo do tipo Excel (xls ou xlsx)

+ Arquivo de texto separado por vÃ­rgulas (csv - _comma-separated values_)


> Existem vÃ¡rias fontes de dados abertas, onde podemos baixar um banco de dados para realizar analises estatÃ­sticas, aqui estÃ£o algumas delas:

+ DataSus: <https://datasus.saude.gov.br/transferencia-de-arquivos>

+ OMS: <https://www.who.int/data/collections>

+ Kaggle: <https://www.kaggle.com/datasets>


> No link (google drive) existem alguns bancos que podemos usar para compreender como importar um banco de dados para o ambiente do RStudio: <https://drive.google.com/drive/folders/1gyORbBEuKBstfSKULA58TLhawOXaY-st>

## Importando um banco csv

1. FaÃ§a _download_ do banco de dados **mcdonald.csv** 
(fonte original: https://www.kaggle.com/datasets/mcdonalds/nutrition-facts)

2. Na Ã¡rea de ambinete de memÃ³ria, localize **Import Dataset**, ao clicar nessa opÃ§Ã£o vocÃª terÃ¡ o seguinte:

<center>![<font size="2"> Figura: Importando banco de dados</font>](telaImportDataset.png){width=40%}
</center>

+ Como queremos importar um arquivo csv, a melhor opÃ§Ã£o Ã© a segunda **From Text (readr)**

+ **_readr_** Ã© uma pacote do R que faz a leitura de arquivo csv (se o pacote ainda nÃ£o estiver instalado no seu computador, o R farÃ¡ a instalaÃ§Ã£o, se vocÃª concordar!)

3. Clicando na opÃ§Ã£o **From Text (readr)**, no botÃ£o **browser** indidique onde (no seu computador) estÃ¡ localizado o arquivo a ser importado. A seguinte tela serÃ¡ apresentada:

<center>![<font size="2"> Figura: PrÃ©via dos dados</font>](telaImportBrowser.png)
</center>

+ No quadro **Data Preview**, temos uma "prÃ©via" com os nomes da variÃ¡veis, seus tipos computacionais e os primeiros valores que estÃ£o armazenados no banco de dados.

+ No quadro **Import Options** temos as opÃ§Ãµes de importaÃ§Ã£o, fique atento ao **Name** do seu banco de dados, geralmente usamos nomes sem espaÃ§os ou caracteres especiais (', ~  ou Ã§), Ã© atÃ© permitido usar alguns desses caracteres especiais, mas evite. 

+ Ainda no quadro **Import Options**, observe que a opÃ§Ã£o **Open Data Viewer** estÃ¡ marcada, isso significa que ao importar o banco de dados, o arquivo de banco de dados serÃ¡ aberto pelo RStudio. Caso esteja trabalhando com bancos com muitos dados (como os bancos do dataSUS), talvez seja melhor desmarcar essa opÃ§Ã£o para nÃ£o sobrecarregar o processamento do seu computador.

+ O quadro **Code Preview** mostra como Ã© a importaÃ§Ã£o (leitura) do banco de dados via cÃ³digo. Ã‰ interessante copiar esse trecho de cÃ³digo para o arquivo de script.

4. Clique no botÃ£o **Import** e observe que no ambiente de memÃ³ria serÃ¡ criado o objeto do tipo **Data** com o nome do banco de dados que foi importado. 

<center>![<font size="2"> Figura: Import dataset</font>](telaImportObjetoData.png){width=60%}
</center>

+ Observe que esse objeto do tipo **Data** Ã© diferente dos objetos do tipo **Values** que vimos nos exemplos iniciais.

+ Ao clicar no Ã­cone ao lado do nome do objeto, temos acesso ao nomes e tipos computacionais das variÃ¡veis, e ao clicar sobre nome do objeto, o banco serÃ¡ aberto!

## Importando um banco xls

Na Ã¡rea de ambiente de memÃ³ria, localize **Import Dataset**, ao clicar sobre essa opÃ§Ã£o, escolha **From Excel...**

<center>![<font size="2"> Figura: Importando banco de dados</font>](telaImportDataset.png){width=40%}
</center>

+ Se for a primeira vez que vocÃª estiver importando um arquivo Excel, pode ser necessÃ¡ria a instalaÃ§Ã£o do pacote que fornece a biblioteca que tem a funÃ§Ã£o de leitura de arquivo xls (**readxl**)! O RStudio mostrarÃ¡ um aviso parecido com este: 

<center>![<font size="2"> Figura: Aviso para instalaÃ§Ã£o de pacote</font>](telaImportPacote.png){width=40%}
</center>


## Exemplo 1

Como obter a mÃ©dia da variÃ¡vel **Calories** que Ã© uma coluna do objeto **mcdonald**, que por sua vez, Ã© um objeto do tipo **Data**? 

```{r eval=FALSE, results='hide'}
# Usamos o operador $
# Para calcular a mÃ©dia precisamos informar para funÃ§Ã£o: 
# mean( NOME DO BANCO $ NOME DA COLUNA ): 
mean(mcdonald$Calories)
```

## Exemplo 2

Como armazenar os valores de uma variÃ¡vel (coluna), em um objeto do tipo **Values** e depois calcular a mÃ©dia?

```{r eval=FALSE, results='hide'}
# Uso o operador <- 
# Criamos o objeto 
caloria <- mcdonald$Calories
# Agora podemos usar o objeto que criamos, por exemplo para calcular a mÃ©dia e o desvio padrÃ£o
mean(caloria)
sd(caloria)
```

## Exemplo 3

O que acontece se usamos a funÃ§Ã£o **summary()** para o objeto **mcdonald**, sem usar o operador, isto Ã© sem indicar uma variÃ¡vel?
```{r eval=FALSE, results='hide'}
# No console serÃ¡ mostrado o resumo de todas as variÃ¡veis do banco!
summary(mcdonald)
```

> Essa forma de obter os resultados nÃ£o Ã© a melhor forma, vamos **instalar um pacote** para obter os resultados em uma tabela bem formatada que podemos copiar e colar diretamente para um editor de texto. 

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/packages/lf20_ynsr82zq.json"  background="transparent"  speed="2"  style="width: 200px; height: 200px;"  loop  autoplay></lottie-player>
</center>

<!--chapter:end:07-Importando-BD.Rmd-->

# Instalando pacotes

Quando instalamos nosso ambiente computacional R e RStudio, instalamos uma versÃ£o bÃ¡sica, onde apenas os recursos bÃ¡sicos do R estÃ£o diponÃ­veis, o pacote bÃ¡sico (**base**) do R.

Os pacotes (**packages**) do R sÃ£o compostos por uma biblioteca (**library**) que Ã© um conjunto de funÃ§Ãµes. Por exemplo, do pacote **base** usamos as funÃ§Ãµes min(), max(), mean(), median(), table(), var(), sd(), summary(), etc.

Para ver a lista de funÃ§Ãµes que compÃµem a bilbioteca do pacote base, execute o cÃ³digo:
```{r}
library(help = "base")
```

Os pacotes sÃ£o anÃ¡logos aos aplicativos que instalamos nos nossos celulares, sÃ£o mÃ³dulos que agregam funcionalidades especÃ­ficas. Ao longo das nossas atividades usaremos alguns desses pacotes.

Como nesse momento estamos interessados em otimizar o trabalho para realizar uma anÃ¡lise descritiva dos dados, entÃ£o vamos instalar um pacote chamado **gtsummary** (<https://www.danieldsjoberg.com/gtsummary/>).

> O pacote **gtsummary** nos fornecerÃ¡ uma tabela resumo de todo banco de dados, otimizando bastante nosso trabalho de resumir o banco de dados. 

+ IMPORTANTE 1: instalamos um pacote apenas uma vez (como um aplicativo no celular... a gente sÃ³ refaz a instalaÃ§Ã£o se o app _bugar_!)

+ IMPORTANTE 2: todas vez precisamos carregar o pacote com as funÃ§Ãµes que queremos usar por meio da funÃ§Ã£o **library()**

Veja o cÃ³digo:

```{r eval=FALSE}
# comando para instalar o pacote gtsummary
install.packages("gtsummary")

# comando para carregar a biblioteca de funÃ§Ãµes do gtsummary
library(gtsummary)

# a funÃ§Ã£o que vamos usar para gerar uma tabela que resume os dados Ã©
# tbl_summary
tbl_summary(mcdonald)
```

+ Ao executar **tbl_summary(mcdonald)** a tabela de resultados serÃ¡ mostrada na Ã¡rea de arquivos, grÃ¡ficos, pacotes... na aba **Viewer**, no quadrante abaixo do ambiente de memÃ³ria.

+ Essa tabela pode ser copiada e colada para o editor de texto que vocÃª utiliza para escrever seus trabalhos, claro essa tabela pode ser melhorada!

+ Observe no rodapÃ© da tabela a seguinte legenda  **n (%); Median (IQR)**, isso significa que para

    + **variÃ¡veis qualitativas:** n Ã© a contagem (frequÃªncia absoluta) e entre parenteses (%) Ã© mostrado a porcentagem de cada categoria.
  
    + **variveis quantitativas:** Median Ã© a mediana e entre parenteses (IQR - de InterQuantile Range) estÃ£o o primeiro e terceiro quartil respectivamente. 

## Exemplo 1
Como mostrar o resultado com a mÃ©dia e desvio padrÃ£o?

```{r eval=FALSE}
# acrescente nos argumentos da funÃ§Ã£o tbl_summary() a opÃ§Ã£o:
# statistic = list(all_continuous() ~ "{mean} ({sd})"
tbl_summary(
            mcdonald, 
            statistic = list(all_continuous() ~ "{mean} ({sd})")
            )
```

## Exemplo 2
Como selecionar somente algumas variÃ¡veis do banco de dados?
```{r eval=FALSE}
# Precisamos do pacote tidyverse, tire o sÃ­mbolo de # se precisar instalar!
# install.packages("tidyverse")

# ative tidyverse
library(tidyverse)

# vamos usar a funÃ§Ã£o select() do pacote tidyverse
dadosSelecionados <- select (mcdonald, Cholesterol, Sodium, Carbohydrates)

# faÃ§a uma tabela para o objeto dadosSelecionados
tbl_summary(dadosSelecionados)
```

## Exemplo 3
Algumas vezes Ã© mais fÃ¡cil excluir algumas variÃ¡veis, por exemplo queremos todas, menos **Item** e **Serving  Size**	
```{r eval=FALSE}
# vamos usar a funÃ§Ã£o select() do pacote tidyverse e colocar o sinal de menos (-)
# antes dos nomes das variÃ¡veis que queremos excluir
# IMPORTANTE: Serving Size Ã© um nome de variÃ¡vel com espaÃ§o 
# entÃ£o devemos referÃªnciÃ¡-la entre aspas: `Serving Size`
dadosSelecionados2 <- select (mcdonald, -Item, -`Serving Size`)

# faÃ§a uma tabela para o objeto dadosSelecionados2
tbl_summary(dadosSelecionados2)
```


## Exemplo 4
Como selecinar um conjunto de variÃ¡veis que estÃ£o em sequÃªncia, por exemplo, de **Carbohydrates** a **Cholesterol (% Daily Value)**
```{r eval=FALSE}
# vamos usar a funÃ§Ã£o select() do pacote tidyverse e colocar o sinal de dois pontos (:)
# entre a primeira variÃ¡vel e a Ãºltima da sequÃªncia 
# IMPORTANTE: Cholesterol (% Daily Value) Ã© um nome de variÃ¡vel com espaÃ§o 
# entÃ£o devemos referÃªnciÃ¡-la entre aspas: `Cholesterol (% Daily Value)`
dadosSelecionados3 <- select (mcdonald, Carbohydrates:`Cholesterol (% Daily Value)`)

# faÃ§a uma tabela para o objeto dadosSelecionados
tbl_summary(dadosSelecionados3)
```

> Saiba mais sobre o Tidyverse <https://www.tidyverse.org/packages/>

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 5

**Escolha outro banco de dados (vocÃª pode atÃ© criar um banco fictÃ­cio!), faÃ§a uma tabela descritiva dos dados e escreva sobre os dados (um ou dois parÃ¡grafos), afinal, o nosso trabalho nÃ£o Ã© sÃ³ obter a tabela, Ã© dissertar sobre o que essa tabela revela sobre a amostra em estudo!**



<!--chapter:end:08-Instalando-Pacotes.Rmd-->

# GrÃ¡ficos

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/packages/lf20_kgyknvpj.json"  background="transparent"  speed="2"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>

Nesse link <https://r-graph-gallery.com/> estÃ¡ algumas possibilidades de grÃ¡ficos que podemos fazer usando o R. Para fazer grÃ¡ficos mais elaborados (aparentemente mais atrativos visualmente) usamos o pacote **GGPlot2** <https://ggplot2.tidyverse.org/>.

Focaremos nossa atenÃ§Ã£o em dois grÃ¡ficos especÃ­ficos para variÃ¡veis quantitativas: **Histograma** e **Boxplot**, em nem faremos nada atrativo, usaremos o pacote bÃ¡sico do R que nos fornece as funÃ§Ãµes **hist()** e **boxplot()**, pois o nosso obtivo para esse momento Ã© simplesmente estudar a importÃ¢ncia desses grÃ¡ficos.

O que a gente levaria um tempinho... Ã© simplesmente assim em cÃ³digo R:

```{r eval=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)

# Para fazer o Histograma de Batimentos
hist(Batimentos)

# Para fazer o Boxplot de Batimentos
boxplot(Batimentos)
```

Na Ã¡rea de grÃ¡ficos (**Plots**), abaixo do ambiente de memÃ³ria, serÃ£o mostrados os grÃ¡ficos:

> Histograma

```{r echo=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)
hist(Batimentos)
```


> Boxplot

```{r echo=FALSE}
Batimentos <- c(62, 55, 56, 46, 75, 67, 62, 75, 60, 54, 69, 63, 39, 57, 40, 39, 64, 71, 61, 54, 120)
boxplot(Batimentos)
```

> ObservaÃ§Ãµes

+ Os grÃ¡ficos mostram a informaÃ§Ã£o batimentos de duas formas diferentes, mas elas estÃ£o relacionadas!

+ Observe que eixo horizontal do histograma corresponde ao eixo vertical do boxplot

## Histograma

O histograma Ã© um grÃ¡fico que usado para variÃ¡veis quantitativas contÃ­nua.

O histograma pode nos dar uma noÃ§Ã£o do tipo de **distribuiÃ§Ã£o de probabibilidade** que os dados seguem.

A ideia desse grÃ¡fico Ã© agrupar os dados em  **classes** (cada barra do histograma Ã© uma classe) e no eixo vertical tem-se a contagem (frequÃªncia) de quantos valores foram alocados em cada classe.

Para fazer a **leitura do histograma**:

  + Identifique as classes no "eixo x" 
  
  + Identifique quantos elementos tem em cada classe no "eixo y"
 
Acredito que nesse exemplo, Ã© fÃ¡cil verificar:

  + A segunda classe: 40 - 50 batimentos, que tem 1 elemento (verifique no objeto Batimentos)
  
  + A terceira classe: 50 - 60 batimentos, que tem 6 elementos  
  
  + EntÃ£o, a **aplitude das classes** Ã© igual a 10. Logo, a primeira classe Ã© de 30 - 40. 
  
  + As classes 80 - 90; 90 - 100 e 100 - 110 nÃ£o tiveram ocorrÃªncias!
  
  + A classe 110-120 possui 1 elemento, que Ã© aquele valor discrepante em relaÃ§Ã£o aos demais valores.


Se nÃ£o for fÃ¡cil identificar as classes (eixo x) vocÃª pode usar o comando abaixo: 

```{r eval=FALSE}
# Para obter as "quebras" de cada classe 
hist(Batimentos)$breaks
```

Se nÃ£o for fÃ¡cil identificar as frequencias (eixo y) vocÃª pode usar o comando abaixo:  
```{r eval=FALSE}
# Para obter a frequÃªncia em cada classe
hist(Batimentos)$count
```

De fato, o que estamos lendo por meio do histograma Ã© o que chamamos de **tabela de frequÃªncia**: 

|   Classe  | FrequÃªncia |
|:---------:|:----------:|
|  30 - 40  |      3     |
|  40 - 50  |      1     |
|  50 - 60  |      6     |
|  60 - 70  |      7     |
|  70 - 80  |      3     |
|  80 - 90  |      0     |
|  90 - 100 |      0     |
| 100 - 110 |      0     |
| 110 - 120 |      1     |
|$\sum n$  |     21     |

  + Por meio do histograma ou da tabela podemos concluir que a classe modal (moda) Ã© a classe de 60 - 70 batimentos;
  
  + A frequÃªncia foi apresentada em termos absolutos mais pode ser transformada em frequÃªncia percentual.
  
  + Quando estamos aprendendo a fazer um histograma manualmente, primeiro construÃ­mos essa tabela de frenquÃªncia, e para construÃ­-la Ã© necessÃ¡rio calcular o nÃºmero Ã³timo de classes, umas das regras mais usada Ã© a Regra Sturges (essa Ã© opÃ§Ã£o padrÃ£o do R).

Podemos usar o pacote bÃ¡sico R para melhorar a aparÃªncia desse grÃ¡fico.
```{r}
hisBat <- hist(Batimentos,
               main = "Histograma",
               xlab = "Batimentos cardÃ­acos",
               sub = "por classes",
               ylab = "FrequÃªncia absoluta",
               xlim = c(20, 120),
               ylim = c(0, 8),
               col = "lightgreen")
text(hisBat$mids, hisBat$counts, labels=hisBat$counts, adj = c(0.5,-0.5))

# adicionar linha para indicar a mÃ©dia
abline(v = mean(Batimentos),                      
       col = "red",
       lwd = 3)
```

## Boxplot

Boxplot ou diagrama de caixa, Ã© um grÃ¡fico que mostra as medidas: menor valor, primeiro quartil, mediana, terceiro quartil e mÃ¡ximo valor.

+ Valores discrepantes (_outliers_) sÃ£o detectados pelo boxplot. Veja a figura:

<center>![<font size="2">Figura: "Anatomia de um boxplot"</font>](Boxplotexemplo.png){width=50%}
</center>

Essa figura foi retirada do site da Prof. Fernanda https://fernandafperes.com.br/blog/interpretacao-boxplot/ (uma exelente referÃªncia para estudar estatÃ­stica!)

> Geralmente eles sÃ£o representados na vertical, mas tambÃ©m Ã© comum a representaÃ§Ã£o na horizontal.

```{r eval=FALSE}
# Para fazer o Boxplot de Batimentos na horizontal
boxplot(Batimentos, horizontal = TRUE)
```

> Ã‰ uma forma de comparar dois grupos em relaÃ§Ã£o a uma medida, por exemplo os batimentos cardiacos de grupo de homens e de mulheres
```{r}
# GeraÃ§Ã£o de amostras simuladas
set.seed(1)
BatimentosMulheres <- rnorm(30, 70, 3)
BatimentosHomens <- rnorm(30, 75, 8)
# Boxplot para os dois grupos Homens e Mulheres 
boxplot(BatimentosHomens, BatimentosMulheres)
```


> O boxplot tambÃ©m pode nos informar se uma distribuiÃ§Ã£o de probabilidade Ã© simÃ©trica ou nÃ£o. Analise os grÃ¡ficos abaixo, veja a conexÃ£o entre histograma e boxplot.

```{r echo=FALSE}
set.seed(1000)
simetrica <- rnorm(1000, 40, 5)
hist(simetrica,
     main="DistribuiÃ§Ã£o SIMÃ‰TRICA",
     xlab = "",
     ylab="")
```



```{r echo=FALSE}
set.seed(1000)
assimetrica <- 20 + 10*rexp(1000, 5)
hist(assimetrica,
     main="DistribuiÃ§Ã£o ASSIMÃ‰TRICA",
     xlab = "",
     ylab="")
abline(v = mean(assimetrica),                      
       col = "red",
       lwd = 3)
boxplot(assimetrica, horizontal = T)
summary(assimetrica)
```

<center>
<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets1.lottiefiles.com/packages/lf20_33asonmr.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>
</center>
## Atividade 6

**Para o banco de dados escolhido na atividade 5, faÃ§a grÃ¡ficos como o histograma e boxplot, alÃ©m disso, pesquise outras formas de fazer grÃ¡ficos no R.**

# Pacote `ggplot` 

O `ggplot2` Ã© um dos pacotes mais populares do R para a criaÃ§Ã£o de grÃ¡ficos estatÃ­sticos sofisticados e visualmente atraentes. Baseado no conceito da "GramÃ¡tica dos GrÃ¡ficos", o `ggplot2` permite construir grÃ¡ficos de maneira flexÃ­vel e modular, combinando camadas (layers) de dados, geometrias, escalas e temas.

## Principais Vantagens

- Produz grÃ¡ficos de alta qualidade e personalizÃ¡veis.
- Permite adicionar camadas de informaÃ§Ã£o facilmente.
- Suporta uma variedade de tipos de grÃ¡ficos.


## Exemplos de GrÃ¡ficos Simples e Bonitos com ggplot2

Antes de comeÃ§ar, certifique-se de instalar e carregar o pacote:

```r
install.packages("ggplot2")
library(ggplot2)
```

Para ilustrar alguns grÃ¡ficos utilizando o `ggplot2`, empregaremos o conjunto de dados *iris*, que jÃ¡ estÃ¡ disponÃ­vel nativamente no R.

O *iris* Ã© um dos bancos de dados mais clÃ¡ssicos e utilizados em estatÃ­stica e aprendizado de mÃ¡quina, trazendo informaÃ§Ãµes sobre 150 flores de trÃªs espÃ©cies diferentes, com quatro variÃ¡veis quantitativas (comprimento e largura das sÃ©palas e pÃ©talas). Ele Ã© amplamente utilizado para exemplos de anÃ¡lise exploratÃ³ria de dados, classificaÃ§Ã£o e visualizaÃ§Ã£o de padrÃµes.

AlÃ©m do iris, o R oferece outros conjuntos de dados nativos bastante Ãºteis para exercÃ­cios e demonstraÃ§Ãµes em diversas Ã¡reas, como *mtcars* (carros), *ToothGrowth* (crescimento de dentes em cobaias), *sleep* (efeito de medicamentos no sono), *airquality* (qualidade do ar em Nova Iorque) e *CO2* (absorÃ§Ã£o de CO2 em plantas).

### GrÃ¡fico de DispersÃ£o (Scatterplot)

```{r, ggplotIris, message=FALSE, warning=FALSE}
library(ggplot2)
# Exemplo com o dataset iris
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
  geom_point(size = 3, alpha = 0.7) +
  theme_minimal() +
  labs(title = "GrÃ¡fico de DispersÃ£o: iris",
       x = "Comprimento da SÃ©pala",
       y = "Largura da SÃ©pala")
```

### GrÃ¡fico de Barras

```{r, ggbarIris}
# Contagem das espÃ©cies no dataset iris
ggplot(iris, aes(x = Species, fill = Species)) +
  geom_bar() +
  theme_classic() +
  labs(title = "GrÃ¡fico de Barras: Contagem de EspÃ©cies",
       x = "EspÃ©cie",
       y = "Contagem")
```

### Histograma

```{r, gghistIris}
# DistribuiÃ§Ã£o do comprimento da sÃ©pala
ggplot(iris, aes(x = Sepal.Length, fill = Species)) +
  geom_histogram(binwidth = 0.3, color = "white", alpha = 0.7, position = "identity") +
  theme_light() +
  labs(title = "Histograma: Comprimento da SÃ©pala",
       x = "Comprimento da SÃ©pala",
       y = "FrequÃªncia")
```

### Boxplot

```{r, ggboxplotIris}
# DistribuiÃ§Ã£o do comprimento da pÃ©tala por espÃ©cie
ggplot(iris, aes(x = Species, y = Petal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  theme_bw() +
  labs(title = "Boxplot: Comprimento da PÃ©tala por EspÃ©cie",
       x = "EspÃ©cie",
       y = "Comprimento da PÃ©tala")
```


O `ggplot2` oferece diversas opÃ§Ãµes de personalizaÃ§Ã£o, como cores, temas e anotaÃ§Ãµes, permitindo criar grÃ¡ficos bonitos e informativos para diferentes finalidades.


## Exemplos de Bancos de Dados do R

| Banco de Dados    | Pacote      | Ãrea/DescriÃ§Ã£o                                               |
|:-------------------|:-------------|:--------------------------------------------------------------|
| iris              | datasets    | BotÃ¢nica, estatÃ­stica, aprendizado de mÃ¡quina (flores)       |
| mtcars            | datasets    | AutomÃ³veis, regressÃ£o, anÃ¡lise multivariada                  |
| airquality        | datasets    | Qualidade do ar, saÃºde ambiental                             |
| ToothGrowth       | datasets    | Farmacologia, saÃºde, crescimento de dentes                   |
| sleep             | datasets    | Psicologia, farmacologia, estudo do sono                     |
| ChickWeight       | datasets    | NutriÃ§Ã£o, crescimento animal                                 |
| USArrests         | datasets    | Sociologia, estatÃ­sticas criminais dos EUA                   |
| CO2               | datasets    | Biologia, fisiologia vegetal                                 |
| BOD               | datasets    | Biologia, demanda bioquÃ­mica de oxigÃªnio                     |
| Boston            | MASS        | ImobiliÃ¡rio, regressÃ£o, anÃ¡lise multivariada                 |
| lung              | survival    | Medicina, anÃ¡lise de sobrevivÃªncia (dados de cÃ¢ncer de pulmÃ£o)|
| bfi               | psych       | Psicologia, personalidade (Big Five Inventory)               |
| NHANES            | NHANES      | SaÃºde pÃºblica, epidemiologia (pesquisa nacional dos EUA)     |
| titanic           | titanic     | SobrevivÃªncia, estatÃ­stica, aprendizado de mÃ¡quina           |
| worldcup          | faraway     | Esportes (Copa do Mundo de Futebol)                          |

**Nota:**  
Os bancos do pacote `datasets` jÃ¡ vÃªm instalados por padrÃ£o no R. Outros, como `MASS`, `psych`, `NHANES`, `survival`, `titanic` e `faraway`, podem ser instalados via `install.packages("nome_do_pacote")`.  
Verifique sempre a documentaÃ§Ã£o do pacote para acessar o nome correto dos bancos de dados e exemplos de uso.

<!--chapter:end:09-Graficos.Rmd-->

# DistribuiÃ§Ã£o de Probabilidade

Uma distribuiÃ§Ã£o de probabilidade Ã© um modelo matemÃ¡tico que descreve a relaÃ§Ã£o entre os valores possÃ­veis de uma variÃ¡vel e as probabilidades de ocorrÃªncia desses valores. Essencialmente, ela nos permite prever a probabilidade de eventos com base em um conjunto de dados.

Entre as distribuiÃ§Ãµes mais comuns, destacam-se:

- DistribuiÃ§Ã£o Normal (ou Gaussiana)
- DistribuiÃ§Ã£o Binomial
- DistribuiÃ§Ã£o Poisson
- DistribuiÃ§Ã£o Exponencial
- DistribuiÃ§Ã£o Uniforme
- DistribuiÃ§Ã£o Qui-quadrado
- DistribuiÃ§Ã£o t-Student
- DistribuiÃ§Ã£o Gama, entre outras.

Cada tipo de distribuiÃ§Ã£o possui caracterÃ­sticas prÃ³prias e Ã© aplicada em diferentes contextos. A distribuiÃ§Ã£o normal Ã© uma das mais amplamente utilizadas, especialmente para modelar fenÃ´menos naturais e sociais, como a altura de indivÃ­duos ou o tempo de vida de produtos.

> **Propriedades Gerais das DistribuiÃ§Ãµes de Probabilidade**

- **Ãrea total sob a curva Ã© igual a 1:** Isso significa que a soma de todas as probabilidades possÃ­veis de ocorrÃªncia dos eventos Ã© igual a 100%.
- **A Ã¡rea sob a curva representa a probabilidade de um evento.** Por exemplo, a probabilidade de um evento ocorrer entre dois valores quaisquer pode ser calculada pela Ã¡rea sob a curva entre esses dois pontos.

## DistribuiÃ§Ã£o Normal

A distribuiÃ§Ã£o normal Ã© uma das mais conhecidas na estatÃ­stica. Ela modela fenÃ´menos que seguem um comportamento simÃ©trico em torno de uma mÃ©dia. A distribuiÃ§Ã£o normal tem vÃ¡rias aplicaÃ§Ãµes, desde a anÃ¡lise de medidas biolÃ³gicas (como a pressÃ£o arterial) atÃ© a previsÃ£o de fenÃ´menos econÃ´micos (como o preÃ§o das aÃ§Ãµes).

> **A distribuiÃ§Ã£o normal Ã© definida por dois parÃ¢metros principais:**

- **MÃ©dia (Î¼):** Representa o valor central da distribuiÃ§Ã£o.
- **Desvio PadrÃ£o (Ïƒ):** Mede a dispersÃ£o dos dados em relaÃ§Ã£o Ã  mÃ©dia.

> **CaracterÃ­sticas da DistribuiÃ§Ã£o Normal**

- **Forma de sino:** A distribuiÃ§Ã£o normal tem a forma de um sino simÃ©trico, com a maior concentraÃ§Ã£o de dados perto da mÃ©dia.
- **Simetria:** A distribuiÃ§Ã£o Ã© simÃ©trica em relaÃ§Ã£o Ã  mÃ©dia.
- **MÃ©dia, Mediana e Moda:** Para uma distribuiÃ§Ã£o normal, a mÃ©dia, mediana e moda sÃ£o "iguais" e localizam-se no centro da distribuiÃ§Ã£o.

> **Teoricamente o comportamento da DistribuiÃ§Ã£o Normal Ã© dado por:**

<center>

![<font size="2">Figura: DistribuiÃ§Ã£o Normal teÃ³rica (Fonte: <https://www.inf.ufsc.br/~andre.zibetti/probabilidade/figures/normal.PNG>)</font>](normalTeorica.png){width="80%"}

</center>

Onde:

-   A mÃ©dia estÃ¡ representada por $\mu$
-   O devio padrÃ£o estÃ¡ representado por $\sigma$

> **Regra empirica 68% - 95% - 99,7%**
Se os dados seguem uma distribuiÃ§Ã£o normal, Ã© possÃ­vel fazer afirmaÃ§Ãµes sobre a concentraÃ§Ã£o dos dados em torno da mÃ©dia, conforme a regra empÃ­rica:

- *68%* dos dados estÃ£o no intervalo de uma vez o desvio padrÃ£o (Î¼ Â± 1Ïƒ).
- *95%* dos dados estÃ£o no intervalo de duas vezes o desvio padrÃ£o (Î¼ Â± 2Ïƒ).
- *99,7%* dos dados estÃ£o no intervalo de trÃªs vezes o desvio padrÃ£o (Î¼ Â± 3Ïƒ).

**Importante:** Dados fora do intervalo de Î¼ Â± 3Ïƒ sÃ£o considerados raros.

> Exemplo de distribuiÃ§Ã£o Normal, com dados simulados usado a funÃ§Ã£o rnorm().

```{r}

# semente de geraÃ§Ã£o de nÃºmeros aleatÃ³rios 
set.seed(1)

# SerÃ¡ simulada uma amostra com a seguinte caracterÃ­stica:
# 1000 valores
# mÃ©dia ~ 70
# desvio padrÃ£o ~ 3
# A funÃ§Ã£o rnorm() gera nÃºmeros randÃ´micos com comportamento de uma distribuiÃ§Ã£o Normal 
BatimentosMulheres <- rnorm(1000, 70, 3)

# Arrendodamento com nenhuma casa depois da vÃ­rugula
BatimentosMulheres <- round(BatimentosMulheres,0)

# histograma
hist(BatimentosMulheres)

# Classes e frequencias do histograma
hist(BatimentosMulheres)$breaks
hist(BatimentosMulheres)$count

# histograma e curva de densidade (da Dist. Normal)
hist(BatimentosMulheres, prob = TRUE)
lines(density(BatimentosMulheres), col = 4, lwd = 2)

# idicaÃ§Ã£o da mÃ©dia
abline(v = mean(BatimentosMulheres), col = 2, lwd = 3)

# medidas resumo
summary(BatimentosMulheres)
sort(table(BatimentosMulheres), decreasing = T)
sd(BatimentosMulheres)

# CV em %
sd(BatimentosMulheres)/mean(BatimentosMulheres)*100
```

> As funÃ§Ãµes **pnorm()** e **dnorm()** sÃ£o usadas para calcular a probabilidade de um evento que segue uma distribuiÃ§Ã£o, a qual conhecemos a mÃ©dia e o desvio padrÃ£o.

**Exemplo:** Sabendo que os batimentos cardÃ­acos de mulheres de 18 a 65 anos tem mÃ©dia de 70bmp e desvio padrÃ£o igual a 3bmp.

Calcule as probabilidades:

-   de uma mulher ter batimentos inferior a 70bmp, ou seja, $P(x<70)$:

```{r}
# pnorm(): Calcula a probabilidade acumulada atÃ© um valor especÃ­fico. Ou seja, retorna a probabilidade de que uma variÃ¡vel aleatÃ³ria, que segue uma distribuiÃ§Ã£o normal, seja menor ou igual a um determinado valor.

# observaÃ§Ã£o: a resposta Ã© 0.5 pois a mÃ©dia 70.
pnorm(70, 70, 3)
```

-   de uma mulher ter batimentos superior a 70bmp, ou seja, $P(x>70)$:

```{r}
# observaÃ§Ã£o: 1 Ã© o valor da Ã¡rea total
# a pnorm() fornece a Ã¡rea Ã¡ esquerda
1 - pnorm(70, 70, 3)
```

-   de uma mulher ter batimentos igual a 70bmp, ou seja, $P(x=70)$:

```{r}
# dnorm(): Calcula a densidade de probabilidade de um valor especÃ­fico em uma distribuiÃ§Ã£o normal. Em outras palavras, ela retorna o valor da funÃ§Ã£o densidade de probabilidade no ponto especificado.
dnorm(70, 70, 3)
```

-   de uma mulher ter batimentos entre 67 e 73bmp $P(67 < x < 73)$:

```{r}
# Observe que estamos testando a regra empÃ­rica (68%)
pnorm(73, 70, 3) - pnorm(67, 70, 3)
```

-   de uma mulher ter batimentos entre 67 e 73bmp $P(64 < x < 76)$:

```{r}
# Observe que estamos testando a regra empÃ­rica (95%)
pnorm(76, 70, 3) - pnorm(64, 70, 3)
```

-   de uma mulher ter batimentos entre 61 e 79bmp $P(61 < x < 79)$:

```{r}
# Observe que estamos testando a regra empÃ­rica (99,7%)
pnorm(79, 70, 3) - pnorm(61, 70, 3)
```

-   de uma mulher ter batimentos maior que 90bmp $P(x > 90)$:

```{r}
# Um evento raro
1 - pnorm(90, 70, 3)
```

-   de uma mulher ter batimentos menor que 65bmp $P(x < 65)$:

```{r}
pnorm(65, 70, 3)
```

## GrÃ¡fico QQ

Uma maneira comum de verificar a normalidade de uma distribuiÃ§Ã£o Ã© utilizando o grÃ¡fico QQ. Ele compara os quantis de uma amostra com os quantis de uma distribuiÃ§Ã£o normal padrÃ£o, e Ã© muito Ãºtil para identificar se os dados seguem uma distribuiÃ§Ã£o normal.

> **DistribuiÃ§Ã£o Normal PadrÃ£o**

A distribuiÃ§Ã£o normal padrÃ£o tem duas caracterÃ­sticas importantes:

- MÃ©dia (Î¼) igual a 0
- Desvio padrÃ£o (Ïƒ) igual a 1


> **CÃ¡lculo do Escore Z**

Qualquer distribuiÃ§Ã£o normal pode ser transformada na distribuiÃ§Ã£o normal padrÃ£o utilizando o escore Z. O **escore Z** Ã© calculado pela fÃ³rmula:

\[
z = \frac{(x - \mu)}{\sigma}
\]

Onde:

- \(x\) Ã© o valor da observaÃ§Ã£o.
- \(\mu\) Ã© a mÃ©dia da distribuiÃ§Ã£o.
- \(\sigma\) Ã© o desvio padrÃ£o da distribuiÃ§Ã£o.

O grÃ¡fico QQ realiza exatamente o que a fÃ³rmula do escore Z descreve: ele transforma os dados da amostra para a distribuiÃ§Ã£o normal padrÃ£o (mÃ©dia 0 e desvio padrÃ£o 1) e entÃ£o compara esses valores transformados com os quantis da distribuiÃ§Ã£o normal teÃ³rica. Se os pontos formarem uma linha reta, isso sugere que os dados seguem uma distribuiÃ§Ã£o normal.

Veja um exemplo no R para uma DistribuiÃ§Ã£o Normal PadrÃ£o: 

```{r}
set.seed(1)
# rnorm(10000, 0, 1): normal padrÃ£o mÃ©dia 0, dp=1
# ou simplesmente rnorm(10000)
NormalPadrao <- rnorm(10000)
hist(NormalPadrao, probability = T)
lines(density(NormalPadrao), col = 4, lwd = 2)
axis(side = 1, at = seq(-3, 3, by = 1), labels = seq(-3, 3, by = 1))
abline(v = mean(NormalPadrao), col = 2, lwd = 3)
```

No grÃ¡fico QQ, os quantis da amostra sÃ£o comparados com os quantis da distribuiÃ§Ã£o normal padrÃ£o. Se a amostra segue uma distribuiÃ§Ã£o normal, os pontos no grÃ¡fico QQ devem se alinhar aproximadamente a uma linha reta.

Se os pontos se afastam dessa linha reta de forma sistemÃ¡tica, isso indica que os dados nÃ£o seguem uma distribuiÃ§Ã£o normal. O tipo de desvio pode dar pistas sobre a natureza dessa nÃ£o-normalidade (por exemplo, se os pontos se curvam para cima ou para baixo, pode indicar assimetria ou caudas pesadas).


> DistrbuiÃ§Ã£o normal Ã© usada para dados contÃ­nuos!

```{r}
# GrÃ¡fico QQ
set.seed(1)
BatimentosMulheres <- rnorm(1000, 70, 3)
qqnorm(BatimentosMulheres)
qqline(BatimentosMulheres, col="red")

# FaÃ§a o arredondamento
BatimentosMulheresR <- round(BatimentosMulheres,0)
qqnorm(BatimentosMulheresR)
qqline(BatimentosMulheresR)
```

> A distribuiÃ§Ã£o Normal Ã© uma distribuiÃ§Ã£o para modelar variÃ¡veis **CONTÃNUAS**!

## Atividade 7

**Utilizando o banco de dados escolhido para as atividades 5 e 6, gere grÃ¡ficos QQ para as variÃ¡veis quantitativas. Em seguida, avalie visualmente se essas variÃ¡veis seguem uma distribuiÃ§Ã£o normal.**

<!--chapter:end:10-DistribuicaoNormal.Rmd-->

# Exemplos de distribuiÃ§Ãµes

```{r setupDist, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
```
<center>
<script src="https://unpkg.com/@dotlottie/player-component@2.7.12/dist/dotlottie-player.mjs" type="module"></script>
<dotlottie-player src="https://lottie.host/74a90344-947f-476a-a118-7d9d5c6cd810/z76UXstist.lottie" background="transparent" speed="1" style="width: 300px; height: 300px" loop autoplay></dotlottie-player>
</center>

## DistribuiÃ§Ãµes Discretas

### Binomial

Modela o nÃºmero de sucessos em n tentativas com probabilidade `p`.

```{r binomialDist}
n <- 10
p <- 0.5
x <- 0:n
y <- dbinom(x, size = n, prob = p)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "DistribuiÃ§Ã£o Binomial (n = 10, p = 0.5)", x = "NÃºmero de Sucessos", y = "Probabilidade")
```

### Poisson

Modela o nÃºmero de eventos raros num intervalo fixo.

```{r poissonDist}
lambda <- 3
x <- 0:15
y <- dpois(x, lambda)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "darkorange") +
  labs(title = "DistribuiÃ§Ã£o de Poisson", x = "NÃºmero de Eventos", y = "Probabilidade")
```

### GeomÃ©trica

Modela o nÃºmero de falhas antes do primeiro sucesso.

```{r geometricaDist}
p <- 0.3
x <- 0:10
y <- dgeom(x, prob = p)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_bar(stat = "identity", fill = "purple") +
  labs(title = "DistribuiÃ§Ã£o GeomÃ©trica (p = 0.3)", x = "Tentativas atÃ© o 1Âº Sucesso", y = "Probabilidade")
```

## DistribuiÃ§Ãµes ContÃ­nuas

### Normal

Modela fenÃ´menos naturais e erros de medida.

```{r normal_plot_Dist}
x <- seq(-4, 4, length.out = 100)
y <- dnorm(x)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "darkgreen", linewidth = 1.2) +
  labs(title = "DistribuiÃ§Ã£o Normal (mÃ©dia = 0, sd = 1)", x = "x", y = "Densidade")
```

### Exponencial

Tempo atÃ© um evento ocorrer.

```{r exponencialDist}
lambda <- 1
x <- seq(0, 5, length.out = 100)
y <- dexp(x, rate = lambda)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "firebrick", size = 1.2) +
  labs(title = "DistribuiÃ§Ã£o Exponencial", x = "Tempo", y = "Densidade")
```

### Uniforme ContÃ­nua

Todos os valores tÃªm a mesma chance.

```{r uniformeDist}
x <- seq(0, 1, length.out = 100)
y <- dunif(x, min = 0, max = 1)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "goldenrod", size = 1.2) +
  labs(title = "DistribuiÃ§Ã£o Uniforme ContÃ­nua (0 a 1)", x = "x", y = "Densidade")
```

### t de Student

Usada em testes com amostras pequenas.

```{r studentDist}
x <- seq(-4, 4, length.out = 100)
y <- dt(x, df = 5)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "navy", size = 1.2) +
  labs(title = "DistribuiÃ§Ã£o t de Student (df = 5)", x = "x", y = "Densidade")
```

### Qui-Quadrado (Ï‡Â²)

Usada para testes de aderÃªncia e independÃªncia.

```{r chisqDist}
x <- seq(0, 20, length.out = 100)
y <- dchisq(x, df = 5)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "tomato", size = 1.2) +
  labs(title = "DistribuiÃ§Ã£o Qui-quadrado (df = 5)", x = "x", y = "Densidade")
```

### F de Fisher

Usada em ANOVA para comparar variÃ¢ncias.

```{r fisherDist}
x <- seq(0, 5, length.out = 100)
y <- df(x, df1 = 5, df2 = 10)

ggplot(data.frame(x, y), aes(x, y)) +
  geom_line(color = "darkviolet", size = 1.2) +
  labs(title = "DistribuiÃ§Ã£o F de Fisher (df1 = 5, df2 = 10)", x = "x", y = "Densidade")
```

> Cada distribuiÃ§Ã£o tem uma aplicaÃ§Ã£o especÃ­fica conforme o tipo de variÃ¡vel (discreta ou contÃ­nua), o contexto do problema e as suposiÃ§Ãµes do modelo. Entender suas formas e usos ajuda na escolha correta da anÃ¡lise estatÃ­stica.

<!--chapter:end:11-Distribuicoes-Probabilidade.Rmd-->

# Normal ou NÃ£o?

<center>
<script src="https://unpkg.com/@dotlottie/player-component@2.7.12/dist/dotlottie-player.mjs" type="module"></script>
<dotlottie-player src="https://lottie.host/32368ff6-8150-40df-a981-abe61d0c919f/Uobp2rITzh.lottie" background="transparent" speed="1" style="width: 300px; height: 300px" loop autoplay></dotlottie-player>
</center>

Antes de avanÃ§armos para a aplicaÃ§Ã£o dos testes estatÃ­sticos, Ã© importante avaliarmos se os dados seguem ou nÃ£o uma distribuiÃ§Ã£o normal. Essa verificaÃ§Ã£o inicial Ã© muito importante porque muitos testes paramÃ©tricos, como o teste t e a ANOVA, partem da suposiÃ§Ã£o de normalidade dos dados. Compreender esse aspecto permite escolher os mÃ©todos estatÃ­sticos mais adequados, aumentando a confiabilidade dos resultados e evitando interpretaÃ§Ãµes equivocadas que poderiam comprometer a anÃ¡lise.

Esta seÃ§Ã£o apresenta uma anÃ¡lise visual da normalidade dos dados por meio de grÃ¡ficos QQ (Quantil-Quantil), com a comparaÃ§Ã£o de trÃªs cenÃ¡rios distintos: dados que seguem uma distribuiÃ§Ã£o normal, dados que levantam dÃºvidas quanto Ã  normalidade e dados que claramente nÃ£o seguem essa distribuiÃ§Ã£o.

- Dados normalmente distribuÃ­dos
- Dados que geram dÃºvida quanto Ã  normalidade
- Dados que claramente nÃ£o seguem distribuiÃ§Ã£o normal

## Dados que seguem distribuiÃ§Ã£o normal

```{r enormalDist}
set.seed(10)
dados_normais <- rnorm(500, mean = 0, sd = 1)

hist(dados_normais, main = "Histograma - DistribuiÃ§Ã£o Normal", col = "lightblue")
boxplot(dados_normais, main = "Boxplot - DistribuiÃ§Ã£o Normal")
qqnorm(dados_normais, main = "QQ Plot - DistribuiÃ§Ã£o Normal")
qqline(dados_normais, col = "blue", lwd = 2)
```

*ObservaÃ§Ã£o:* Os pontos seguem de perto a linha, indicando que os dados sÃ£o normalmente distribuÃ­dos.

## Dados que geram dÃºvida

```{r duvidosaDist}
set.seed(20)
dados_mistos <- c(rnorm(250, 0, 1), rnorm(250, 2, 1))

hist(dados_mistos, main = "Histograma - Mistura de Normais", col = "lightgreen")
boxplot(dados_mistos, main = "Boxplot - Mistura de Normais")
qqnorm(dados_mistos, main = "QQ Plot - Mistura de Normais")
qqline(dados_mistos, col = "orange", lwd = 2)
```

*ObservaÃ§Ã£o:* As caudas do grÃ¡fico QQ comeÃ§am a se afastar da linha, o que pode gerar dÃºvida sobre a normalidade.


## Dados que nÃ£o seguem distribuiÃ§Ã£o normal

```{r nnormalDist}
set.seed(30)
dados_chi <- rchisq(500, df = 3)

hist(dados_chi, main = "Histograma - DistribuiÃ§Ã£o Qui-quadrado", col = "lightpink")
boxplot(dados_chi, main = "Boxplot - Qui-quadrado")
qqnorm(dados_chi, main = "QQ Plot - Qui-quadrado")
qqline(dados_chi, col = "red", lwd = 2)
```

*ObservaÃ§Ã£o:* A forte curvatura do grÃ¡fico QQ indica clara violaÃ§Ã£o da normalidade (assimetria Ã  direita).

## Dados com forte concentraÃ§Ã£o de repetiÃ§Ã£o de valor (nÃ£o seguem distribuiÃ§Ã£o normal)

```{r dados_repetidos_dist}
set.seed(42)
dados_repetidos <- c(rep(18, 5), rep(23, 10), rep(26,7)) 

# Histograma
hist(dados_repetidos, main = "Histograma - Dados Repetidos", col = "lightblue", xlab = "Valor", ylab = "FrequÃªncia")

# Boxplot
boxplot(dados_repetidos, main = "Boxplot - Dados Repetidos", col = "lightgreen")

# QQ Plot
qqnorm(dados_repetidos, main = "QQ Plot - Dados Repetidos")
qqline(dados_repetidos, col = "red", lwd = 2)
```

> O grÃ¡fico QQ Ã© uma ferramenta visual poderosa para avaliar se um conjunto de dados segue uma distribuiÃ§Ã£o normal. Em conjunto com histogramas e boxplots, permite identificar desvios, outliers e assimetrias de maneira clara.

<!--chapter:end:12-diagnostico-normalidade.Rmd-->

# EstatÃ­stica Inferencial

A **estatÃ­stica inferencial** Ã© uma Ã¡rea essencial da estatÃ­stica que permite fazer generalizaÃ§Ãµes sobre uma populaÃ§Ã£o com base em dados coletados de uma amostra. Um passo fundamental nesse processo Ã© o **cÃ¡lculo amostral**, que determina o tamanho ideal da amostra para garantir a validade dos resultados, e esse cÃ¡lculo depende diretamente do **tipo de teste estatÃ­stico** que serÃ¡ utilizado, pois diferentes testes exigem diferentes parÃ¢metros, como variabilidade, efeito esperado e poder do teste. 

Ao conduzir uma anÃ¡lise inferencial, formulam-se **hipÃ³teses**: a **hipÃ³tese nula (Hâ‚€)**, que representa a ausÃªncia de efeito ou diferenÃ§a, e a **hipÃ³tese alternativa (Hâ‚)**, que sugere a existÃªncia de um efeito ou diferenÃ§a. Define-se tambÃ©m um **nÃ­vel de significÃ¢ncia (Î±)**, geralmente 0,05 (5%), que representa a probabilidade de rejeitar Hâ‚€ quando ela Ã© verdadeira (**erro tipo I**). O **valor-p**, calculado a partir dos dados, indica a probabilidade de obter um resultado tÃ£o extremo quanto o observado, supondo que Hâ‚€ seja verdadeira. Com base na comparaÃ§Ã£o entre o valor-p e o nÃ­vel de significÃ¢ncia, aplica-se o **critÃ©rio de decisÃ£o**: se o valor-p for menor que Î±, rejeita-se Hâ‚€, o que indica **evidÃªncias estatÃ­sticas suficientes para apoiar a hipÃ³tese alternativa**.


## Etapas de um Teste EstatÃ­stico

Para realizar qualquer **teste estatÃ­stico**, seguimos uma sequÃªncia bÃ¡sica de passos:

1. **Escrevemos as hipÃ³teses do teste**, comeÃ§ando com a **hipÃ³tese nula (Hâ‚€)**, que geralmente afirma que nÃ£o hÃ¡ efeito ou diferenÃ§a, e a **hipÃ³tese alternativa (Hâ‚)**, que propÃµe o contrÃ¡rio.

2. **Definimos o nÃ­vel de significÃ¢ncia (Î±)**, que Ã© a margem de erro aceitÃ¡vel. Esse valor, geralmente 0,05 (ou 5%), jÃ¡ foi considerado no **cÃ¡lculo do tamanho da amostra**, garantindo que os resultados tenham confiabilidade.

3. **Utilizamos um recurso computacional**, como um software estatÃ­stico, para calcular o **valor-p**, que mostra a probabilidade de observarmos os dados coletados caso a hipÃ³tese nula seja verdadeira.

5. **Comparamos o valor-p com o nÃ­vel de significÃ¢ncia**. Se o valor-p for menor que Î±, **rejeitamos a hipÃ³tese nula**. Caso contrÃ¡rio, nÃ£o rejeitamos.

6. Por fim, **chegamos Ã  conclusÃ£o do teste**, que nos diz se hÃ¡ ou nÃ£o **evidÃªncia estatÃ­stica** suficiente para apoiar a hipÃ³tese alternativa.




## Erros Tipo I e Tipo II

Em um **teste estatÃ­stico**, tomamos uma decisÃ£o com base nos dados coletados de uma amostra: **rejeitar** ou **nÃ£o rejeitar a hipÃ³tese nula (Hâ‚€)**. Por isso, Ã© fundamental realizar um **cÃ¡lculo amostral adequado**, selecionar cuidadosamente a **tÃ©cnica de amostragem** e estar atento Ã s possÃ­veis **fontes de vieses**, garantindo que a amostra seja representativa e que os resultados do teste sejam confiÃ¡veis.

Entretanto, essa decisÃ£o envolve **riscos de erro**, que sÃ£o inerentes ao processo justamente porque estamos baseando nossas conclusÃµes em uma amostra e nÃ£o na populaÃ§Ã£o inteira. Esses erros se dividem em dois tipos:

- **Erro Tipo I (Î±) â€“ Falso Positivo**  
  Ocorre quando **rejeitamos Hâ‚€ mesmo ela sendo verdadeira**.  
  Ã‰ como afirmar que existe um efeito quando, na verdade, nÃ£o existe.  
 
  > Exemplo na medicina: concluir que um novo medicamento reduz a pressÃ£o arterial quando ele nÃ£o tem efeito real, o que pode levar Ã  aprovaÃ§Ã£o de um tratamento ineficaz.  
  
  > Exemplo no esporte: afirmar que um programa de treinamento melhora o desempenho dos atletas quando ele nÃ£o traz benefÃ­cio real, gerando investimentos desnecessÃ¡rios.  
  
  > Exemplo na psicologia: dizer que uma terapia cognitivo-comportamental reduz a ansiedade, mesmo sem efeito comprovado, gerando falsas expectativas nos pacientes.  
 
  Essa Ã© a chance de um **falso positivo**, e o **nÃ­vel de significÃ¢ncia Î±** (geralmente 0,05) representa a probabilidade de cometer esse erro.

- **Erro Tipo II (Î²) â€“ Falso Negativo**  
  Ocorre quando **nÃ£o rejeitamos Hâ‚€ mesmo ela sendo falsa**.  
  Ã‰ como deixar passar um efeito real sem detectÃ¡-lo.  
  
  > Exemplo na medicina: nÃ£o identificar que o medicamento Ã© eficaz, rejeitando seu uso quando ele realmente funciona.  
  
  > Exemplo no esporte: nÃ£o perceber a melhora no desempenho causada pelo programa de treinamento, deixando de adotÃ¡-lo e prejudicando os atletas.  
  
  > Exemplo na psicologia: nÃ£o detectar que a terapia Ã© eficaz para reduzir a ansiedade, levando Ã  rejeiÃ§Ã£o de um tratamento que poderia beneficiar os pacientes.  
  
  Isso Ã© um **falso negativo**, e **Î²** Ã© a probabilidade de cometer esse erro.

## Poder do Teste EstatÃ­stico

- O **poder do teste** Ã© a probabilidade de **detectar um efeito real quando ele realmente existe**, ou seja, **rejeitar Hâ‚€ quando Hâ‚€ Ã© falsa**.  
- O poder Ã© calculado como:  
  **Poder = 1 - Î²**

Um teste com **alto poder** (geralmente desejado acima de 80%) tem menos chance de cometer erro tipo II, o que significa maior capacidade de detectar diferenÃ§as reais quando elas existem. O poder depende do **tamanho da amostra**, do **nÃ­vel de significÃ¢ncia**, da **variabilidade dos dados** e da **magnitude do efeito** que se deseja identificar.


## Tabela: Erros, DecisÃµes e Poder do Teste

| SituaÃ§Ã£o Real       | DecisÃ£o: Rejeitar Hâ‚€            | DecisÃ£o: NÃ£o Rejeitar Hâ‚€          |
|:-------------------:|:------------------------------:|:--------------------------------:|
| Hâ‚€ Ã© verdadeira     | Erro Tipo I (*Î±*)    | DecisÃ£o correta                  |
| Hâ‚€ Ã© falsa          | DecisÃ£o correta (*poder*)                | Erro Tipo II (*Î²*)    |


- **Poder do teste:** Probabilidade de rejeitar Hâ‚€ quando Hâ‚€ Ã© falsa (ou seja, evitar o erro tipo II).


## Tamanho do Efeito

### O que Ã© o Tamanho do Efeito?

O **tamanho do efeito** Ã© uma medida que indica **o quanto uma diferenÃ§a ou relaÃ§Ã£o observada nos dados Ã© relevante na prÃ¡tica**. 

Enquanto o **valor-p** nos informa se um resultado Ã© estatisticamente significativo (ou seja, se Ã© improvÃ¡vel que tenha ocorrido por acaso), o tamanho do efeito **complementa essa anÃ¡lise mostrando a magnitude real do efeito observado**.


### Exemplos para Entender Melhor

> Imagine que um novo remÃ©dio reduza a pressÃ£o arterial em mÃ©dia em **1 mmHg** comparado ao tratamento padrÃ£o.  
  Com uma amostra muito grande, essa pequena diferenÃ§a pode ser estatisticamente significativa (*valor-p* < 0,05), mas **clinicamente irrelevante**. O tamanho do efeito, neste caso, mostra que, apesar do resultado ser significativo, **o impacto prÃ¡tico Ã© muito pequeno**.

> Suponha um estudo que compara dois mÃ©todos de treinamento de forÃ§a e encontra uma diferenÃ§a mÃ©dia de **0,5 kg** no aumento de carga mÃ¡xima entre os grupos apÃ³s 8 semanas.  
  Com uma amostra grande, essa diferenÃ§a pode ser estatisticamente significativa, mas **na prÃ¡tica, esse ganho Ã© muito pequeno** para justificar a troca de mÃ©todo. O tamanho do efeito indica que, embora exista diferenÃ§a detectada, **ela tem pouco impacto real no desempenho atlÃ©tico**.

> Considere uma pesquisa que compara nÃ­veis de ansiedade entre terapia online e presencial, com diferenÃ§a mÃ©dia de **1 ponto** (em escala de 0 a 100).  
  Mesmo que essa diferenÃ§a seja estatisticamente significativa, **nÃ£o representa uma mudanÃ§a clinicamente relevante** no estado emocional dos pacientes. O tamanho do efeito ajuda a perceber que a diferenÃ§a entre as modalidades pode ser mÃ­nima na prÃ¡tica.


## Medidas Comuns de Tamanho do Efeito

A escolha da medida depende do tipo de teste e das variÃ¡veis analisadas.

### d de Cohen (teste t)

Usado para comparar mÃ©dias entre dois grupos, mede a diferenÃ§a em unidades de desvio padrÃ£o.

| Valor do d | InterpretaÃ§Ã£o       |
|:------------|:---------------------|
| â‰ˆ 0.2      | Efeito pequeno      |
| â‰ˆ 0.5      | Efeito mÃ©dio        |
| â‰¥ 0.8      | Efeito grande       |

### C de Cramer, para tabela 2x2 (teste qui-quadrado)

Mede a associaÃ§Ã£o entre variÃ¡veis categÃ³ricas (varia de 0 a 1).

| Valor de C | InterpretaÃ§Ã£o       |
|:------------|:---------------------|
| â‰ˆ 0.1      | AssociaÃ§Ã£o fraca    |
| â‰ˆ 0.3      | AssociaÃ§Ã£o moderada |
| â‰¥ 0.5      | AssociaÃ§Ã£o forte    |

### Coeficiente de CorrelaÃ§Ã£o de Pearson (r)

Mede a forÃ§a da relaÃ§Ã£o linear entre duas variÃ¡veis quantitativas.

| Valor de r   | InterpretaÃ§Ã£o          |
|:--------------|:------------------------|
| â‰ˆ 0.1        | CorrelaÃ§Ã£o fraca       |
| â‰ˆ 0.3        | CorrelaÃ§Ã£o moderada    |
| â‰¥ 0.5        | CorrelaÃ§Ã£o forte       |
| 0            | Nenhuma correlaÃ§Ã£o     |
| Â±1           | CorrelaÃ§Ã£o perfeita    |


## Por que o Tamanho do Efeito Ã© Importante?

Um resultado estatisticamente significativo **nem sempre indica relevÃ¢ncia prÃ¡tica**. O tamanho do efeito responde Ã  pergunta: **"Esse resultado faz diferenÃ§a no mundo real?"**

## Testes

Nas prÃ³ximas seÃ§Ãµes, abordaremos os testes de **comparaÃ§Ã£o entre grupos** com base em uma variÃ¡vel quantitativa, os testes de **associaÃ§Ã£o entre variÃ¡veis categÃ³ricas** nominais, e os testes de **correlaÃ§Ã£o**, que podem envolver variÃ¡veis quantitativas ou qualitativas ordinais. Essa abordagem visa facilitar a compreensÃ£o e a interpretaÃ§Ã£o dos resultados estatÃ­sticos em variados contextos, ressaltando sempre a importÃ¢ncia de avaliar a relevÃ¢ncia prÃ¡tica dos achados para uma tomada de decisÃ£o mais informada.


<!--chapter:end:13-EstatÃ­stica-Inferencial.Rmd-->

# Testes de ComparaÃ§Ã£o entre Grupos

Os testes de comparaÃ§Ã£o sÃ£o usados para verificar se existem diferenÃ§as significativas entre grupos em relaÃ§Ã£o a uma variÃ¡vel quantitativa. Essas comparaÃ§Ãµes podem variar conforme a relaÃ§Ã£o entre os grupos, o nÃºmero de grupos e o tipo de dado.

## ComparaÃ§Ãµes Pareadas (Dependentes)

Quando os grupos comparados sÃ£o relacionados ou â€œligadosâ€ de alguma forma, dizemos que a comparaÃ§Ã£o Ã© **pareada** ou entre grupos **dependentes**. Isso acontece, por exemplo, quando medimos a mesma amostra em dois momentos diferentes â€” antes e depois de uma intervenÃ§Ã£o â€” ou quando comparamos pares de indivÃ­duos relacionados, como gÃªmeos.

**Exemplos:**

> Avaliar a pressÃ£o arterial dos pacientes antes e depois de um tratamento.

> Medir a forÃ§a muscular dos atletas antes e apÃ³s um programa de treinamento.

> Aplicar um teste de ansiedade em pacientes antes e depois de uma terapia.

## ComparaÃ§Ãµes NÃ£o-Pareadas (Independentes)

As comparaÃ§Ãµes sÃ£o **nÃ£o-pareadas** ou entre grupos **independentes** quando os grupos nÃ£o tÃªm relaÃ§Ã£o entre si, ou seja, os participantes de um grupo nÃ£o pertencem ao outro. Cada observaÃ§Ã£o Ã© independente das outras.

**Exemplos:**

> Comparar a pressÃ£o arterial entre pacientes que receberam medicamento e pacientes que receberam placebo.

> Comparar a velocidade mÃ©dia de corrida entre dois times diferentes.

> Comparar nÃ­veis de estresse entre grupos que fizeram terapia presencial e terapia online.

## NÃºmero de Grupos na ComparaÃ§Ã£o

A comparaÃ§Ã£o pode ser feita entre **dois grupos** ou **mais de dois grupos**:

- **Dois grupos:** Por exemplo, comparar o desempenho entre dois mÃ©todos de ensino.
- **Mais de dois grupos:** Por exemplo, comparar o efeito de trÃªs diferentes dietas no peso corporal.

## Testes ParamÃ©tricos e NÃ£o ParamÃ©tricos

Para escolher o teste estatÃ­stico adequado, Ã© importante considerar as caracterÃ­sticas dos dados:

- **Testes ParamÃ©tricos:**  
  Utilizados quando os dados seguem certas condiÃ§Ãµes, como distribuiÃ§Ã£o normal e variÃ¢ncia homogÃªnea, permitindo uma anÃ¡lise mais precisa.

- **Testes NÃ£o ParamÃ©tricos:**  
  Indicados quando os dados nÃ£o atendem Ã s condiÃ§Ãµes dos testes paramÃ©tricos, como em distribuiÃ§Ãµes assimÃ©tricas ou dados ordinais, oferecendo uma alternativa robusta para comparaÃ§Ã£o.


```{r setup2diag, include=FALSE}
library(DiagrammeR)
```

# ComparaÃ§Ã£o entre dois grupos

O fluxograma abaixo apresenta a sequÃªncia de etapas para a escolha do teste estatÃ­stico mais adequado na comparaÃ§Ã£o entre dois grupos, considerando o tipo de comparaÃ§Ã£o entre os dois grupos (pareada ou nÃ£o pareada) e a verificaÃ§Ã£o da normalidade dos dados.

```{r fluxograma2gr, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
grViz("
digraph fluxo_teste {
  graph [layout = dot, rankdir = TB, bgcolor = white]

  node [shape = box, style = solid, fontname = 'Arial']
  grupos2      [label = '2 grupos']
  pareados     [label = 'Pareados']
  naopareados  [label = 'NÃ£o Pareados']
  norm_p       [label = 'Normalidade?']
  p_sim        [label = 'Teste t']
  p_nao        [label = 'Teste Wilcoxon']
  norm_np      [label = 'Normalidade?']
  variancia    [label = 'Teste de variÃ¢ncia']
  t_indep      [label = 'Teste t']
  wmw_indep    [label = 'Teste Wilcoxon']

  # CÃ­rculos para Sim/NÃ£o
  sim1         [label = 'Sim', shape = circle, width = 0.2, style = solid]
  nao1         [label = 'NÃ£o', shape = circle, width = 0.2, style = solid]
  sim2         [label = 'Sim', shape = circle, width = 0.2, style = solid]
  nao2         [label = 'NÃ£o', shape = circle, width = 0.2, style = solid]

  grupos2      -> pareados
  grupos2      -> naopareados

  pareados     -> norm_p
  norm_p       -> sim1
  norm_p       -> nao1
  sim1         -> p_sim
  nao1         -> p_nao

  naopareados  -> norm_np
  norm_np      -> sim2
  norm_np      -> nao2
  sim2         -> variancia
  variancia    -> t_indep
  nao2         -> wmw_indep
}
")
```

Exemplos didÃ¡ticos para comparaÃ§Ã£o entre dois grupos sÃ£o mostrados a seguir. 

## Teste t pareado

O teste t (pareado ou nÃ£o pareado) Ã© um teste **paramÃ©trico**, por isso, antes de aplicar o teste, recomenda-se verificar a normalidade dos dados.

O teste t pareado avalia se hÃ¡ diferenÃ§a entre as mÃ©dias de dois conjuntos dependentes (ex: antes e depois em um mesmo grupo).

**HipÃ³teses:**

> Hâ‚€: A mÃ©dia antes Ã© igual Ã  mÃ©dia depois (nÃ£o hÃ¡ efeito).

> Hâ‚: A mÃ©dia antes Ã© diferente da mÃ©dia depois (hÃ¡ efeito).

```{r t-pareadotest, message=FALSE}
# Simulando dados: pressÃ£o antes e depois
set.seed(123)
antes <- rnorm(20, mean=120, sd=10)
depois <- antes + rnorm(20, mean=-5, sd=8) # espera-se uma reduÃ§Ã£o mÃ©dia de 5

# Teste t pareado
t.test(antes, depois, paired = TRUE)
```

No R, fazer o teste t pareado Ã© muito fÃ¡cil. VocÃª sÃ³ precisa usar uma linha: `t.test(antes, depois, paired = TRUE)`.  

Basta colocar os seus dois conjuntos de dados (por exemplo, as medidas antes e depois) e escrever **`paired = TRUE`** para avisar ao R que os dados sÃ£o do mesmo grupo em dois momentos.  

Assim, o R faz todo o cÃ¡lculo para vocÃª!

Ao realizar o teste t pareado no R, a saÃ­da apresenta vÃ¡rias informaÃ§Ãµes importantes:

- **t**: Este Ã© o valor do teste t calculado a partir dos dados. Ele indica o quanto a diferenÃ§a mÃ©dia observada entre os grupos se afasta do que seria esperado se nÃ£o houvesse diferenÃ§a real.
- **df**: Significa "degrees of freedom" (graus de liberdade), que neste caso Ã© igual ao nÃºmero de pares menos 1 (aqui, 19).
- **p-value**: Ã‰ a probabilidade de observarmos uma diferenÃ§a igual ou maior que a encontrada, caso a hipÃ³tese nula (de que nÃ£o hÃ¡ diferenÃ§a) seja verdadeira. Um p-valor pequeno (por exemplo, menor que 0,05) indica que a diferenÃ§a Ã© estatisticamente significativa.
- **alternative hypothesis**: Mostra qual hipÃ³tese alternativa estÃ¡ sendo testada â€“ neste caso, que a diferenÃ§a mÃ©dia entre "antes" e "depois" Ã© diferente de zero.
- **95 percent confidence interval**: Indica o intervalo de valores no qual a verdadeira diferenÃ§a mÃ©dia estÃ¡ com 95% de confianÃ§a. Aqui, podemos dizer que a diferenÃ§a mÃ©dia entre os grupos estÃ¡ provavelmente entre 2,30 e 8,52.
- **mean difference**: Ã‰ a diferenÃ§a mÃ©dia observada nos dados, neste exemplo, aproximadamente 5,41.

**Resumo:**  

O resultado sugere que hÃ¡ uma diferenÃ§a significativa entre "antes" e "depois" (p = 0,0017), com a diferenÃ§a mÃ©dia estimada em 5,41 unidades e um intervalo de confianÃ§a que nÃ£o inclui zero.

> **ObservaÃ§Ã£o**: Se p Ã© maior que 0,05, nÃ£o rejeitamos Hâ‚€, nesse caso a conclusÃ£o seria que nÃ£o hÃ¡ evidÃªncia de diferenÃ§a significativa.


## Wilcoxon pareado

O teste de Wilcoxon para amostras pareadas Ã© a alternativa nÃ£o paramÃ©trica ao teste t pareado, sendo utilizado quando os dados nÃ£o seguem uma distribuiÃ§Ã£o normal.

**HipÃ³teses:**

> Hâ‚€: As distribuiÃ§Ãµes dos pares sÃ£o iguais (nÃ£o hÃ¡ diferenÃ§a entre antes e depois).

> Hâ‚: As distribuiÃ§Ãµes dos pares sÃ£o diferentes (hÃ¡ diferenÃ§a entre antes e depois).

Formalmente, o teste verifica se a **distribuiÃ§Ã£o das diferenÃ§as entre os pares** Ã© simÃ©trica em torno de zero. Quando essa condiÃ§Ã£o de simetria Ã© atendida, podemos interpretar o teste como uma comparaÃ§Ã£o das **medianas** das duas situaÃ§Ãµes (por exemplo, antes e depois).

**HipÃ³teses:**

> Hâ‚€: A mediana das diferenÃ§as entre os pares Ã© igual a zero (nÃ£o hÃ¡ diferenÃ§a entre antes e depois).

> Hâ‚: A mediana das diferenÃ§as entre os pares Ã© diferente de zero (hÃ¡ diferenÃ§a entre antes e depois).

*ObservaÃ§Ã£o: Esta formulaÃ§Ã£o das hipÃ³teses em termos de mediana Ã© vÃ¡lida quando as diferenÃ§as apresentam distribuiÃ§Ã£o simÃ©trica.*

```{r wilcoxon-pareadotest, message=FALSE}
wilcox.test(antes, depois, paired = TRUE)
```

Ao fazer o teste de Wilcoxon pareado no R, a resposta traz as seguintes informaÃ§Ãµes:

- **V**: Ã‰ o valor da estatÃ­stica do teste de Wilcoxon, calculado a partir das diferenÃ§as entre os pares. NÃ£o precisamos interpretar esse nÃºmero diretamente; ele serve para o cÃ¡lculo do p-valor.
- **p-value**: Ã‰ a chance de observarmos uma diferenÃ§a igual ou maior que a encontrada, caso nÃ£o exista diferenÃ§a real entre os grupos. Se o p-valor for menor que 0,05, dizemos que hÃ¡ diferenÃ§a significativa entre "antes" e "depois".
- **alternative hypothesis**: Mostra qual hipÃ³tese alternativa foi testada. Nesse caso, que a posiÃ§Ã£o central (mediana) dos dois momentos nÃ£o Ã© igual.


No R, por padrÃ£o, a funÃ§Ã£o `wilcox.test()` nÃ£o mostra o intervalo de confianÃ§a para a mediana das diferenÃ§as.
No entanto, vocÃª pode pedir para calcular o intervalo de confianÃ§a usando o argumento **`conf.int = TRUE`**:

```{r wilcoxon-pareado-ictest, message=FALSE}
wilcox.test(antes, depois, paired = TRUE, conf.int = TRUE)
```

ObservaÃ§Ãµes sobre o intervalo de confianÃ§a do teste de Wilcoxon

**95 percent confidence interval:**  
  O intervalo de confianÃ§a de 95% vai de 2,29 atÃ© 8,68. Isso significa que, com 95% de confianÃ§a, a verdadeira mediana da diferenÃ§a entre "antes" e "depois" estÃ¡ entre esses valores.  
  Como esse intervalo **nÃ£o inclui o zero**, temos mais uma indicaÃ§Ã£o de que existe diferenÃ§a significativa entre os dois momentos.

**(pseudo)median:**  
  O valor de 5,55 indica a mediana das diferenÃ§as observadas nos dados.  
  Ã‰ chamado de â€œpseudo-medianâ€ porque, no teste de Wilcoxon, esse valor Ã© uma estimativa robusta do deslocamento central entre os pares.
 
  O termo â€œpseudo-medianâ€ aparece no teste de Wilcoxon porque, nesse teste, a maneira de calcular a â€œmedianaâ€ Ã© um pouco diferente da mediana comum.

**Mediana comum:** Ã‰ o valor do meio quando colocamos todos os nÃºmeros em ordem.

**Pseudo-median:** No teste de Wilcoxon, em vez de pegar sÃ³ o valor do meio, o cÃ¡lculo usa todos os pares possÃ­veis de diferenÃ§as entre os grupos. Ele faz uma mÃ©dia especial desses valores do meio. Por isso, chama-se â€œpseudoâ€ (uma â€œfalsaâ€ ou â€œquaseâ€ mediana).

  
## Teste t nÃ£o pareado

Se vocÃª olhar no fluxograma apresentado no inÃ­cio do capÃ­tulo, vocÃª verÃ¡ que antes de executar o teste t para amostras nÃ£o pareadas, Ã© necessÃ¡rio executar o teste de variÃ¢ncia.

### Teste de variÃ¢ncia

**Ã‰ um prÃ©-requisito para o teste t nÃ£o pareado** Verifica se as variÃ¢ncias de dois grupos nÃ£o pareados podem ser consideradas iguais ou nÃ£o. 

**HipÃ³teses:**

> Hâ‚€: As variÃ¢ncias dos dois grupos sÃ£o iguais.

> Hâ‚: As variÃ¢ncias dos dois grupos sÃ£o diferentes.

**InterpretaÃ§Ã£o:**  

Se p < 0,05, rejeitamos Hâ‚€ e concluÃ­mos que as variÃ¢ncias sÃ£o diferentes

> No teste t acrescentado o argumento `var.equal=FALSE` ou `var.equal=F`.

Se p > 0,05, consideramos as variÃ¢ncias iguais.

> No teste t acrescentado o argumento `var.equal=TRUE` ou `var.equal=T`

**Importante:**  

O argumento **`var.equal`** dentro de **`t.test()`** define qual versÃ£o do teste serÃ¡ utilizada: se `var.equal = TRUE`, o teste assume variÃ¢ncias iguais; se `var.equal = FALSE`, Ã© usada a correÃ§Ã£o de Welch, que nÃ£o assume homogeneidade. A escolha incorreta desse parÃ¢metro pode comprometer a validade do p-valor obtido, afetando a conclusÃ£o do teste.

**ExplicaÃ§Ã£o didÃ¡tica**

Imagine que vocÃª quer comparar as mÃ©dias de duas turmas. A Turma A tem poucos alunos e notas parecidas; a Turma B tem muitos alunos, mas as notas variam bastante.

Se vocÃª comparar as mÃ©dias assumindo que ambas tÃªm a mesma variaÃ§Ã£o, o resultado pode ser injusto.

A correÃ§Ã£o de Welch resolve isso: ela ajusta o cÃ¡lculo do teste para considerar que as turmas sÃ£o diferentes â€” olhando para a variaÃ§Ã£o e o tamanho de cada grupo separadamente. Assim, o teste fica mais confiÃ¡vel quando os grupos sÃ£o desiguais.

---

O teste t para amostras nÃ£o pareadas compara mÃ©dias de dois grupos independentes.

**HipÃ³teses:**

> Hâ‚€: A mÃ©dia do grupo A Ã© igual Ã  mÃ©dia do grupo B.

> Hâ‚: As mÃ©dias dos grupos sÃ£o diferentes.

```{r t-independentetest, message=FALSE}
# Simulando dados
set.seed(456)
grupoA <- rnorm(30, mean=50, sd=7)
grupoB <- rnorm(30, mean=55, sd=7)

# Teste de variÃ¢ncia (prÃ©-requisito do t independente)
var.test(grupoA, grupoB)

# Teste t independente
t.test(grupoA, grupoB, var.equal = TRUE)
```

**DescriÃ§Ã£o dos resultados do teste F para comparaÃ§Ã£o de variÃ¢ncias**

- **F = 1.8842**: Este Ã© o valor da estatÃ­stica F, que compara as duas variÃ¢ncias. Ele Ã© calculado dividindo a variÃ¢ncia do grupo com maior variÃ¢ncia pela variÃ¢ncia do outro grupo.
- **num df = 29, denom df = 29**: Esses sÃ£o os graus de liberdade, relacionados ao tamanho de cada grupo (n - 1), neste caso ambos com 30 participantes.
- **p-value = 0.09347**: Este Ã© o valor de significÃ¢ncia. Ele mostra a probabilidade de observarmos uma diferenÃ§a entre as variÃ¢ncias tÃ£o grande quanto a encontrada, caso as variÃ¢ncias dos grupos fossem realmente iguais. Como o p-valor Ã© maior que 0,05, nÃ£o podemos dizer que as variÃ¢ncias sÃ£o diferentes de forma significativa.
- **alternative hypothesis: true ratio of variances is not equal to 1**: Isso mostra que o teste estÃ¡ verificando se as variÃ¢ncias sÃ£o diferentes (nÃ£o iguais).
- **95 percent confidence interval: 0.896797 a 3.958627**: Com 95% de confianÃ§a, o verdadeiro valor da razÃ£o entre as variÃ¢ncias estÃ¡ entre aproximadamente 0,90 e 3,96. Como esse intervalo inclui o valor 1, nÃ£o hÃ¡ diferenÃ§a significativa entre as variÃ¢ncias.
- **ratio of variances = 1.884167**: Esse Ã© o valor observado da razÃ£o entre as variÃ¢ncias dos dois grupos. O grupo com maior variÃ¢ncia tem uma variÃ¢ncia cerca de 1,88 vezes maior que o outro grupo.

**Resumo:**  
O teste F mostrou que nÃ£o hÃ¡ diferenÃ§a estatisticamente significativa entre as variÃ¢ncias dos grupos A e B, pois o p-valor Ã© maior que 0,05 e o intervalo de confianÃ§a inclui o valor 1.


**DescriÃ§Ã£o dos resultados do teste t para duas amostras nÃ£o pareadas**

- **t = -2.4453**: Este Ã© o valor da estatÃ­stica t, que indica o quanto as mÃ©dias dos grupos A e B diferem em relaÃ§Ã£o Ã  variaÃ§Ã£o dos dados.
- **df = 58**: SÃ£o os graus de liberdade do teste, relacionados ao tamanho das amostras.
- **p-value = 0.01753**: O p-valor representa a probabilidade de encontrar uma diferenÃ§a igual ou maior que a observada entre as mÃ©dias, caso realmente nÃ£o haja diferenÃ§a entre os grupos. Como o p-valor Ã© menor que 0,05, podemos considerar que hÃ¡ diferenÃ§a estatisticamente significativa entre as mÃ©dias de grupoA e grupoB.
- **alternative hypothesis: true difference in means is not equal to 0**: O teste verifica se existe diferenÃ§a entre as mÃ©dias dos dois grupos (hipÃ³tese alternativa de diferenÃ§a).
- **95 percent confidence interval: -8.13 a -0.81**: Com 95% de confianÃ§a, a diferenÃ§a real entre as mÃ©dias estÃ¡ entre -8,13 e -0,81. Como esse intervalo nÃ£o inclui o zero, reforÃ§a a indicaÃ§Ã£o de diferenÃ§a significativa.
- **mean of x (grupoA): 51.62**  
  **mean of y (grupoB): 56.09**  
  As mÃ©dias dos grupos mostram que o grupo B teve, em mÃ©dia, um valor maior que o grupo A.

**Resumo:**  
O teste t indicou que existe uma diferenÃ§a estatisticamente significativa entre as mÃ©dias dos grupos A e B. O grupo B apresentou mÃ©dia maior que o grupo A, e essa diferenÃ§a dificilmente ocorreu ao acaso.


## Wilcoxon nÃ£o pareado

O teste Ã© tambÃ©m conhecido como Wilcoxon-Mann-Whitney. Ã‰ a alternativa nÃ£o paramÃ©trica ao t independente para comparar dois grupos independentes.

**HipÃ³teses:**

> Hâ‚€: As distribuiÃ§Ãµes dos grupos sÃ£o iguais.

> Hâ‚: As distribuiÃ§Ãµes dos grupos sÃ£o diferentes.

```{r mann-whitneytest, message=FALSE}
wilcox.test(grupoA, grupoB)
```

**DescriÃ§Ã£o dos resultados do teste de Wilcoxon para duas amostras nÃ£o pareadas**

- **W = 316**: Este Ã© o valor da estatÃ­stica de Wilcoxon, que representa a soma dos postos atribuÃ­dos aos valores dos grupos ao comparar suas distribuiÃ§Ãµes.
- **p-value = 0.04789**: O valor de p indica a probabilidade de observar uma diferenÃ§a igual ou maior entre os grupos, caso nÃ£o exista diferenÃ§a real. Como Ã© menor que 0,05, isso sugere que hÃ¡ diferenÃ§a estatisticamente significativa entre os grupos A e B.
- **alternative hypothesis: true location shift is not equal to 0**: O teste estÃ¡ avaliando se hÃ¡ diferenÃ§a (deslocamento) entre as localizaÃ§Ãµes centrais dos dois grupos (medianas diferentes).

**Resumo:**  
O teste de Wilcoxon mostrou que hÃ¡ uma diferenÃ§a estatisticamente significativa nas distribuiÃ§Ãµes dos grupos A e B, indicando que eles provavelmente apresentam medianas diferentes.


## Teste bilateral vs. teste unilateral

### O que sÃ£o?

- **Teste bilateral (bicaudal ou two-sided):**
  - Verifica se hÃ¡ diferenÃ§a **em qualquer direÃ§Ã£o** entre os grupos ou condiÃ§Ãµes.
  - Exemplo: "SerÃ¡ que a mÃ©dia do grupo A Ã© **diferente** da mÃ©dia do grupo B?" (pode ser maior ou menor).

- **Teste unilateral (caudal ou one-sided):**
  - Verifica se hÃ¡ diferenÃ§a **em uma direÃ§Ã£o especÃ­fica**.
  - Exemplo: "SerÃ¡ que a mÃ©dia do grupo A Ã© **maior** que a mÃ©dia do grupo B?" ou "SerÃ¡ que Ã© **menor**?".

---

### FormulaÃ§Ã£o das hipÃ³teses

- **Teste bilateral:**
  - HipÃ³tese nula (\(H_0\)): nÃ£o hÃ¡ diferenÃ§a (\(\mu_A = \mu_B\))
  - HipÃ³tese alternativa (\(H_1\)): hÃ¡ diferenÃ§a (\(\mu_A \neq \mu_B\))

- **Teste unilateral (maior):**
  - HipÃ³tese nula (\(H_0\)): \(\mu_A \leq \mu_B\)
  - HipÃ³tese alternativa (\(H_1\)): \(\mu_A > \mu_B\)

- **Teste unilateral (menor):**
  - HipÃ³tese nula (\(H_0\)): \(\mu_A \geq \mu_B\)
  - HipÃ³tese alternativa (\(H_1\)): \(\mu_A < \mu_B\)

---

### InfluÃªncia no cÃ¡lculo do p-valor

- **Teste bilateral:**  
  O p-valor representa a probabilidade de encontrar um resultado tÃ£o extremo quanto o observado **em ambas as direÃ§Ãµes** (para mais ou para menos).  
  Ã‰ mais rigoroso, pois considera desvios para cima e para baixo.

- **Teste unilateral:**  
  O p-valor considera apenas **uma direÃ§Ã£o** (maior ou menor).  
  Geralmente, o p-valor do teste unilateral Ã© a metade do bilateral, para o mesmo dado e direÃ§Ã£o, tornando o teste **mais sensÃ­vel** a detectar diferenÃ§as naquela direÃ§Ã£o, mas exige justificativa teÃ³rica para ser usado.

---

### O que muda nas funÃ§Ãµes `t.test()` e `wilcox.test()`

Nas duas funÃ§Ãµes, vocÃª controla o tipo de teste pelo argumento `alternative`:

- **Teste bilateral (padrÃ£o):**
  - `alternative = "two.sided"`

- **Teste unilateral (maior):**
  - `alternative = "greater"`

- **Teste unilateral (menor):**
  - `alternative = "less"`

**Exemplo:**
```r
# Teste t bilateral (padrÃ£o)
t.test(x, y, alternative = "two.sided")

# Teste t unilateral (x maior que y)
t.test(x, y, alternative = "greater")

# Teste de Wilcoxon unilateral (x menor que y)
wilcox.test(x, y, alternative = "less")
```

Ou seja:
- **O argumento `alternative` define se o teste Ã© bilateral ou unilateral.**
- Isso altera a formulaÃ§Ã£o das hipÃ³teses, o cÃ¡lculo do p-valor e a interpretaÃ§Ã£o do resultado.


## ExercÃ­cio 1 

**ComparaÃ§Ã£o da velocidade dos PokÃ©mons verdes e amarelos**

1. **Baixe o banco de dados**  
   Use o banco de dados: [Pokemon.csv](https://drive.google.com/drive/folders/1gyORbBEuKBstfSKULA58TLhawOXaY-st)  
   Importe o arquivo **Pokemon.csv** para o RStudio.


2. **Pergunta do exercÃ­cio**  
   Teste se existe diferenÃ§a significativa entre a velocidade (**speed**) dos PokÃ©mons verdes (**green**) e amarelos (**yellow**).


3. **FormulaÃ§Ã£o das hipÃ³teses de acordo com os testes**
   
   > HipÃ³tese nula (\(H_0\)): 
  
   > HipÃ³tese alternativa (\(H_1\)): 


4. **NÃ­vel de significÃ¢ncia**  
   Considere \(\alpha = 0,05\).
   
   
5. **Passos para executar o teste adequado**
   
   a) Separe os dados dos PokÃ©mons de cor verde e de cor amarela.  
   b) Verifique a normalidade dos dados de velocidade de cada grupo (grÃ¡fico QQ).  
   c) Escolha o teste mais apropriado:
      - Se as duas amostras seguirem distibuiÃ§Ã£o Normal â†’ teste de variÃ¢ncia â†’ teste t
      - Se uma das amostras nÃ£o seguir distibuiÃ§Ã£o Normal â†’ teste de Wilcoxon
   d) Execute o teste, compare o p-valor com \(\alpha\) e conclua
   
   
6. **ConclusÃ£o**  
   - Se \(p\)-valor < 0,05: rejeite a hipÃ³tese nula e conclua que hÃ¡ diferenÃ§a significativa nas velocidades.
   - Se \(p\)-valor â‰¥ 0,05: nÃ£o rejeite a hipÃ³tese nula e conclua que nÃ£o hÃ¡ diferenÃ§a significativa nas velocidades.

**Resposta** [Posit.cloud](https://posit.cloud/content/10470490)

## ExercÃ­cio 2 

Considere a tabela de resultados publicados no artigo [Resposta da PressÃ£o Arterial ao EsforÃ§o em Adolescentes: InfluÃªncia do Sobrepeso e Obesidade](https://www.google.com/search?q=teste+t+medicina+artigo+&sca_esv=e5b91424496cf486&ei=2bREaLDDNsnX5OUPnpW78Ac&ved=0ahUKEwjwk8eEpuCNAxXJK7kGHZ7KDn4Q4dUDCBA&uact=5&oq=teste+t+medicina+artigo+&gs_lp=Egxnd3Mtd2l6LXNlcnAiGHRlc3RlIHQgbWVkaWNpbmEgYXJ0aWdvIDIHECEYoAEYCjIHECEYoAEYCjIFECEYnwVIlhdQrQlY4BVwAngBkAEAmAG6AaABrwmqAQMwLji4AQPIAQD4AQGYAgqgAt8JwgIKEAAYsAMY1gQYR8ICBRAhGKABwgIIEAAYCBgNGB7CAgUQABjvBcICCBAAGIAEGKIEmAMAiAYBkAYIkgcDMi44oAflIrIHAzAuOLgH1gnCBwUwLjcuM8gHHA&sclient=gws-wiz-serp#:~:text=Resposta%20da%20Press%C3%A3o,br%20%E2%80%BA%20abc):

| Grupo                  | GSO Meninas (n = 24) | GE Meninas (n = 24) | p        |
|------------------------|:--------------------:|:-------------------:|:--------:|
| **Idade** (anos)       | 12,1 Â± 1,3           | 12,0 Â± 1,5          | 0,86     |
| **Peso** (kg)          | 59,3 Â± 12,9          | 38,8 Â± 9,3**         | <0,0001  |
| **Estatura** (m)       | 1,53 Â± 0,09          | 1,46 Â± 0,10*         | 0,02     |
| **IMC** (kg/mÂ²)        | 25,2 Â± 3,8           | 17,9 Â± 2,3**         | <0,0001  |
| **RT/S** (mm)          | 0,85 Â± 0,19          | 1,43 Â± 0,40**        | <0,0001  |
| **PAS repouso** (mmHg) | 114 Â± 12             | 108 Â± 10             | 0,07     |
| **PAD repouso** (mmHg) | 66 Â± 6               | 67 Â± 8               | 0,51     |
| **PAM repouso** (mmHg) | 82 Â± 7               | 81 Â± 8               | 0,67     |
| **FC** (bpm)           | 84 Â± 10              | 87 Â± 9               | 0,34     |

*Teste t-Student para amostras independentes; *p â‰¤ 0,05; **p â‰¤ 0,01.  
DiferenÃ§as entre mÃ©dias do grupo de sobrepeso e obesos vs eutrÃ³ficos.

IMC - Ã­ndice de massa corporal (peso/estaturaÂ²); 

RT/S - relaÃ§Ã£o trÃ­ceps/subescapular;  

PAS - pressÃ£o arterial sistÃ³lica; 

PAD - pressÃ£o arterial diastÃ³lica; 

PAM - pressÃ£o arterial mÃ©dia; 

FC - frequÃªncia cardÃ­aca mÃ©dia.*


**Contexto:**  
A tabela acima apresenta caracterÃ­sticas antropomÃ©tricas e hemodinÃ¢micas de meninas do grupo de sobrepeso/obesidade (GSO) e do grupo eutrÃ³fico (GE). Os autores utilizaram o teste t de Student para amostras independentes.

**Pergunta:**  
Escolha uma variÃ¡vel da tabela e formule as hipÃ³teses nula e alternativa para a comparaÃ§Ã£o entre os grupos GSO e GE. Depois, descreva a conclusÃ£o dos autores com base no valor de p apresentado na tabela.

---

**Exemplo de resposta:**

**VariÃ¡vel escolhida:** Peso (kg)

**HipÃ³teses:**

- HipÃ³tese nula (Hâ‚€):  
  As mÃ©dias de peso (kg) dos grupos GSO e GE sÃ£o iguais.  

- HipÃ³tese alternativa (Hâ‚):  
  As mÃ©dias de peso (kg) dos grupos GSO e GE sÃ£o diferentes.  

**NÃ­vel de significÃ¢ncia:** Î± = 0,05

**Valor de p na tabela:** p < 0,0001

**ConclusÃ£o:**  
Como o valor de p Ã© menor que 0,05, rejeita-se a hipÃ³tese nula. Portanto, os autores concluem que existe diferenÃ§a estatisticamente significativa entre as mÃ©dias de peso dos grupos GSO e GE, sendo o peso significativamente maior no grupo GSO.

**VocÃª pensou nisso?** 
O peso Ã© a variÃ¡vel intrÃ­nseca Ã  comparaÃ§Ã£o, pois define os grupos.

---

## ExercÃ­cio 3 

O artigo [Sintomas de estresse prÃ©-competitivo em atletas adolescentes de handebol](https://www.scielo.br/j/rbce/a/WkdgtTdkykSVHJ9rGYGh7Lx/?format=pdf&lang=pt) utilizou como instrumento a Lista de Sintomas de Estresse PrÃ©-competitivo Infanto-juvenil (LSSPCI), uma escala do tipo Likert (De Rose Jr., 1998). A LSSPCI contÃ©m 31 sintomas, para os quais cada atleta responde em uma escala de 1 (nunca) a 5 (sempre) sobre a frequÃªncia com que cada situaÃ§Ã£o ocorreu nas 24 horas anteriores Ã  competiÃ§Ã£o. Os escores dos sintomas sÃ£o somados para cada atleta, resultando em um escore total de estresse. Analise os resultados da Tabela 1 do artigo:  

**Tabela 1. MÃ©dias, desvios-padrÃ£o, valores p da diferenÃ§a de mÃ©dias e mediana dos sintomas de estresse medidos pela LSSPCI em atletas adolescentes de handebol, segundo o sexo (n = 97)** 

| Sintomas de estresse â€“ LSSPCI                         | Meninos  | Meninas  | Valor páµƒ |
|------------------------------------------------------|:----------------------------:|:----------------------------:|:--------:|
| Meu coraÃ§Ã£o bate mais rÃ¡pido que o normal            | 2,2 Â± 1,0 (2,0)              | 2,5 Â± 0,9 (2,5)              | 0,1      |
| Suo bastante                                         | 2,5 Â± 1,2 (2,0)              | 2,4 Â± 1,3 (2,0)              | 0,4      |
| Fico agitado (a)                                     | 3,0 Â± 0,9 (3,0)              | 3,2 Â± 1,3 (3,0)              | 0,5      |
| Fico preocupado (a) com crÃ­ticas das pessoas         | 2,9 Â± 1,5 (3,0)              | 2,6 Â± 1,4 (2,0)              | 0,2      |
| Sinto muita vontade de fazer xixi                    | 2,0 Â± 1,3 (1,0)              | 2,0 Â± 1,2 (2,0)              | 0,7      |
| Fico preocupado (a) com meus adversÃ¡rios             | 2,7 Â± 1,2 (3,0)              | 2,9 Â± 1,4 (3,0)              | 0,5      |
| Bebo muita Ã¡gua                                      | 2,5 Â± 1,2 (3,0)              | 2,9 Â± 1,5 (3,0)              | 0,3      |
| Roo (como) as unhas                                 | 2,5 Â± 1,9 (2,0)              | 2,1 Â± 1,5 (1,0)              | 0,2      |
| Fico empolgado (a)                                   | 3,5 Â± 1,3 (4,0)              | 3,6 Â± 1,5 (4,0)              | 0,6      |
| Fico aflito (a)                                      | 2,3 Â± 1,7 (2,0)              | 2,8 Â± 1,3 (3,0)              | 0,1      |
| Tenho medo de competir mal                           | 2,6 Â± 1,4 (3,0)              | 2,9 Â± 1,4 (3,0)              | 0,4      |
| Demoro muito para dormir                             | 2,8 Â± 2,4 (3,0)              | 2,3 Â± 2,0 (2,0)              | 0,05     |
| Tenho dÃºvidas sobre minha capacidade de competir     | 2,4 Â± 1,8 (2,0)              | 2,4 Â± 1,2 (2,0)              | 0,7      |
| Sonho com a competiÃ§Ã£o                             |  2,4 Â± 1,2 (2,0)          | 1,9 Â± 1,3 (1,0)        | 0,04 |
| Fico nervoso (a)                                     | 3,1 Â± 1,6 (3,0)              | 3,3 Â± 1,2 (3,0)              | 0,6      |
| Fico preocupado (a) com o resultado da competiÃ§Ã£o    | 3,1 Â± 1,4 (3,0)              | 3,7 Â± 1,4 (4,0)              | 0,1      |
| Minha boca fica seca                                 | 2,4 Â± 1,3 (2,0)              | 2,3 Â± 1,4 (2,0)              | 0,6      |
| Sinto muito cansaÃ§o no fim do treino                 | 2,6 Â± 1,3 (2,0)              | 2,7 Â± 1,3 (2,0)              | 0,9      |
| A presenÃ§a de meus pais na competiÃ§Ã£o me preocupa    | 3,1 Â± 1,7 (2,0)              | 2,6 Â± 1,6 (2,0)              | 0,1      |
| Falo muito sobre a competiÃ§Ã£o                        | 3,0 Â± 1,5 (3,0)              | 3,2 Â± 1,3 (3,0)              | 0,6      |
| Tenho medo de perder                                 | 2,9 Â± 1,4 (3,0)              | 3,1 Â± 1,4 (3,0)              | 0,4      |
| Fico impaciente                                      | 2,4 Â± 1,1 (2,0)              | 2,6 Â± 1,3 (2,5)              | 0,5      |
| NÃ£o penso em outra coisa a nÃ£o ser na competiÃ§Ã£o     | 2,2 Â± 1,2 (2,0)              | 2,7 Â± 1,4 (2,0)              | 0,2      |
| NÃ£o vejo a hora de competir                          | 3,2 Â± 1,4 (3,0)              | 3,3 Â± 1,4 (3,0)              | 0,7      |
| Fico emocionado (a)                                  | 1,8 Â± 1,3 (1,0)              | 2,3 Â± 1,3 (2,0)              | 0,1      |
| Fico ansioso (a)                                     | 3,6 Â± 1,2 (3,0)              | 3,4 Â± 1,5 (4,0)              | 0,7      |
| No dia da competiÃ§Ã£o acordo mais cedo do que o normal| 3,1 Â± 1,7 (3,0)              | 3,0 Â± 1,6 (3,0)              | 0,8      |
| Tenho medo de decepcionar as pessoas                 | 2,7 Â± 1,4 (3,0)              | 3,0 Â± 1,5 (3,0)              | 0,3      |
| Sinto-me mais responsÃ¡vel                            | 3,1 Â± 1,3 (3,0)              | 2,7 Â± 1,3 (3,0)              | 0,2      |
| Sinto que as pessoas exigem muito de mim             | 2,5 Â± 1,4 (2,0)              | 2,4 Â± 1,4 (2,0)              | 0,8      |
| Tenho medo de cometer erros na competiÃ§Ã£o            | 3,4 Â± 1,4 (3,0)              | 3,6 Â± 1,3 (4,0)              | 0,4      |

MÃ©dia Â± DP (mediana); áµƒ Teste de Wilcoxon nÃ£o pareado; p < 0,05.

**Com base na Tabela 1, qual sintoma de estresse apresentou diferenÃ§a estatisticamente significativa entre meninos e meninas segundo o teste de Wilcoxon? Explique como interpretar esse resultado considerando o contexto da escala LSSPCI.**

## ExercÃ­cio 4

O artigo [Qualidade de vida de estudantes de Psicologia](https://pepsic.bvsalud.org/pdf/psicoinfo/v16n16/v16n16a07.pdf) avaliou a qualidade de vida de acadÃªmicos de psicologia e correlacionou-a com fatores sociodemogrÃ¡ficos. Participaram 310 alunos de psicologia que responderam a um questionÃ¡rio sociodemogrÃ¡fico e ao The Medical Outcomes Study 36-item Short-Form Health Survey (SF-36) para avaliar a qualidade de vida. Veja os resultados do teste t na Tabela 2: 

**Tabela 2: ComparaÃ§Ã£o entre gÃªneros nas dimensÃµes de qualidade de vida**

| DimensÃµes             | VariÃ¡vel   | MÃ©dia   | DP     | t    | p-valor |
|-----------------------|:------------:|:---------:|:---------:|:------:|:---------:|
| Capacidade funcional  | Masculino  | 89,74   | 14,49   | 2,44 | 0,119   |
|                       | Feminino   | 86,95   | 11,6    |      |         |
| Aspectos fÃ­sicos      | Masculino  | 79,74   | 25,84   | 0,76 | 0,383   |
|                       | Feminino   | 75,82   | 31,84   |      |         |
| Dor                   | Masculino  | 74,93   | 22,05   | 4,33 | 0,038   |
|                       | Feminino   | 68,26   | 22,00   |      |         |
| Estado geral de saÃºde | Masculino  | 75,21   | 20,36   | 1,15 | 0,284   |
|                       | Feminino   | 72,32   | 17,67   |      |         |
| Vitalidade            | Masculino  | 61,38   | 22,47   | 1,50 | 0,222   |
|                       | Feminino   | 57,92   | 18,57   |      |         |
| Aspectos sociais      | Masculino  | 71,34   | 27,61   | 0,06 | 0,804   |
|                       | Feminino   | 70,43   | 24,31   |      |         |
| Aspecto emocional     | Masculino  | 63,16   | 40,67   | 0,38 | 0,536   |
|                       | Feminino   | 59,51   | 39,85   |      |         |
| SaÃºde mental          | Masculino  | 70,55   | 19,97   | 3,05 | 0,082   |
|                       | Feminino   | 65,7    | 18,80   |      |         |

**Com base na Tabela 2, em qual dimensÃ£o da qualidade de vida foi observada diferenÃ§a estatisticamente significativa entre estudantes do sexo masculino e feminino? O que esse resultado sugere sobre a experiÃªncia dos alunos nesses grupos?**

<!--chapter:end:14-Testes-Comparacao.Rmd-->

# CÃ¡lculo amostral no R

O cÃ¡lculo do tamanho da amostra Ã© fundamental para garantir a validade estatÃ­stica de um estudo. No R, esse cÃ¡lculo pode ser realizado de forma prÃ¡tica utilizando diversos pacotes.

## Principais Pacotes para CÃ¡lculo Amostral

- **pwr**: Utilizado para anÃ¡lise de poder estatÃ­stico e cÃ¡lculo do tamanho da amostra para diferentes testes (t-test, ANOVA, correlaÃ§Ã£o, etc.).
- **epiDisplay**: Oferece funÃ§Ãµes para cÃ¡lculos amostrais em estudos epidemiolÃ³gicos.
- **epiR**: Bastante utilizado em epidemiologia, com funÃ§Ãµes para diferentes desenhos de estudo.
- **samplesize**: Possui mÃ©todos para cÃ¡lculo de tamanho amostral em diferentes contextos.

## Exemplo de cÃ¡lculo amostral para teste t

```r
# Instale o pacote se necessÃ¡rio
# install.packages("pwr")
library(pwr)

# CÃ¡lculo do tamanho da amostra para detectar um efeito de tamanho mÃ©dio (d = 0.5)
# com poder de 80% e nÃ­vel de significÃ¢ncia de 5%
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```
O uso de funÃ§Ãµes e pacotes especÃ­ficos no R torna o cÃ¡lculo amostral mais acessÃ­vel, permitindo maior precisÃ£o no planejamento de estudos. Sempre leve em conta os parÃ¢metros do seu estudo, como efeito esperado, variÃ¢ncia, poder e nÃ­vel de significÃ¢ncia.


No exemplo os seguintes parÃ¢metros foram utilizados:

- **d = 0.5**  
  *Tamanho do efeito (Effect size)*: Representa a magnitude da diferenÃ§a que se espera detectar entre as mÃ©dias dos grupos, em unidades de desvio padrÃ£o. Quanto maior o efeito, mais fÃ¡cil Ã© detectÃ¡-lo com uma amostra menor.  
  - O tamanho do efeito pode ser estimado a partir de dados prÃ©vios, estudos semelhantes ou com base em uma suposiÃ§Ã£o informada.  
  - Categorias comuns: pequeno (~0,2), mÃ©dio (~0,5) e grande (~0,8).

- **power = 0.8**  
  *Poder estatÃ­stico (Power)*: Ã‰ a probabilidade de detectar uma diferenÃ§a real quando ela de fato existe (ou seja, de rejeitar corretamente a hipÃ³tese nula se ela for falsa).  
  - Poder = 1 - Î², onde Î² Ã© a probabilidade de erro tipo II (falso negativo).  
  - O valor padrÃ£o mais utilizado Ã© 0,80 (ou 80%).

- **sig.level = 0.05**  
  *NÃ­vel de significÃ¢ncia (Î±)*: Ã‰ a probabilidade de rejeitar a hipÃ³tese nula quando ela Ã© verdadeira (erro tipo I, falso positivo).  
  - O valor padrÃ£o Ã© 0,05 (ou 5%), indicando que aceitamos atÃ© 5% de chance de um falso positivo.

- **type = "two.sample"**  
  Indica que estamos comparando dois grupos independentes (teste t para duas amostras).

**InterpretaÃ§Ã£o dos Resultados**

Ao rodar o comando acima, o R retorna o tamanho mÃ­nimo de amostra necessÃ¡rio **em cada grupo** para que seja possÃ­vel detectar uma diferenÃ§a de tamanho de efeito `d = 0.5` com 80% de poder e 5% de nÃ­vel de significÃ¢ncia, usando um teste t para duas amostras.

Por exemplo, o resultado pode ser algo assim:

```
     Two-sample t test power calculation 

              n = 63.76561
              d = 0.5
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group
```

**ExplicaÃ§Ã£o:**

- *n â‰ˆ 64*: VocÃª precisaria de pelo menos **64 participantes em cada grupo** para ter 80% de chance de detectar uma diferenÃ§a de tamanho mÃ©dio (0,5 desvios padrÃ£o) entre os grupos, com risco de 5% de um falso positivo.

**ConsideraÃ§Ãµes**

- O tamanho da amostra depende diretamente do tamanho do efeito esperado, do poder estatÃ­stico desejado e do nÃ­vel de significÃ¢ncia escolhido.
- Quanto maior o efeito esperado, menor precisa ser a amostra.
- Quanto maior o poder ou menor o nÃ­vel de significÃ¢ncia, maior serÃ¡ o tamanho da amostra necessÃ¡ria.
- Use dados prÃ©vios, literatura ou cÃ¡lculos exploratÃ³rios para definir o tamanho do efeito.

## O que Ã© o d de Cohen?

O d de Cohen Ã© uma **medida padronizada** do tamanho do efeito para comparar a diferenÃ§a entre duas mÃ©dias, levando em conta a variabilidade dos dados. Ele Ã© muito utilizado para quantificar o quÃ£o grande Ã© a diferenÃ§a entre dois grupos em termos de desvios padrÃ£o.

---

### FÃ³rmula Geral para Dados NÃ£o Pareados (Amostras Independentes)

\[
d = \frac{\bar{X}_1 - \bar{X}_2}{s_p}
\]

Onde:

- \(\bar{X}_1\) = mÃ©dia do grupo 1  
- \(\bar{X}_2\) = mÃ©dia do grupo 2  
- \(s_p\) = desvio padrÃ£o combinado (pooled) dos dois grupos

**Como calcular o desvio padrÃ£o combinado**

\[
s_p = \sqrt{ \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2} }
\]

Onde:

- \(n_1\), \(n_2\) = tamanhos das amostras dos grupos 1 e 2  
- \(s_1\), \(s_2\) = desvios padrÃ£o dos grupos 1 e 2

#### Exemplo prÃ¡tico em R

Suponha:

- Grupo 1: mÃ©dia = 10, desvio padrÃ£o = 2, n = 30  
- Grupo 2: mÃ©dia = 8, desvio padrÃ£o = 2.5, n = 35

```{r d-cohencal, message=FALSE}
media1 <- 10
media2 <- 8
sd1 <- 2
sd2 <- 2.5
n1 <- 30
n2 <- 35

# Desvio padrÃ£o combinado
sp <- sqrt( ((n1-1)*sd1^2 + (n2-1)*sd2^2) / (n1 + n2 - 2) )

# d de Cohen para dados nÃ£o pareados
d_np <- (media1 - media2) / sp
d_np
```


### FÃ³rmula para Dados Pareados (Amostras Dependentes)

Quando os dados sÃ£o pareados (por exemplo, antes e depois para o mesmo grupo de indivÃ­duos), o cÃ¡lculo do d de Cohen Ã© diferente:

\[
d = \frac{\bar{d}}{s_d}
\]

Onde:

- \(\bar{d}\) = mÃ©dia das diferenÃ§as entre os pares  
- \(s_d\) = desvio padrÃ£o das diferenÃ§as

#### Exemplo prÃ¡tico em R

Suponha que temos as diferenÃ§as entre as mediÃ§Ãµes de 5 sujeitos: -0,5; 0; 0,6; 1,2 e 1,7.

```{r d-cohenpareado, message=FALSE}
diferencas <- c(-0.5, 0.0, 0.6, 1.2, 1.7)

media_dif <- mean(diferencas)
sd_dif <- sd(diferencas)

# d de Cohen para dados pareados
d_p <- media_dif / sd_dif
d_p
```

**Valores tÃ­picos para d de Cohen:**

- **0.2**: efeito pequeno  
- **0.5**: efeito mÃ©dio  
- **0.8**: efeito grande  

Assim, quanto maior o valor de d, maior a diferenÃ§a entre os grupos em relaÃ§Ã£o Ã  variabilidade dos dados.


Pense no **d de Cohen** como uma rÃ©gua que compara a diferenÃ§a entre as mÃ©dias de dois grupos, levando em conta o quanto os dados variam dentro desses grupos.

- Se d Ã© pequeno, significa que a diferenÃ§a entre as mÃ©dias dos grupos Ã© pequena em relaÃ§Ã£o Ã  â€œbagunÃ§aâ€ (variaÃ§Ã£o) dos dados â€“ ou seja, os grupos sÃ£o parecidos.
- Se d Ã© grande, significa que a diferenÃ§a entre as mÃ©dias Ã© grande em comparaÃ§Ã£o com a variaÃ§Ã£o dos dados â€“ ou seja, os grupos sÃ£o bem diferentes.

Um valor alto de d indica que os grupos sÃ£o realmente diferentes entre si, enquanto um valor baixo mostra que eles sÃ£o muito parecidos, considerando o quanto os dados â€œdispersamâ€ dentro de cada grupo.

## Exemplos prÃ¡ticos

A seguir, apresento exemplos prÃ¡ticos para Medicina, Psicologia e EducaÃ§Ã£o FÃ­sica.

### Medicina: ComparaÃ§Ã£o de dois tratamentos para dor

**CenÃ¡rio:**  
Um estudo clÃ­nico quer comparar dois medicamentos para dor crÃ´nica.  

- Tamanho do efeito esperado (Cohen's d): 0.2 (pequeno)  
- Poder desejado: 0.80  
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-medcal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necessÃ¡ria para cada grupo
pwr.t.test(d = 0.2, power = 0.8, sig.level = 0.05, type = "two.sample")
```

Tamanho da amostra: 394 em cada grupo

### Psicologia: IntervenÃ§Ã£o para reduÃ§Ã£o de ansiedade

**CenÃ¡rio:**  
Um psicÃ³logo quer testar se uma nova terapia reduz a ansiedade em relaÃ§Ã£o ao tratamento padrÃ£o.  

- Tamanho do efeito esperado (Cohen's d): 0.6 (mÃ©dio/grande)  
- Poder desejado: 0.80  
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-psicocal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necessÃ¡ria para cada grupo
pwr.t.test(d = 0.6, power = 0.8, sig.level = 0.05, type = "two.sample")
```

Tamanho da amostra: 45 em cada grupo

### EducaÃ§Ã£o FÃ­sica: Efeito de um programa de treinamento na performance de corrida

**CenÃ¡rio:**  
Um preparador fÃ­sico quer comparar a performance de alunos submetidos a dois programas de treinamento diferentes.  

- Tamanho do efeito esperado (Cohen's d): 0.8 (grande)  
- Poder desejado: 0.80
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-educacal, message=FALSE,  warning=FALSE}
library(pwr)
# Calculando o tamanho da amostra necessÃ¡ria para cada grupo
pwr.t.test(d = 0.8, power = 0.8, sig.level = 0.05, type = "two.sample")
```
Tamanho da amostra: 26 em cada grupo

- O resultado de cada funÃ§Ã£o indica o **nÃºmero mÃ­nimo de participantes em cada grupo** para atingir o **poder estatÃ­stico** desejado.


## Como calcular o poder do teste quando vocÃª jÃ¡ tem o tamanho da amostra

O pacote `pwr` do R nÃ£o serve apenas para calcular o tamanho da amostra necessÃ¡rio. Ele tambÃ©m permite **descobrir o poder do teste** caso vocÃª jÃ¡ saiba quantos participantes terÃ¡ em cada grupo.

### Exemplo 

Suponha que vocÃª fez um estudo com **26 participantes em cada grupo** e espera encontrar um **tamanho de efeito grande (d = 0.8)**. O nÃ­vel de significÃ¢ncia que vocÃª escolheu Ã© o padrÃ£o, **0,05**. VocÃª quer saber: *com essa amostra, qual Ã© o poder do meu teste*?

VocÃª pode usar:

```{r pwr-podercal, message=FALSE,  warning=FALSE}
pwr.t.test(n = 26, d = 0.8, power = NULL, sig.level = 0.05, type = "two.sample")
```

**ExplicaÃ§Ã£o dos parÃ¢metros**

- `n = 20`: tamanho da amostra em cada grupo jÃ¡ definido.
- `d = 0.8`: tamanho do efeito (Cohenâ€™s d), aqui considerado grande.
- `sig.level = 0.05`: nÃ­vel de significÃ¢ncia (chance mÃ¡xima de um falso positivo).
- `type = "two.sample"`: teste t para dois grupos independentes.
- `power = NULL`: ao deixar o parÃ¢metro `power` em NULL, vocÃª estÃ¡ dizendo ao R para calcular **qual Ã© o poder do teste** com esses valores.

Nesse caso o poder do teste Ã© de 70%.

**O que acontece nesse cÃ¡lculo?**

O R resolve a equaÃ§Ã£o para o poder estatÃ­stico usando os valores que vocÃª forneceu. Ou seja, ele vai informar a **probabilidade de detectar uma diferenÃ§a real (de tamanho d = 0.8) entre os grupos, com 26 participantes em cada grupo**, considerando o nÃ­vel de significÃ¢ncia especificado.

**Por que isso Ã© Ãºtil?**

- Se o poder calculado for **menor que 0,80** (80%), pode ser interessante aumentar a amostra para garantir maior chance de detectar diferenÃ§as reais.
- Se o poder jÃ¡ for **maior que 0,80**, seu estudo tem boa sensibilidade para o efeito esperado.

**Resumindo**

- VocÃª pode usar `pwr.t.test` para calcular o poder do teste, **bastando informar `n` e deixar `power = NULL`**.
- Isso Ã© Ãºtil para analisar experimentos jÃ¡ realizados ou planejar com base em restriÃ§Ãµes de amostra.


## CÃ¡lculo do Tamanho da Amostra para Testes t Pareado e Wilcoxon

AlÃ©m do teste t para amostras independentes, vocÃª pode calcular o tamanho da amostra para outras situaÃ§Ãµes, como o teste t pareado e os testes nÃ£o paramÃ©tricos de Wilcoxon (para amostras pareadas ou nÃ£o pareadas). Para os testes nÃ£o paramÃ©tricos, recomenda-se aumentar o tamanho da amostra em 15% em relaÃ§Ã£o ao cÃ¡lculo do teste t correspondente.


### Teste t Pareado

**CenÃ¡rio:**  
VocÃª quer testar se uma intervenÃ§Ã£o reduz o nÃ­vel de estresse dos mesmos participantes antes e depois do tratamento.  

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-t-pareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
```

Observe o argumento **type = "paired"** indicando que o cÃ¡lculo Ã© para amostras pareadas.

### Teste de Wilcoxon para Amostras NÃ£o Pareadas

**CenÃ¡rio:**  
VocÃª deseja comparar dois grupos de pacientes com dados nÃ£o normalmente distribuÃ­dos. 

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-wilcox-naopareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t de duas amostras
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
# Acrescentar 15% para o teste de Wilcoxon
63.76 * 1.15
```

Acrescentando 15% ao cÃ¡lculo amostral realizado com o `pwr.t.test`, sÃ£o necessÃ¡rias 74 amostras. Os testes nÃ£o paramÃ©tricos, como o teste de Wilcoxon, geralmente apresentam menor poder estatÃ­stico em comparaÃ§Ã£o aos testes paramÃ©tricos. Para compensar essa diferenÃ§a e obter um poder semelhante ao dos testes paramÃ©tricos, recomenda-se aumentar o tamanho da amostra em cerca de 15%. Assim, o teste nÃ£o paramÃ©trico passa a ter uma chance semelhante de detectar um efeito real, caso ele exista.

### Teste de Wilcoxon Pareado

**CenÃ¡rio:**  
VocÃª avalia o desempenho dos mesmos alunos antes e depois de um programa de treinamento, com dados nÃ£o normalmente distribuÃ­dos.  

- Tamanho do efeito esperado (d de Cohen): 0.5  
- Poder desejado: 0.80  
- NÃ­vel de significÃ¢ncia: 0.05

```{r pwr-wilcox-pareadocal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
# Acrescentar 15% para o teste de Wilcoxon
34 * 1.15
```
Acrescentando 15% ao cÃ¡lculo amostral realizado com o `pwr.t.test`, sÃ£o necessÃ¡rias aproximadamente 40 amostras.

<!--chapter:end:15-Calculo-amostral-R.Rmd-->

# Memes de EstatÃ­stica: p-valor

O p-valor Ã© um dos conceitos mais populares (e polÃªmicos) da estatÃ­stica. A seguir, veja alguns memes famosos sobre p-valor, acompanhados de interpretaÃ§Ãµes e traduÃ§Ã£o para o portuguÃªs.

Memes ajudam a ilustrar de forma divertida como o p-valor Ã© frequentemente mal interpretado ou supervalorizado. Rejeitar H0 nÃ£o Ã© tudo: pense criticamente sobre seus resultados!

## Quando vocÃª encontra um p-valor baixo e sabe que deve rejeitar H0

![Fonte: https://library.fiveable.me/ap-stats/unit-6/concluding-test-for-population-proportion/study-guide/THZeUpkm11DAwnNb6p4g](p-value4.jpg)

**TraduÃ§Ã£o:**  
Quando vocÃª encontra um p-valor baixo e sabe que deve rejeitar a hipÃ³tese nula.

**InterpretaÃ§Ã£o:**  
O meme brinca com o entusiasmo de muitos pesquisadores ao encontrar um p-valor baixo (menor que 0,05), pois sabem que isso permite rejeitar a hipÃ³tese nula (H0). No entanto, Ã© importante lembrar que rejeitar H0 nÃ£o garante que o resultado seja relevante do ponto de vista prÃ¡tico ou cientÃ­fico. O p-valor indica o quanto os resultados observados seriam inesperados caso a hipÃ³tese nula fosse verdadeira, mas nÃ£o informa o tamanho ou a relevÃ¢ncia prÃ¡tica dessa diferenÃ§a encontrada.

---

## Homem-Aranha apontando

![Fonte: https://danawanzer.github.io/stats-with-jamovi/alpha-p-values.html](p-value3.jpg)

**TraduÃ§Ã£o:**  
P < 0,05  
Rejeitar a hipÃ³tese nula  
Estatisticamente significativo

**InterpretaÃ§Ã£o:**  
Esse meme mostra como as pessoas frequentemente confundem ou usam como sinÃ´nimos as expressÃµes "p < 0,05", "rejeitar a hipÃ³tese nula" e "significÃ¢ncia estatÃ­stica". Na prÃ¡tica, sÃ£o conceitos relacionados, mas nÃ£o exatamente iguais: um p-valor menor que o nÃ­vel de significÃ¢ncia leva Ã  rejeiÃ§Ã£o de H0, o que Ã© chamado de resultado estatisticamente significativo. Mas lembre-se: um resultado pode ser estatisticamente significativo e, mesmo assim, nÃ£o ter importÃ¢ncia prÃ¡tica no mundo real.

---

## Namorado distraÃ­do

![Fonte: https://imgflip.com/i/2b00xk](p-values2.jpg)

**TraduÃ§Ã£o:**  
p-valor 0,083  
>  
NÃ­vel de significÃ¢ncia 0,05

**InterpretaÃ§Ã£o:**  
O pesquisador estÃ¡ andando tranquilamente com sua fiel companheira, o nÃ­vel de significÃ¢ncia 0,05, mas nÃ£o resiste e joga aquele olhar para o p-valor 0,083 que acabou de passar. Mesmo sabendo que, tecnicamente, 0,083 Ã© â€œmaiorâ€ do que 0,05 e nÃ£o deveria chamar tanta atenÃ§Ã£o, ele fica tentado a inventar desculpas para dar uma chance Ã quele resultado quase-significativo: â€œah, mas foi quase!â€, â€œquem nunca, nÃ©?â€. No fundo, esse Ã© o tÃ­pico caso do pesquisador que se empolga com resultados que chegaram perto do valor de corte, tentando transformar um â€œquaseâ€ em uma grande descoberta. Mas Ã© importante lembrar: resultado quase significativo ainda nÃ£o Ã© significativo!

---

## Willy Wonka e o p-valor menor que 0,05

![Fonte: https://naturallyspeaking.blog/2015/06/03/episode-25-the-problem-with-p-values/](p-values1.jpg)

**TraduÃ§Ã£o:**  
Ah, vocÃª encontrou um p-valor menor que 0,05?  
Por favor, me conte tudo sobre sua grande descoberta.

**InterpretaÃ§Ã£o:**  
Willy Wonka ironiza a empolgaÃ§Ã£o de quem encontra um p-valor abaixo de 0,05, sugerindo que nem sempre isso significa uma grande descoberta. O meme alerta para a importÃ¢ncia de interpretar o p-valor no contexto do estudo, considerando tamanho de efeito, relevÃ¢ncia prÃ¡tica e outros fatores alÃ©m da simples significÃ¢ncia estatÃ­stica. O prÃ³prio Wonka pediria: â€œme convenÃ§a de que seu resultado importa de verdade!â€

---

## Cantada Nerd

![Fonte: https://varshitasher.medium.com/memorizing-p-value-interpretation-through-coronavirus-76e36606b5ff](p-value5.jpg)

**TraduÃ§Ã£o**:  
Ei, garota, seu p deve ser maior que 0,05, porque eu falho em te rejeitar.

**InterpretaÃ§Ã£o**:  
Esse meme faz uma brincadeira romÃ¢ntica usando a linguagem estatÃ­stica: em vez de rejeitar a hipÃ³tese nula, a pessoa estÃ¡ dizendo que nÃ£o consegue rejeitar a garota, assim como um p-valor acima de 0,05 geralmente significa que nÃ£o rejeitamos H0. Ã‰ o clÃ¡ssico â€œnÃ£o posso te rejeitar, cientificamente falandoâ€! Uma piada para conquistar coraÃ§Ãµes e estatÃ­sticos ao mesmo tempo.

---

## P-valor nÃ£o Ã© tudo

![Fonte: https://x.com/data_question/status/1675416773665890304](p-value6.jpg)

**TraduÃ§Ã£o:**  
Cena de duas pessoas no carro, uma com expressÃ£o de frustraÃ§Ã£o ao ouvir "p-values", enquanto a outra estÃ¡ alegre ou satisfeita.

**InterpretaÃ§Ã£o:**  
A graÃ§a do meme estÃ¡ justamente no contraste entre frustraÃ§Ã£o e alegria: enquanto uma pessoa demonstra cansaÃ§o ou desapontamento ao ouvir sobre p-values de novo, a outra parece satisfeita sÃ³ com isso. O meme brinca com as diferentes expectativas na anÃ¡lise estatÃ­stica, hÃ¡ quem se contente apenas com a significÃ¢ncia estatÃ­stica (p < 0,05), enquanto outros esperam uma anÃ¡lise completa, considerando tambÃ©m o tamanho do efeito, intervalos de confianÃ§a, e a real relevÃ¢ncia dos achados. Ã‰ um lembrete de que estatÃ­stica vai alÃ©m do p-value!

---

## Coitado do tamanho do efeito

![](p-value9.jpg)

**TraduÃ§Ã£o:**  
Ã€ esquerda, uma fila enorme se forma na barraca "p-values". Ã€ direita, a barraca "effect sizes" estÃ¡ vazia, quase ouvindo grilos.

**InterpretaÃ§Ã£o:**  
Este meme Ã© o retrato da triste (e hilÃ¡ria) realidade dos artigos cientÃ­ficos: todo mundo corre para saber se o valor de p Ã© menor que 0,05, como se fosse a Ãºltima coca-cola do deserto. JÃ¡ o tamanho do efeito, que realmente diz se o resultado Ã© relevante, Ã© solenemente ignorado. Moral estatÃ­stica: enquanto os p-values lotam (mesmo que tragam resultados irrelevantes), o effect size fica sozinho no canto, esperando alguÃ©m notar sua real importÃ¢ncia. Quem entende estatÃ­stica sabe: tamanho do efeito merece atenÃ§Ã£o!

---

## Senhora estatÃ­stica

![Fonte: https://lovestats.wordpress.com/dman/survey-research-statistics-meme/](p-value7.jpg)

**TraduÃ§Ã£o:**  
Em cima: "ONE DOES NOT SIMPLY" ("SIMPLESMENTE NÃƒO SE...")
Embaixo: "REPORT P-VALUES WITHOUT EFFECT SIZES" ("RELATA P-VALORES SEM TAMANHOS DE EFEITO")

**InterpretaÃ§Ã£o:**  
Esse meme faz referÃªncia ao clÃ¡ssico da cultura pop (Senhor dos Aneis) para lembrar que estatÃ­stica nÃ£o Ã© terra sem lei: nÃ£o basta encontrar um p < 0,05 e sair comemorando. Relatar apenas o valor de p Ã© igual a contar sÃ³ metade da fofoca: falta o contexto! O tamanho do efeito Ã© quem diz se a diferenÃ§a Ã© daquelas que mudam a vida ou se Ã© sÃ³ uma diferenÃ§a microscÃ³pica e irrelevante. Em outras palavras, estatÃ­stica de verdade combina significado estatÃ­stico (p-value) com significado prÃ¡tico (effect size). NÃ£o faÃ§a estatÃ­stica â€œpela metadeâ€!

---

## Pobi do gatinho

![Fonte: https://x.com/Jente_O/status/1698942647493153251](p-value8.jpg)

**TraduÃ§Ã£o:**  
Primeira cena: Pessoa abraÃ§a um cachorro chamado â€œP-VALUESâ€. AtrÃ¡s, um gato (effect sizes) observa, excluÃ­do.  
Demais cenas: Close no gato â€œeffect sizesâ€, visivelmente triste, segurando um brinquedo, ignorado.

**InterpretaÃ§Ã£o:**  
O meme mostra o drama dos tamanhos de efeito: sempre deixados de lado, enquanto os p-values recebem todo o carinho e atenÃ§Ã£o. Ã‰ como se o cachorro (p-value) ganhasse petiscos sÃ³ por latir, enquanto o gato (effect size), que realmente entrega o conteÃºdo, sÃ³ observa de longe. Estatisticamente, Ã© como celebrar um resultado significativo sem saber se ele realmente importa no mundo real. O gato chora, e o revisor do artigo tambÃ©m!

---

Esses memes ilustram, com bom humor, que o p-valor sozinho nÃ£o conta toda a histÃ³ria. Um resultado estatisticamente significativo nÃ£o garante relevÃ¢ncia prÃ¡tica. O tamanho do efeito Ã© fundamental para avaliar se uma diferenÃ§a observada tem impacto real, e nÃ£o apenas estatÃ­stico. Ao analisar dados, valorize tanto o p-valor quanto o tamanho do efeito para conclusÃµes mais robustas e informativas.

<!--chapter:end:16-Memes.Rmd-->

# Pacotes `pwr`, `rstatix` e `effsize`

Nesse capÃ­tulo, abordaremos como calcular tamanho de amostra, poder estatÃ­stico e tamanho do efeito em diferentes testes estatÃ­sticos usando os pacotes `pwr`, `rstatix` e `effsize`. O foco serÃ¡ nos testes t (pareado e nÃ£o pareado) e Wilcoxon (pareado e nÃ£o pareado), com exemplos prÃ¡ticos e orientaÃ§Ãµes sobre interpretaÃ§Ã£o dos resultados.

> **Importante:** Antes de comeÃ§ar, certifique-se de instalar o pacote `pwr`, `rstatix` e `effsize`:
```r
install.packages(c("pwr", "rstatix", "effsize"))
```

## CÃ¡lculos de tamanho de amostra, poder e efeito com o pacote `pwr`

O pacote `pwr` permite calcular:

- **Tamanho de amostra** necessÃ¡rio para detectar um determinado efeito;
- **Poder estatÃ­stico** de um teste para amostras de tamanho fixo;
- **Menor tamanho de efeito** que pode ser detectado para um dado poder e amostra.

### ExercÃ­cio 1: Tamanho da amostra para teste t nÃ£o pareado

Calcule o tamanho da amostra necessÃ¡rio para detectar um efeito moderado (d = 0.5), com poder de 0.8 e nÃ­vel de significÃ¢ncia de 0.05, em um teste t bilateral para duas amostras independentes.

```{r n-tnpcal, message=FALSE,  warning=FALSE}
library(pwr)
# Tamanho da amostra para teste t nÃ£o pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```

---

### ExercÃ­cio 2: Poder do teste t nÃ£o pareado para n fixo

Se vocÃª dispÃµe de 26 observaÃ§Ãµes em cada grupo, qual Ã© o poder do teste para detectar um efeito de 0.5, com sig.level = 0.05?

```{r p-tnpcal, message=FALSE,  warning=FALSE}
# Poder do teste t nÃ£o pareado para n = 26 por grupo
pwr.t.test(n = 26, d = 0.5, sig.level = 0.05, type = "two.sample")
```

---

### ExercÃ­cio 3: Menor efeito detectÃ¡vel no teste t nÃ£o pareado

Com 26 observaÃ§Ãµes por grupo, poder de 0.8 e sig.level de 0.05, qual o menor tamanho de efeito detectÃ¡vel?

```{r d-tnpcal, message=FALSE,  warning=FALSE}
# Tamanho do efeito detectÃ¡vel
pwr.t.test(n = 26, power = 0.8, sig.level = 0.05, type = "two.sample")
```

---

### ExercÃ­cio 4: Repita para outros testes

#### a) Teste t pareado

```{r n-tpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para teste t pareado
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")

# Poder para n = 26 pares
pwr.t.test(n = 26, d = 0.5, sig.level = 0.05, type = "paired")

# Tamanho do efeito detectÃ¡vel
pwr.t.test(n = 26, power = 0.8, sig.level = 0.05, type = "paired")
```

#### b) Wilcoxon nÃ£o pareado

```{r n-wnpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para Wilcoxon nÃ£o pareado (aproximaÃ§Ã£o pelo teste t)
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "two.sample")
```

> **Dica:** O pacote `pwr` nÃ£o possui funÃ§Ãµes especÃ­ficas para testes nÃ£o-paramÃ©tricos como Wilcoxon. Por isso, costuma-se usar o cÃ¡lculo para teste t como aproximaÃ§Ã£o, aumentando o tamanho da amostra em cerca de 15% (multiplique o valor obtido por 1,15), jÃ¡ que testes nÃ£o-paramÃ©tricos geralmente requerem amostras maiores para o mesmo poder estatÃ­stico.

```{r p-wnpcal, message=FALSE,  warning=FALSE}
# Recalculando o tamanho da amostra
63.76561*1.15
```

> O *tamanho do efeito para o teste de Wilcoxon* pode ser aproximado *por d Ã— 0,86*, sendo d o tamanho do efeito de Cohen, desde que as distribuiÃ§Ãµes dos grupos sejam aproximadamente normais e com variÃ¢ncias semelhantes (Lehmann, 2006; Noether, 1987).

```{r e-wnpcal, message=FALSE,  warning=FALSE}
# Poder da amostra para Wilcoxon nÃ£o pareado (aproximaÃ§Ã£o pelo teste t)
pwr.t.test(n = 26, d = 0.5*0.86, sig.level = 0.05, type = "two.sample")
```

#### c) Wilcoxon pareado

```{r n-wpcal, message=FALSE,  warning=FALSE}
# Tamanho da amostra para Wilcoxon pareado (aproximaÃ§Ã£o pelo teste t pareado)
pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05, type = "paired")
```

```{r p-wpcal, message=FALSE,  warning=FALSE}
# Poder da amostra para Wilcoxon nÃ£o pareado (aproximaÃ§Ã£o pelo teste t)
pwr.t.test(n = 26, d = 0.5*0.86, sig.level = 0.05, type = "two.sample")
```

> **AtenÃ§Ã£o:** O **d de Cohen** foi criado para testes paramÃ©tricos, como o teste t. Para testes nÃ£o paramÃ©tricos (Wilcoxon), utilize medidas especÃ­ficas, pois a interpretaÃ§Ã£o do d nÃ£o se aplica ao contexto de ranks.

---

### Argumentos principais da funÃ§Ã£o `pwr.t.test()`

A funÃ§Ã£o `pwr.t.test()` possui os seguintes argumentos principais:

- `n`: tamanho da amostra em cada grupo (ou nÃºmero de pares, para teste pareado)
- `d`: tamanho do efeito (diferenÃ§a padronizada entre grupos)
- `power`: poder estatÃ­stico desejado
- `sig.level`: nÃ­vel de significÃ¢ncia (geralmente 0.05)
- `type`: tipo de teste t: `"two.sample"`, `"paired"` ou `"one.sample"`

> **Dica:** Deixe como `NULL` o parÃ¢metro que vocÃª deseja calcular.
> - Para calcular o tamanho do efeito: `d = NULL`
> - Para calcular o poder: `power = NULL`
> - Para calcular o tamanho da amostra: `n = NULL`

**Exemplo para calcular o tamanho do efeito:**
```r
pwr.t.test(n = 26, d = NULL, power = 0.8, sig.level = 0.05, type = "two.sample")
```
Neste exemplo, o argumento `d` Ã© o valor a ser calculado.

---

### Grupos Desbalanceados: usando `pwr.t2n.test()`

Quando os grupos tÃªm tamanhos diferentes, use `pwr.t2n.test()` para calcular o poder.

```{r pwr-2ncal, message=FALSE,  warning=FALSE}
# Exemplo: grupo 1 com 95, grupo 2 com 30 observaÃ§Ãµes
library(pwr)
pwr.t2n.test(n1 = 95, n2 = 30, d = 0.5, sig.level = 0.05)
```

- **n1**: tamanho do primeiro grupo
- **n2**: tamanho do segundo grupo

**AtenÃ§Ã£o:** Grupos desbalanceados podem comprometer o poder do teste, aumentar a variÃ¢ncia e dificultar a interpretaÃ§Ã£o dos resultados. Sempre que possÃ­vel, busque amostras equilibradas.

---

## Tamanho do efeito em testes de Wilcoxon

O tamanho do efeito complementa a anÃ¡lise estatÃ­stica, indicando a magnitude da diferenÃ§a entre grupos. Para testes paramÃ©tricos (como o t), usa-se o **d de Cohen**. Para testes nÃ£o paramÃ©tricos (Wilcoxon), utilize medidas apropriadas, como **r de Wilcoxon** e **Delta de Cliff**.

### Por que NÃƒO usar d de Cohen no Wilcoxon?

- O d de Cohen pressupÃµe distribuiÃ§Ã£o normal e comparaÃ§Ã£o direta de mÃ©dias/desvios.
- O Wilcoxon compara **ranks**, nÃ£o mÃ©dias.
- Aplicar o d de Cohen em dados de Wilcoxon pode gerar interpretaÃ§Ãµes erradas.

### Medidas recomendadas para Wilcoxon:

- **r de Wilcoxon:** Calculado com o pacote `rstatix`.
- **Cliffâ€™s Delta:** DisponÃ­vel no pacote `effsize`.

---

#### r de Wilcoxon (Wilcoxon rank-sum, nÃ£o pareado)

```{r rWilcoxcal, eval=TRUE, message=FALSE,  warning=FALSE}
library(rstatix)
library(readr)

# Importe o banco de dados Pokemon
Pokemon <- read_csv("Pokemon.csv")

# Subconjunto com PokÃ©mons verdes ou amarelos
dados_filtrados <- subset(Pokemon, Color %in% c("Green", "Yellow"))

# Verifique os dados apÃ³s o filtro
print(table(dados_filtrados$Color))

# Boxplot
boxplot(dados_filtrados$Speed ~ dados_filtrados$Color)

# Teste de Wilcoxon nÃ£o pareado
wilcox.test(dados_filtrados$Speed ~ dados_filtrados$Color)

# Tamanho do efeito r de Wilcoxon para Green vs Yellow
wilcox_effsize(dados_filtrados, Speed ~ Color)

levels(dados_filtrados$Color)
```

A tabela apresentada Ã© resultado da funÃ§Ã£o `wilcox_effsize()` do pacote `rstatix` e resume o tamanho do efeito (r de Wilcoxon) para a comparaÃ§Ã£o entre dois grupos ("Green" e "Yellow") em relaÃ§Ã£o Ã  variÃ¡vel "Speed". Veja como interpretar cada coluna:

- **.y.**: variÃ¡vel de interesse analisada, neste caso, "Speed" (velocidade dos PokÃ©mons).
- **group1**: primeiro grupo comparado ("Green").
- **group2**: segundo grupo comparado ("Yellow").
- **effsize**: valor ABSOLUTO do tamanho de efeito calculado, aqui 0.206.  
- O resultado apresentado na coluna `effsize` Ã© sempre positivo, independentemente da ordem dos grupos definidos na variÃ¡vel categÃ³rica.
- **n1**: nÃºmero de observaÃ§Ãµes no grupo 1 (79 PokÃ©mons verdes).
- **n2**: nÃºmero de observaÃ§Ãµes no grupo 2 (64 PokÃ©mons amarelos).
- **magnitude**: classificaÃ§Ã£o qualitativa do tamanho de efeito ("small", ou seja, efeito pequeno).

**InterpretaÃ§Ã£o:**  
A diferenÃ§a de velocidade entre PokÃ©mons verdes e amarelos Ã© estatisticamente significativa (W = 1920.5, p-value = 0.01363), porÃ©m de **pequena magnitude** (r = 0.206). Isso indica que, embora exista uma diferenÃ§a, ela Ã© discreta do ponto de vista prÃ¡tico.



> No caso de teste pareado, acrescente o argumento `paired = TRUE`:
> ```r
> wilcox_effsize(dados, antes ~ depois, paired = TRUE)
> ```

---

#### Delta de Cliff

```{r, DCliffcal, message=FALSE, warning=FALSE}
library(effsize)

# Calcule o Delta de Cliff
cliff.delta(dados_filtrados$Speed ~ dados_filtrados$Color)
```

O **Delta de Cliff** estimado foi de **-0,24**, classificado como efeito **pequeno** ("small"). O intervalo de confianÃ§a de 95% vai de aproximadamente **-0,41** a **-0,05**, indicando que, com alta confianÃ§a, o efeito verdadeiro Ã© negativo e pequeno.

- **Sinal negativo:** Indica que o grupo "Yellow" tende a apresentar velocidades maiores do que o grupo "Green". Ou seja, ao comparar aleatoriamente um PokÃ©mon amarelo com um verde, Ã© mais provÃ¡vel que o amarelo tenha uma velocidade superior.
- **Magnitude pequena:** O valor absoluto de -0,24 mostra que a diferenÃ§a entre os grupos existe, mas Ã© de pouca relevÃ¢ncia prÃ¡tica.
- **Intervalo de confianÃ§a nÃ£o inclui zero:** Como o intervalo vai de -0,41 a -0,05, podemos afirmar que existe uma diferenÃ§a real entre os grupos, embora seja pequena.
- **InterpretaÃ§Ã£o prÃ¡tica:** Apesar de haver uma diferenÃ§a estatÃ­stica, ela nÃ£o Ã© marcante. Ã‰ importante avaliar se essa diferenÃ§a tem relevÃ¢ncia biolÃ³gica ou prÃ¡tica no contexto do seu estudo.

O Delta de Cliff indica que PokÃ©mons amarelos tendem a ser um pouco mais rÃ¡pidos do que os verdes, mas a diferenÃ§a Ã© pequena do ponto de vista prÃ¡tico.


### ComparaÃ§Ã£o entre o r de Wilcoxon e o Delta de Cliff

Quando realizamos testes nÃ£o paramÃ©tricos para comparar grupos, como o teste de Wilcoxon (Mann-Whitney ou Wilcoxon pareado), Ã© importante complementar o resultado do teste com uma medida de tamanho de efeito. As duas opÃ§Ãµes mais comuns sÃ£o o **r de Wilcoxon** e o **Delta de Cliff**. Veja a seguir uma comparaÃ§Ã£o entre elas:

### r de Wilcoxon

- **DefiniÃ§Ã£o:** Mede a magnitude da diferenÃ§a entre grupos com base nos postos (ranks) dos dados. O cÃ¡lculo Ã© semelhante ao coeficiente de correlaÃ§Ã£o de Pearson, mas aplicado a dados nÃ£o paramÃ©tricos.
- **VariaÃ§Ã£o dos valores:** O r de Wilcoxon varia de -1 a 1.
  - Valores prÃ³ximos de 0 indicam pouca diferenÃ§a entre grupos.
  - Valores prÃ³ximos de -1 ou 1 indicam diferenÃ§as muito grandes.
  - O sinal indica a direÃ§Ã£o da diferenÃ§a.

**QualificaÃ§Ã£o dos valores**, segundo Cohen (1988):

| Valor absoluto de $r$ | InterpretaÃ§Ã£o    |
|:---------------------|:----------------|
| aproximadamente 0,10                | Pequeno         |
| aproximadamente 0,30                | Moderado        |
| maior ou igual 0,50                | Grande          |

**Exemplos:**

- **Efeito pequeno:**  
  Se o valor absoluto de r estiver prÃ³ximo de **0,10**, a diferenÃ§a entre os grupos Ã© pequena.  
  _(Exemplo: |r| = 0,10 â†’ efeito pequeno)_

- **Efeito moderado:**  
  Se o valor absoluto de r estiver prÃ³ximo de **0,30**, a diferenÃ§a entre os grupos Ã© moderada.  
  _(Exemplo: |r| = 0,30 â†’ efeito moderado)_

- **Efeito grande:**  
  Se o valor absoluto de r for igual ou superior a **0,50**, a diferenÃ§a Ã© grande.  
  _(Exemplo: |r| = 0,55 â†’ efeito grande)_



### Delta de Cliff ($\delta$) 

- **DefiniÃ§Ã£o:** Mede a probabilidade de um valor de um grupo ser maior do que de outro grupo, subtraÃ­da da probabilidade contrÃ¡ria. Ã‰ totalmente nÃ£o paramÃ©trico e nÃ£o depende de distribuiÃ§Ã£o, sendo adequado para variÃ¡veis ordinais ou dados assimÃ©tricos.
- **VariaÃ§Ã£o dos valores:** O Delta de Cliff varia de -1 a 1.
    - Valor 0: nÃ£o hÃ¡ diferenÃ§a entre os grupos.
    - Valor positivo: o grupo 1 tende a ter valores maiores que o grupo 2.
    - Valor negativo: o grupo 2 tende a ter valores maiores que o grupo 1.
- **Como interpretar os valores do Delta de Cliff?**  
  O **Delta de Cliff** mostra o tamanho da diferenÃ§a entre dois grupos. O mais comum Ã© considerar o valor absoluto de $\delta$ (ou seja, ignorar se Ã© positivo ou negativo e olhar sÃ³ para o tamanho do nÃºmero).

**ClassificaÃ§Ã£o da magnitude do efeito**, segundo Romano et al. (2006)

| Valor absoluto de $\delta$ | InterpretaÃ§Ã£o    |
|:--------------------------|:----------------|
| menor que 0.147                    | DesprezÃ­vel     |
| de 0.147 e menor que 0.33             | Pequeno         |
| de 0.33 e menor que 0.474             | MÃ©dio           |
| maior ou igual a 0.474                    | Grande          |

**Exemplos:**

- **Efeito desprezÃ­vel:**  
  Se o valor absoluto do delta for menor que **0,147**, a diferenÃ§a entre os grupos Ã© desprezÃ­vel.  
  _(Exemplo: |$\delta$| = 0,10 â†’ efeito desprezÃ­vel)_

- **Efeito pequeno:**  
  Se o valor absoluto do delta for igual ou maior que **0,147** e menor que **0,33**, a diferenÃ§a Ã© pequena.  
  _(Exemplo: |$\delta$| = 0,20 â†’ efeito pequeno)_

- **Efeito mÃ©dio:**  
  Se o valor absoluto do delta for igual ou maior que **0,33** e menor que **0,474**, a diferenÃ§a Ã© mÃ©dia.  
  _(Exemplo: |$\delta$| = 0,40 â†’ efeito mÃ©dio)_

- **Efeito grande:**  
  Se o valor absoluto do delta for igual ou maior que **0,474**, a diferenÃ§a Ã© grande.  
  _(Exemplo: |$\delta$| = 0,50 â†’ efeito grande)_

**Resumindo:**  
Quanto mais prÃ³ximo de zero, menor a diferenÃ§a. Quanto mais prÃ³ximo de 1 (ou -1), maior a diferenÃ§a entre os grupos.

> **Dica:** Sempre use o valor absoluto, ou seja, olhe apenas para o tamanho do nÃºmero, sem se preocupar se ele Ã© positivo ou negativo.


### Qual Ã© melhor usar?

- **Ambos** sÃ£o vÃ¡lidos e amplamente aceitos para dados nÃ£o paramÃ©tricos.
- O **r de Wilcoxon** Ã© intuitivo se vocÃª jÃ¡ estÃ¡ acostumado com o coeficiente de correlaÃ§Ã£o, e Ã© facilmente interpretÃ¡vel em contextos onde se deseja uma analogia ao r de Pearson.
- O **Delta de Cliff** Ã© mais robusto em situaÃ§Ãµes com muitos empates, diferentes tamanhos de grupo ou dados ordinais, e fornece uma interpretaÃ§Ã£o mais direta da diferenÃ§a de probabilidades entre grupos.
- **RecomendaÃ§Ã£o prÃ¡tica:**  
  - Para estudos com dados ordenados, amostras desbalanceadas ou muitos empates, o Delta de Cliff pode ser preferido.
  - Se vocÃª busca uma medida anÃ¡loga ao r de Pearson para facilitar comparaÃ§Ãµes, use o r de Wilcoxon.
  - Em muitos casos, apresentar ambos os valores enriquece a interpretaÃ§Ã£o dos resultados.

NÃ£o existe uma medida "melhor" de forma absoluta; a escolha depende do contexto do estudo e das caracterÃ­sticas dos dados. Ambas sÃ£o Ãºteis para interpretar a relevÃ¢ncia prÃ¡tica das diferenÃ§as identificadas em testes nÃ£o paramÃ©tricos.


> **Nota:** Para a comparaÃ§Ã£o entre os grupos *Green* e *Yellow* na variÃ¡vel *Speed*, o tamanho de efeito calculado pelo **r de Wilcoxon** foi **0,206** (efeito pequeno), enquanto o **delta de Cliff** foi **-0,240** (efeito pequeno, IC 95%: -0,414 a -0,050). Ã‰ esperado que os valores numÃ©ricos dessas mÃ©tricas diferem, pois sÃ£o baseados em cÃ¡lculos estatÃ­sticos distintos, mas ambos apontam para uma diferenÃ§a de pequena magnitude entre os grupos.

No entanto, Ã© importante destacar que, neste caso, o valor negativo do delta de Cliff estÃ¡ condizente com o observado no boxplot: o grupo *Yellow* tende a apresentar valores de *Speed* ligeiramente maiores que o grupo *Green*, o que Ã© evidenciado pela direÃ§Ã£o negativa do delta. 

Esse alinhamento entre o resultado numÃ©rico do delta de Cliff e a visualizaÃ§Ã£o grÃ¡fica reforÃ§a a importÃ¢ncia de sempre analisar os dados de forma complementar, utilizando tanto medidas estatÃ­sticas quanto representaÃ§Ãµes visuais (como boxplots). A visualizaÃ§Ã£o grÃ¡fica pode revelar padrÃµes, tendÃªncias e assimetrias que enriquecem a interpretaÃ§Ã£o do tamanho de efeito e facilitam a comunicaÃ§Ã£o dos resultados.

<!--chapter:end:17-Exercicios-pwr.Rmd-->

# Teste de Normalidade

Antes de aplicar muitos testes estatÃ­sticos, Ã© importante verificar se os dados seguem uma distribuiÃ§Ã£o normal (ou "distribuiÃ§Ã£o gaussiana"). Essa etapa Ã© fundamental porque vÃ¡rios testes paramÃ©tricos (como o teste t de Student e a ANOVA) assumem a normalidade dos dados. Quando essa condiÃ§Ã£o nÃ£o Ã© atendida, a escolha do teste estatÃ­stico pode mudar para opÃ§Ãµes nÃ£o paramÃ©tricas.

## HipÃ³teses nos Testes de Normalidade

Todo teste de normalidade avalia as seguintes hipÃ³teses:

- **HipÃ³tese Nula (Hâ‚€):** Os dados seguem uma distribuiÃ§Ã£o normal.
- **HipÃ³tese Alternativa (Hâ‚):** Os dados **nÃ£o** seguem uma distribuiÃ§Ã£o normal.

- Se o valor de p for menor que 0,05: **Rejeitamos** a hipÃ³tese nula.
 
- Se o valor de p for maior ou igual 0,05: **NÃ£o rejeitamos** a hipÃ³tese nula. 

## Principais Testes de Normalidade

Abaixo estÃ£o os testes de normalidade mais conhecidos, quando sÃ£o mais recomendados e os pacotes em R:

| Teste             | Quando Usar                                      | Pacote no R    |
|-------------------|--------------------------------------------------|----------------|
| **Shapiro-Wilk**  | Amostras pequenas e mÃ©dias (n < 50 atÃ© ~ 2000)   | `stats`        |
| **Kolmogorov-Smirnov (K-S)** | Amostras maiores; pode comparar duas distribuiÃ§Ãµes, mas menos potente para normalidade | `stats`        |
| **Lilliefors**    | VersÃ£o do K-S ajustado para mÃ©dia e desvio amostrais | `nortest`      |
| **Anderson-Darling** | Mais sensÃ­vel nas caudas da distribuiÃ§Ã£o; recomendado para mÃ©dias e grandes amostras | `nortest`      |
| **Jarque-Bera**   | Teste baseado em assimetria (skewness) e curtose (kurtosis); comum em econometria | `tseries`      |
| **Dâ€™Agostino-Pearson** | Avalia assimetria e curtose em conjunto; recomendado para mÃ©dias e grandes amostras | `moments`      |

### Dicas de Uso

- Para **amostras pequenas** (n < 50): prefira o **Shapiro-Wilk** (funÃ§Ã£o `shapiro.test()` do pacote base `stats`).
- Para **amostras mÃ©dias a grandes**: considere **Anderson-Darling** (`ad.test()` do pacote `nortest`) ou **Dâ€™Agostino-Pearson** (`agostino.test()` do pacote `moments`).
- O **Kolmogorov-Smirnov** (`ks.test()`) Ã© mais geral, mas menos recomendado quando a mÃ©dia e desvio padrÃ£o sÃ£o estimados dos prÃ³prios dados.
- O **Lilliefors** (`lillie.test()` do pacote `nortest`) Ã© uma boa alternativa ao K-S para dados amostrais.
- Para anÃ¡lises em econometria ou sÃ©ries temporais, o **Jarque-Bera** (`jarque.bera.test()` do pacote `tseries`) Ã© bastante utilizado.

### Exemplo PrÃ¡tico em R

```{r, testenormex, message=FALSE, warning=FALSE}

#install.packages("nortest")
#install.packages("moments")

# Importe o banco de dados Pokemon
library(readr)
Pokemon <- read_csv("Pokemon.csv")

# Veja o QQ
qqnorm(Pokemon$Speed)
qqline(Pokemon$Speed)


# Shapiro-Wilk
shapiro.test(Pokemon$Speed)

# Anderson-Darling
library(nortest)
ad.test(Pokemon$Speed)

# Lilliefors
lillie.test(Pokemon$Speed)

# D'Agostino
library(moments)
agostino.test(Pokemon$Speed)

```

**Resumo**

- Sempre comece analisando a normalidade dos seus dados.
- Escolha o teste de acordo com o tamanho da amostra e o objetivo da anÃ¡lise.
- **Use grÃ¡ficos (histograma, boxplot e principalmente o QQ) junto com testes estatÃ­sticos para uma anÃ¡lise mais completa.**

> **Importante:** Testes de normalidade sÃ£o sensÃ­veis ao tamanho da amostra. Em amostras muito grandes, pequenas desvios podem resultar em p-valores baixos; em amostras pequenas, a potÃªncia dos testes Ã© baixa.


## Assimetria e Curtose: O que sÃ£o e por que sÃ£o importantes?

Quando analisamos dados, Ã© importante entender nÃ£o sÃ³ a mÃ©dia e o desvio padrÃ£o, mas tambÃ©m o **formato da distribuiÃ§Ã£o** dos valores. Duas medidas ajudam muito nisso: **assimetria** e **curtose**. Vamos entender cada uma de forma simples:

---

### O que Ã© Assimetria (Skewness)?

A **assimetria** mostra se os dados estÃ£o â€œpuxadosâ€ para algum lado, ou seja, se a distribuiÃ§Ã£o tem uma cauda maior para a direita ou para a esquerda.

- **Assimetria zero:** Os dados estÃ£o distribuÃ­dos de forma equilibrada ao redor da mÃ©dia (exemplo: distribuiÃ§Ã£o normal perfeita).
- **Assimetria positiva (Ã  direita):** A cauda Ã© mais longa Ã  direita, ou seja, hÃ¡ mais valores extremos acima da mÃ©dia.
- **Assimetria negativa (Ã  esquerda):** A cauda Ã© mais longa Ã  esquerda, hÃ¡ mais valores extremos abaixo da mÃ©dia.

**Por que isso importa?**  
A distribuiÃ§Ã£o Normal Ã© um exemplo de distribuiÃ§Ã£o simÃ©trica.

### O que Ã© Curtose (Kurtosis)?

A **curtose** indica o quanto a distribuiÃ§Ã£o Ã© â€œpontudaâ€ ou â€œachatadaâ€ em relaÃ§Ã£o Ã  DistribuiÃ§Ã£o Normal.

- **Curtose alta (leptocÃºrtica):** DistribuiÃ§Ã£o muito â€œpontudaâ€, com muitas observaÃ§Ãµes prÃ³ximas da mÃ©dia, mas tambÃ©m mais valores extremos (outliers).
- **Curtose baixa (platicÃºrtica):** DistribuiÃ§Ã£o mais achatada, com menos valores extremos.
- **Curtose mÃ©dia (mesocÃºrtica):** Parecida com a distribuiÃ§Ã£o normal.

**Por que isso importa?**  
A presenÃ§a de muita curtose (valores muito altos ou baixos) pode indicar que hÃ¡ mais outliers do que o esperado, o que tambÃ©m pode afetar os resultados de testes estatÃ­sticos.

- **Assimetria:** mostra se a distribuiÃ§Ã£o â€œpendeâ€ para um lado.
- **Curtose:** mostra se a distribuiÃ§Ã£o Ã© â€œpontudaâ€ e cheia de extremos, ou mais â€œachatadaâ€.

Essas duas medidas ajudam a entender melhor o comportamento dos seus dados e garantem que vocÃª escolha os testes estatÃ­sticos mais adequados para a sua anÃ¡lise!

<!--chapter:end:18-testedenormalidade.Rmd-->

# ComparaÃ§Ã£o de mais de dois grupos

Assim como na comparaÃ§Ã£o entre dois grupos, ao desejarmos comparar mais de dois grupos em uma anÃ¡lise estatÃ­stica, Ã© fundamental selecionar o teste mais adequado de acordo com as caracterÃ­sticas dos dados. Os testes podem ser **paramÃ©tricos** ou **nÃ£o paramÃ©tricos**, e a escolha correta depende da verificaÃ§Ã£o prÃ©via de alguns pressupostos, como normalidade, homogeneidade de variÃ¢ncias e independÃªncia das observaÃ§Ãµes.

## Revisando as hipÃ³teses da comparaÃ§Ã£o entre dois grupos

- **ParamÃ©trico (Teste t)**
  - **NÃ£o pareado (t de Student):**
    - Hâ‚€: As mÃ©dias dos dois grupos sÃ£o iguais (Î¼â‚ = Î¼â‚‚)
    - Hâ‚: As mÃ©dias dos dois grupos sÃ£o diferentes (Î¼â‚ â‰  Î¼â‚‚)
  - **Pareado (t pareado):**
    - Hâ‚€: A mÃ©dia das diferenÃ§as entre os pares Ã© igual a zero (Î¼_d = 0)
    - Hâ‚: A mÃ©dia das diferenÃ§as entre os pares Ã© diferente de zero (Î¼_d â‰  0)

- **NÃ£o paramÃ©trico**
  - **NÃ£o pareado (Mann-Whitney/Wilcoxon rank-sum):**
    - Hâ‚€: As distribuiÃ§Ãµes dos dois grupos sÃ£o iguais
    - Hâ‚: As distribuiÃ§Ãµes dos dois grupos sÃ£o diferentes
  - **Pareado (Wilcoxon signed-rank):**
    - Hâ‚€: A distribuiÃ§Ã£o das diferenÃ§as entre os pares Ã© simÃ©trica em torno de zero
    - Hâ‚: A distribuiÃ§Ã£o das diferenÃ§as entre os pares nÃ£o Ã© simÃ©trica em torno de zero
  
Na comparaÃ§Ã£o entre **dois grupos**, tanto nos testes paramÃ©tricos quanto nos nÃ£o paramÃ©tricos, a hipÃ³tese nula (Hâ‚€) geralmente afirma que as mÃ©dias (ou distribuiÃ§Ãµes) dos dois grupos sÃ£o iguais, enquanto a hipÃ³tese alternativa (Hâ‚) aponta que elas sÃ£o diferentes. Ou seja, o teste busca identificar uma diferenÃ§a especÃ­fica entre os dois grupos analisados.

## HipÃ³teses para a comparaÃ§Ã£o entre mais de dois grupos

- **ParamÃ©trico (ANOVA)**
  - **NÃ£o pareado (ANOVA one-way):**
    - Hâ‚€: As mÃ©dias dos grupos sÃ£o todas iguais (Î¼â‚ = Î¼â‚‚ = ... = Î¼_k)
    - Hâ‚: Pelo menos uma mÃ©dia de grupo Ã© diferente das outras
  - **Pareado (ANOVA de medidas repetidas):**
    - Hâ‚€: As mÃ©dias dos tratamentos (ou condiÃ§Ãµes) sÃ£o iguais
    - Hâ‚: Pelo menos uma mÃ©dia de tratamento Ã© diferente das outras

- **NÃ£o paramÃ©trico**
  - **NÃ£o pareado (Kruskal-Wallis):**
    - Hâ‚€: As distribuiÃ§Ãµes dos grupos sÃ£o todas iguais
    - Hâ‚: Pelo menos uma distribuiÃ§Ã£o de grupo Ã© diferente das outras
  - **Pareado (Friedman):**
    - Hâ‚€: As distribuiÃ§Ãµes dos tratamentos (ou condiÃ§Ãµes) sÃ£o todas iguais
    - Hâ‚: Pelo menos uma distribuiÃ§Ã£o de tratamento Ã© diferente das outras
    
Na comparaÃ§Ã£o entre **mais de dois grupos** (por exemplo, usando ANOVA ou Kruskal-Wallis), a hipÃ³tese nula (Hâ‚€) Ã© que **todas** as mÃ©dias (ou distribuiÃ§Ãµes) dos grupos sÃ£o iguais. Por outro lado, a hipÃ³tese alternativa (Hâ‚) nÃ£o especifica qual grupo Ã© diferente, mas sim que **pelo menos um dos grupos se difere dos demais**. Ou seja, a rejeiÃ§Ã£o da hipÃ³tese nula indica que existe pelo menos uma diferenÃ§a, mas nÃ£o revela imediatamente entre quais grupos essa diferenÃ§a ocorre.

> **AtenÃ§Ã£o:** Ã‰ importante notar que, no contexto de mais de dois grupos, a hipÃ³tese alternativa nÃ£o identifica quais grupos sÃ£o diferentes, apenas aponta que existe pelo menos uma diferenÃ§a.

## Testes ParamÃ©tricos

- **NÃ£o Pareados:**  O teste mais utilizado Ã© a **ANOVA de uma via**, que compara as mÃ©dias de trÃªs ou mais grupos independentes.
- **Pareados:** Utiliza-se a **ANOVA para medidas repetidas** quando as mediÃ§Ãµes sÃ£o feitas nos mesmos indivÃ­duos em diferentes condiÃ§Ãµes ou tempos.

### PrÃ©-requisitos para ANOVA (dados pareados ou nÃ£o)

1. **Normalidade dos resÃ­duos:** Os resÃ­duos do modelo devem seguir uma distribuiÃ§Ã£o normal.
2. **Homogeneidade de variÃ¢ncias:** As variÃ¢ncias dos grupos devem ser semelhantes.
3. **Esfericidade** (apenas para medidas repetidas): A variÃ¢ncia das diferenÃ§as entre todas as combinaÃ§Ãµes de pares de grupos deve ser semelhante.
4. **IndependÃªncia das observaÃ§Ãµes:** Para grupos independentes.

Se algum desses prÃ©-requisitos nÃ£o for atendido, Ã© recomendado utilizar testes nÃ£o paramÃ©tricos.

## Testes NÃ£o ParamÃ©tricos

- **NÃ£o Pareados:** O teste de **Kruskal-Wallis** Ã© utilizado para comparar mais de dois grupos independentes.
- **Pareados:** O teste de **Friedman** Ã© usado para comparar trÃªs ou mais grupos pareados.


## ANOVA de uma via no R

A seguir, apresentamos um exemplo de ANOVA de uma via e do teste de Kruskal-Wallis, incluindo a verificaÃ§Ã£o dos prÃ©-requisitos.

### SimulaÃ§Ã£o de Dados

```{r dadosAnovatest, message=FALSE,  warning=FALSE}
set.seed(123)
grupo <- factor(rep(c("A", "B", "C"), each = 10))
valor <- c(rnorm(10, mean = 5, sd = 1),
           rnorm(10, mean = 6, sd = 1),
           rnorm(10, mean = 7, sd = 1))
dados <- data.frame(grupo, valor)
```

### VisualizaÃ§Ã£o dos Dados

```{r boxplotAnovabp, message=FALSE,  warning=FALSE}
boxplot(valor ~ grupo, data = dados, main = "Boxplot dos Grupos", ylab = "Valor")
```

### VerificaÃ§Ã£o dos PrÃ©-requisitos para ANOVA

#### Normalidade dos resÃ­duos

```{r residuosAnovatest, message=FALSE,  warning=FALSE}
modelo_aov <- aov(valor ~ grupo, data = dados)
residuos <- residuals(modelo_aov)

shapiro.test(residuos)
qqnorm(residuos)
qqline(residuos)
```

- A funÃ§Ã£o `aov` no R Ã© utilizada para realizar **anÃ¡lise de variÃ¢ncia (ANOVA)**.

- **modelo_aov <- aov(valor ~ grupo, data = dados)**  
  Esta linha ajusta um modelo de ANOVA de uma via, avaliando se a mÃ©dia da variÃ¡vel `valor` difere entre os diferentes nÃ­veis do fator `grupo`, usando os dados do data frame `dados`.

- **residuos <- residuals(modelo_aov)**  
  Esta linha extrai os resÃ­duos do modelo ajustado, ou seja, as diferenÃ§as entre os valores observados e os valores previstos pelo modelo. A anÃ¡lise dos resÃ­duos Ã© fundamental para verificar os pressupostos da ANOVA, como a normalidade.
  
> Neste exemplo, tanto o teste de normalidade quanto a inspeÃ§Ã£o visual do grÃ¡fico QQ sugerem que os resÃ­duos seguem uma distribuiÃ§Ã£o normal.

#### Homogeneidade de variÃ¢ncias

```{r leveneAnovatest, message=FALSE,  warning=FALSE}
# Instale 'car' se necessÃ¡rio: install.packages("car")
library(car)
leveneTest(valor ~ grupo, data = dados)
```

- O *teste de Levene* avalia a homogeneidade das variÃ¢ncias entre os grupos, que Ã© um dos prÃ©-requisitos para a ANOVA.

- **Valor de p (Pr(>F)) = 0.9995:** O valor de p Ã© muito maior que 0,05, indicando que **nÃ£o hÃ¡ evidÃªncias para rejeitar a hipÃ³tese nula de igualdade das variÃ¢ncias**.

> Nesse exemplo, as variÃ¢ncias dos grupos podem ser consideradas homogÃªneas. Portanto, o prÃ©-requisito de homogeneidade de variÃ¢ncias para a ANOVA foi atendido.

### ANOVA de Uma Via

```{r Anovatest, message=FALSE,  warning=FALSE}
summary(modelo_aov)
```

- **Valor de p (Pr(>F)) = 0.00518:** O valor de p Ã© menor que 0,05, indicando que existem diferenÃ§as estatisticamente significativas entre as mÃ©dias dos grupos analisados.

- Rejeita-se a hipÃ³tese nula de igualdade das mÃ©dias. Isso significa que pelo menos um dos grupos difere significativamente dos demais. Recomenda-se realizar *testes post hoc (por exemplo, Tukey)* para identificar quais grupos apresentam diferenÃ§as entre si.

#### Teste Post Hoc (se ANOVA for significativa)

```{r TukeyHSDtest, message=FALSE,  warning=FALSE}
TukeyHSD(modelo_aov)
```

O teste de Tukey compara as mÃ©dias dos grupos dois a dois, apÃ³s a ANOVA indicar diferenÃ§a significativa entre eles. Os resultados mostram as diferenÃ§as entre as mÃ©dias dos grupos (`diff`), os limites inferior (`lwr`) e superior (`upr`) do intervalo de confianÃ§a de 95%, e o valor de p ajustado (`p adj`).

**Resultados:**

- **B vs A:**  
  DiferenÃ§a = 1.13; IC 95% = [0.05, 2.22]; p = 0.038  
  â†’ O grupo B tem mÃ©dia significativamente maior que o grupo A.

- **C vs A:**  
  DiferenÃ§a = 1.50; IC 95% = [0.42, 2.58]; p = 0.005  
  â†’ O grupo C tem mÃ©dia significativamente maior que o grupo A.

- **C vs B:**  
  DiferenÃ§a = 0.37; IC 95% = [-0.71, 1.45]; p = 0.681  
  â†’ NÃ£o hÃ¡ diferenÃ§a significativa entre os grupos C e B.

> Os grupos B e C apresentam mÃ©dias significativamente maiores do que o grupo A. NÃ£o foi observada diferenÃ§a significativa entre os grupos B e C.

## Kruskal-Wallis no R

Se os prÃ©-requisitos da ANOVA nÃ£o forem atendidos, utilize o Kruskal-Wallis:

```{r KWtest, message=FALSE,  warning=FALSE}
kruskal.test(valor ~ grupo, data = dados)
```

- **Valor de p (p-value) = 0.01669:** O valor de p Ã© menor que 0,05, indicando que hÃ¡ diferenÃ§a estatisticamente significativa entre pelo menos dois dos grupos analisados.

- Rejeita-se a hipÃ³tese nula de que as distribuiÃ§Ãµes dos grupos sÃ£o todas iguais. Ou seja, pelo menos um dos grupos apresenta distribuiÃ§Ã£o diferente dos demais. Para identificar especificamente quais grupos diferem entre si, Ã© recomendada a realizaÃ§Ã£o de testes post hoc apropriados (por exemplo, Dunn ou pairwise Wilcoxon com ajuste para mÃºltiplas comparaÃ§Ãµes).
  
### Teste Post Hoc para Kruskal-Wallis

```{r KWphtest, message=FALSE,  warning=FALSE}
# Instale PMCMRplus se necessÃ¡rio: install.packages("PMCMRplus")
library(PMCMRplus)
kwAllPairsDunnTest(valor ~ grupo, data = dados)
```

O teste de Dunn Ã© um teste pÃ³s-hoc nÃ£o-paramÃ©trico, utilizado apÃ³s o teste de Kruskal-Wallis para identificar quais pares de grupos diferem significativamente entre si.

Os _p-valores_ apresentados pelo teste compara todos os pares possÃ­veis entre os grupos (neste exemplo: A, B e C):

- **A vs. B**: p = 0.058
- **A vs. C**: p = 0.021
- **B vs. C**: p = 0.611

> Portanto, os resultados sugerem que apenas os grupos A e C, para a variÃ¡vel analisada, sÃ£o estatisticamente diferentes entre si.

## Por que nÃ£o Ã© indicado comparar os grupos dois a dois diretamente?

Quando se tem mais de dois grupos, pode parecer tentador realizar mÃºltiplos testes de comparaÃ§Ã£o entre pares de grupos (por exemplo, vÃ¡rios testes t para todos os pares possÃ­veis). No entanto, esse procedimento **nÃ£o Ã© recomendado**, pois aumenta significativamente o risco de cometer um **erro do tipo I** (falso positivo).

Cada teste realizado tem uma determinada probabilidade de indicar uma diferenÃ§a por acaso (erro tipo I), geralmente 5% se Î± = 0,05. Ao fazer muitos testes independentes, a probabilidade de encontrar pelo menos um resultado "significativo" apenas por acaso aumenta. Esse fenÃ´meno Ã© chamado de **inflacionamento da taxa de erro tipo I**.

Por isso, para comparaÃ§Ã£o de mais de dois grupos, utiliza-se primeiro um teste global (como ANOVA ou Kruskal-Wallis). Se o resultado for significativo, aÃ­ sim sÃ£o realizados testes post hoc, que jÃ¡ incluem correÃ§Ãµes para mÃºltiplas comparaÃ§Ãµes (como o teste de Tukey), controlando o risco de erro tipo I.


## ANOVA para Dados Repetidos no R

Vamos analisar o desempenho de 6 alunos em 3 provas diferentes (Prova 1, Prova 2 e Prova 3). Cada aluno fez todas as provas, ou seja, temos medidas repetidas!

### Gerar dados simulados

```{r AnovaRtest, message=FALSE,  warning=FALSE}
set.seed(123)
n <- 20
dados <- data.frame(
  aluno = factor(1:n),
  prova1 = round(rnorm(n, mean = 7, sd = 1), 1),
  prova2 = round(rnorm(n, mean = 7.5, sd = 1), 1),
  prova3 = round(rnorm(n, mean = 8, sd = 1), 1)
)
head(dados)
```

### Converter para formato longo

```{r AnovaRltest, message=FALSE,  warning=FALSE}
library(tidyr)
dados_long <- pivot_longer(
  dados,
  cols = c("prova1", "prova2", "prova3"),
  names_to = "prova",
  values_to = "nota"
)
head(dados_long)
```

> Transformar os dados para o formato longo Ã© fundamental para anÃ¡lises de medidas repetidas porque permite que o R identifique corretamente as repetiÃ§Ãµes de cada aluno ao longo das diferentes provas. Sem isso, nÃ£o Ã© possÃ­vel fazer ANOVA de medidas repetidas de forma adequada!

### VisualizaÃ§Ã£o (opcional)

```{r AnovaRgtest, message=FALSE,  warning=FALSE}
library(ggplot2)
library(RColorBrewer)

# Use uma paleta de cores apropriada para atÃ© 20 alunos
cores <- colorRampPalette(brewer.pal(9, "Set1"))(20)

ggplot(dados_long, aes(x = prova, y = nota, group = aluno, color = aluno)) +
  geom_line(alpha = 0.7, size = 1) +
  geom_point(size = 2) +
  labs(x = "AvaliaÃ§Ãµes", y = "PontuaÃ§Ã£o") +
  scale_color_manual(values = cores) +
  labs(title = "Notas dos Alunos nas TrÃªs Provas", color = "Aluno") +
  theme_minimal() +
  theme(legend.position = "right")
```


### Teste de normalidade das diferenÃ§as (prÃ©-requisito)

```{r AnovaRnormtest, message=FALSE,  warning=FALSE}
dif12 <- dados$prova1 - dados$prova2
dif13 <- dados$prova1 - dados$prova3
dif23 <- dados$prova2 - dados$prova3

qqnorm(dif12)
qqline(dif12)
shapiro.test(dif12)

qqnorm(dif13)
qqline(dif13)
shapiro.test(dif13)

qqnorm(dif23)
qqline(dif23)
shapiro.test(dif23)
```

> As diferenÃ§as seguem distribuiÃ§Ã£o normal.

### ANOVA de medidas repetidas com afex (testa e corrige esfericidade)

A funÃ§Ã£o `aov_ez()`, do pacote `afex` realiza toda a ANOVA de medidas repetidas de forma prÃ¡tica e automÃ¡tica.

```{r AnovaRetest, message=FALSE,  warning=FALSE}
# Instale se necessÃ¡rio: install.packages("afex")
library(afex)
modelo_afex <- aov_ez(
  id = "aluno",
  dv = "nota",
  within = "prova",
  data = dados_long
)
modelo_afex
```

- **Effect**: O fator analisado (`prova`), ou seja, se as notas variam entre as provas.
- **df**: Graus de liberdade. Note que aparecem valores decimais (1.91, 36.27) porque foi aplicada a correÃ§Ã£o de Greenhouse-Geisser (GG), devido Ã  violaÃ§Ã£o da esfericidade.
- **MSE**: Erro quadrÃ¡tico mÃ©dio.
- **F**: EstatÃ­stica F da ANOVA.
- **ges**: Generalized Eta Squared, uma medida de tamanho de efeito.
- **p.value**: Valor de p associado ao teste F. Neste caso, p = 0.009 indica que hÃ¡ diferenÃ§a significativa entre as mÃ©dias das provas (p < 0.05).
- **ObservaÃ§Ã£o sobre esfericidade:** A linha `Sphericity correction method: GG` informa que o pressuposto de esfericidade foi violado (teste de Mauchly p < 0.05) e, por isso, os graus de liberdade e o valor de p foram corrigidos automaticamente pelo mÃ©todo de Greenhouse-Geisser.

> A anÃ¡lise de variÃ¢ncia (ANOVA) mostrou que o fator "prova" teve um efeito significativo sobre as notas (F(1.91, 36.27) = 5.53, p = 0.009, ges = 0.168), indicando que as mÃ©dias das notas diferem entre as provas.

### PÃ³s-hoc: ComparaÃ§Ãµes mÃºltiplas entre as provas

```{r AnovaRphtest, message=FALSE,  warning=FALSE}
# Instale se necessÃ¡rio: install.packages("emmeans")
library(emmeans)
emm <- emmeans(modelo_afex, ~ prova)
pairs(emm, adjust = "bonferroni") # ou "holm", "sidak", etc.
```

- **prova1 vs prova2:** NÃ£o hÃ¡ diferenÃ§a significativa (p = 0.9212).
- **prova1 vs prova3:** DiferenÃ§a significativa (p = 0.0225). As mÃ©dias dessas provas sÃ£o estatisticamente diferentes.
- **prova2 vs prova3:** NÃ£o hÃ¡ diferenÃ§a significativa (p = 0.0717).

> A anÃ¡lise revelou que existe diferenÃ§a significativa nas notas entre as provas. Especificamente, a Ãºnica diferenÃ§a significativa foi entre as provas 1 e 3, indicando que as mÃ©dias dessas avaliaÃ§Ãµes diferem estatisticamente. Entre as demais provas, nÃ£o foram observadas diferenÃ§as significativas apÃ³s o ajuste de Bonferroni.

 
## Teste de Friedman

```{r Friedmantest, message=FALSE,  warning=FALSE}
# O teste de Friedman compara as trÃªs provas considerando a repetiÃ§Ã£o por aluno
friedman.test(as.matrix(dados[, c("prova1", "prova2", "prova3")]))
```

### PÃ³s-teste: ComparaÃ§Ãµes MÃºltiplas (Wilcoxon pareado)

```{r Friedmanphtest, message=FALSE,  warning=FALSE}
pairwise.wilcox.test(
  dados_long$nota,
  dados_long$prova,
  paired = TRUE,
  p.adjust.method = "bonferroni"
)
```

ApÃ³s o teste de Friedman indicar que hÃ¡ diferenÃ§a nas notas das provas, fazemos um pÃ³s-teste para descobrir entre quais provas hÃ¡ diferenÃ§a.

- Apenas **entre Prova 1 e Prova 3 existe diferenÃ§a significativa** (0.033 < 0.05).
- Entre Prova 1 e 2, e entre Prova 2 e 3, nÃ£o hÃ¡ diferenÃ§a significativa (valores maiores que 0.05).

<!--chapter:end:19-Comparacao-mais-de-2grupos.Rmd-->

# CorrelaÃ§Ã£o entre variÃ¡veis

A correlaÃ§Ã£o Ã© uma forma de medir o grau de relaÃ§Ã£o entre duas variÃ¡veis. Quando duas variÃ¡veis estÃ£o correlacionadas, significa que podemos esperar que, ao mudar uma delas, a outra tambÃ©m sofra alguma alteraÃ§Ã£o. Se ambas aumentam juntas, dizemos que a correlaÃ§Ã£o Ã© positiva; se uma aumenta enquanto a outra diminui, a correlaÃ§Ã£o Ã© negativa.

Ã‰ importante destacar que a correlaÃ§Ã£o indica apenas que as variÃ¡veis variam juntas, mas nÃ£o prova que uma causa a mudanÃ§a na outra. Outros fatores podem estar influenciando essa relaÃ§Ã£o, ou pode ser apenas uma coincidÃªncia. Por isso, correlaÃ§Ã£o mostra como as variÃ¡veis estÃ£o relacionadas, mas nÃ£o estabelece uma relaÃ§Ã£o de causa e efeito.


> Na medicina, um exemplo clÃ¡ssico Ã© investigar a correlaÃ§Ã£o entre o Ã­ndice de massa corporal (IMC) e a pressÃ£o arterial sistÃ³lica. Pesquisadores podem avaliar se pessoas com IMC mais elevado tendem a ter pressÃ£o arterial mais alta, o que ajuda a entender riscos cardiovasculares.

> Na psicologia, pode-se analisar a correlaÃ§Ã£o entre a pontuaÃ§Ã£o em uma escala de ansiedade (por exemplo, a pontuaÃ§Ã£o total em um questionÃ¡rio) e o nÃºmero de horas de sono por noite. Essa relaÃ§Ã£o ajuda a compreender como o sono influencia o nÃ­vel de ansiedade.

> Na educaÃ§Ã£o fÃ­sica, um exemplo Ã© estudar a correlaÃ§Ã£o entre o tempo gasto em atividade fÃ­sica semanal (em horas) e a porcentagem de gordura corporal. Isso auxilia na avaliaÃ§Ã£o do impacto do exercÃ­cio sobre a composiÃ§Ã£o corporal.

## Tipos de VariÃ¡veis
Para analisar correlaÃ§Ã£o, usamos variÃ¡veis numÃ©ricas (quantitativas ou qualitativas ordinais).

## Diagrama de DispersÃ£o
O diagrama de dispersÃ£o Ã© um grÃ¡fico que permite visualizar a relaÃ§Ã£o entre duas variÃ¡veis. A seguir, exemplos de diferentes padrÃµes de correlaÃ§Ã£o:

```{r exemplo-correlacoes, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(2025)
df_cor <- data.frame(
  x = rnorm(100)
)
df_cor$y_pos_forte <- df_cor$x + rnorm(100, 0, 0.3)
df_cor$y_neg_forte <- -df_cor$x + rnorm(100, 0, 0.3)
df_cor$y_moderada <- 0.5*df_cor$x + rnorm(100, 0, 0.7)
df_cor$y_fraca <- df_cor$x + rnorm(100, 0, 3)
df_cor$y_sem <- rnorm(100,0,10)
df_cor$y_nlinear <- (df_cor$x)^2 + rnorm(100)

par(mfrow = c(2, 3), mgp = c(1.1, 0.1, 0)) # mgp aproxima xlab/ylab do grÃ¡fico

plot(df_cor$x, df_cor$y_pos_forte, 
     main = "CorrelaÃ§Ã£o Positiva Forte", 
     xlab = expression("variÃ¡vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("variÃ¡vel 2" ~ "\u2192"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_moderada, 
     main = "CorrelaÃ§Ã£o Positiva Moderada", 
     xlab = expression("variÃ¡vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("variÃ¡vel 2" ~ "\u2192"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_fraca, 
     main = "CorrelaÃ§Ã£o Positiva Fraca", 
     xlab = expression("variÃ¡vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("variÃ¡vel 2" ~ "\u2192"), # seta para a direita 
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_neg_forte, 
     main = "CorrelaÃ§Ã£o Negativa Forte", 
     xlab = expression("variÃ¡vel 1" ~ "\u2192"), # seta para a direita
     ylab = expression("variÃ¡vel 2" ~ "\u2190"), # seta para a esquerda
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_sem, 
     main = "Sem CorrelaÃ§Ã£o", 
     xlab = expression("variÃ¡vel 1"), # seta para a direita
     ylab = expression("variÃ¡vel 2"), # seta para a direita
     xaxt = "n", yaxt = "n")

plot(df_cor$x, df_cor$y_nlinear, 
     main = "CorrelaÃ§Ã£o NÃ£o Linear", 
     xlab = expression("variÃ¡vel 1"), # seta para a direita
     ylab = expression("variÃ¡vel 2"), # seta para a direita 
     xaxt = "n", yaxt = "n")
```

Para criar um grÃ¡fico de dispersÃ£o no R, vocÃª pode usar a funÃ§Ã£o `plot()`. Os argumentos bÃ¡sicos que vocÃª deve fornecer entre os parÃªnteses sÃ£o:

- "x": um vetor numÃ©rico com os valores do eixo x (variÃ¡vel independente).
- "y": um vetor numÃ©rico com os valores do eixo y (variÃ¡vel dependente).

> Ou seja, algo como: `plot(x,y)`  

## Coeficientes de CorrelaÃ§Ã£o

Existem diferentes mÃ©todos para medir a correlaÃ§Ã£o entre variÃ¡veis, cada um adequado a tipos especÃ­ficos de dados e relaÃ§Ãµes. Os trÃªs tipos mais comuns sÃ£o: a **correlaÃ§Ã£o de Pearson**, que avalia a relaÃ§Ã£o linear entre variÃ¡veis numÃ©ricas contÃ­nuas; a **correlaÃ§Ã£o de Spearman**, que mede associaÃ§Ãµes monotÃ´nicas usando postos, sendo indicada para dados ordinais ou quando a relaÃ§Ã£o nÃ£o Ã© estritamente linear; e a **correlaÃ§Ã£o de Kendall**, tambÃ©m baseada em postos, que Ã© especialmente Ãºtil em amostras pequenas ou com muitos empates nos dados. Conhecer essas diferenÃ§as Ã© fundamental para escolher o mÃ©todo mais apropriado em cada situaÃ§Ã£o.

### Coeficiente de CorrelaÃ§Ã£o de Pearson

O coeficiente de correlaÃ§Ã£o de **Pearson** ($r$) Ã© utilizado quando se deseja avaliar a relaÃ§Ã£o linear entre duas variÃ¡veis quantitativas contÃ­nuas. Ele pressupÃµe que os dados de ambas as variÃ¡veis seguem uma **distribuiÃ§Ã£o normal** (ou aproximadamente normal) e que a relaÃ§Ã£o entre elas Ã© linear, ou seja, uma linha reta pode descrever bem o padrÃ£o dos dados em um grÃ¡fico de dispersÃ£o. Ã‰ sensÃ­vel a outliers.

### Coeficiente de CorrelaÃ§Ã£o de Spearman

O coeficiente de **Spearman** ($\rho$) avalia a forÃ§a e a direÃ§Ã£o da associaÃ§Ã£o entre duas variÃ¡veis com base em seus **ranks** (postos) em vez dos valores originais. Ele Ã© indicado quando a relaÃ§Ã£o entre as variÃ¡veis Ã© **monotÃ´nica**, ou seja, conforme uma variÃ¡vel aumenta, a outra tambÃ©m aumenta ou diminui, mas nÃ£o necessariamente de maneira linear. O Spearman Ã© apropriado para dados que nÃ£o seguem a normalidade ou para situaÃ§Ãµes em que a relaÃ§Ã£o nÃ£o pode ser descrita por uma linha reta. AlÃ©m disso, Ã© menos sensÃ­vel a outliers do que o Pearson.


### Coeficiente de CorrelaÃ§Ã£o de Kendall

O coeficiente de **Kendall** ($\tau$) tambÃ©m se baseia nos postos dos dados, sendo utilizado para medir a forÃ§a da associaÃ§Ã£o entre duas variÃ¡veis. Ã‰ especialmente Ãºtil em situaÃ§Ãµes com **pequenas amostras** ou quando hÃ¡ muitos **empates** nos valores dos dados (valores iguais). Assim como o Spearman, o Kendall nÃ£o exige normalidade dos dados e Ã© apropriado para relaÃ§Ãµes monotÃ´nicas. Em geral, o tau de Kendall Ã© visto como mais robusto em amostras pequenas ou com muitos empates.

### InterpretaÃ§Ã£o dos Coeficientes

O valor a correlaÃ§Ã£o varia de -1 (correlaÃ§Ã£o negativa perfeita) a +1 (correlaÃ§Ã£o positiva perfeita), sendo 0 a ausÃªncia de correlaÃ§Ã£o linear. 

| Faixa de valores     | InterpretaÃ§Ã£o    |
|:-------------------------:|:-------------:|
| 0,00 â€“ 0,10          | DesprezÃ­vel      |
| 0,10 â€“ 0,30          | Fraca            |
| 0,30 â€“ 0,50          | Moderada         |
| 0,50 â€“ 0,70          | Forte            |
| 0,70 â€“ 1,00          | Muito forte      |

### Exemplo no R

Vamos supor que temos os dados de 18 alunos: a quantidade de aulas frequentadas (de um total de 20) e suas notas finais na disciplina de EstatÃ­stica (de 0 a 10).

```{r}
# Vetor de presenÃ§as (nÃºmero de aulas frequentadas)
presencas <- c(20, 18, 17, 19, 15, 16, 20, 18, 17, 19, 14, 15, 12, 16, 20, 13, 17, 18)

# Vetor de notas finais em EstatÃ­stica
notas <- c(9.8, 9.0, 8.5, 9.5, 7.0, 7.5, 10.0, 8.7, 8.0, 9.2, 6.5, 7.2, 5.0, 7.8, 9.7, 6.0, 8.2, 8.8)
```

```{r correlation-matrix}
# Para calcular o r de Pearson
cor(presencas, notas, method = "pearson")
# Para calcular o rho de Spearman
cor(presencas, notas, method = "spearman")
# Para calular o tau de Kendall
cor(presencas, notas, method = "kendall")

# Dica: dÃ¡ para abreviar o nome de cada mÃ©todo
# Para calcular o r de Pearson
cor(presencas, notas, method = "p")
# Para calcular o rho de Spearman
cor(presencas, notas, method = "s")
#para calular o tau de Kendall
cor(presencas, notas, method = "k")

```

## Testes de CorrelaÃ§Ã£o

### Pearson
- H0: $r = 0$ (nÃ£o hÃ¡ correlaÃ§Ã£o linear entre as variÃ¡veis "x" e "y")
- H1: $r \neq 0$ (existe correlaÃ§Ã£o)
```{r pearson-test}
cor.test(presencas, notas, method = "pearson")
```

O teste de correlaÃ§Ã£o de Pearson realizado entre as variÃ¡veis `presencas` e `notas` apresentou os seguintes resultados:

- **t = 32.615**:  
  Este Ã© o valor do teste t calculado, que indica uma diferenÃ§a extremamente significativa entre a correlaÃ§Ã£o observada e a hipÃ³tese nula (correlaÃ§Ã£o igual a zero). Quanto maior o valor de t, maior a evidÃªncia contra a hipÃ³tese nula.

- **df = 16**:  
  Refere-se aos graus de liberdade do teste, calculados por (n - 2), onde n Ã© o nÃºmero de pares de dados analisados. Neste caso, indica que havia 18 observaÃ§Ãµes.

- **p-value = 4.597e-16**:  
  O valor-p extremamente baixo mostra que a probabilidade de obter uma correlaÃ§Ã£o tÃ£o forte por acaso Ã© praticamente nula. Portanto, a correlaÃ§Ã£o Ã© estatisticamente significativa.

- **alternative hypothesis: true correlation is not equal to 0**:  
  A hipÃ³tese alternativa testada Ã© de que existe alguma correlaÃ§Ã£o (positiva ou negativa) diferente de zero entre as variÃ¡veis.

- **95 percent confidence interval: 0.9796700 a 0.9972906**:  
  O intervalo de confianÃ§a indica que, com 95% de certeza, o valor real da correlaÃ§Ã£o populacional entre `presencas` e `notas` estÃ¡ entre aproximadamente 0,98 e 0,997. Isso Ã© considerado uma correlaÃ§Ã£o extremamente forte.

- **sample estimates: cor = 0.992563**:  
  O coeficiente de correlaÃ§Ã£o de Pearson ($r$) observado foi de 0,99, indicando uma relaÃ§Ã£o positiva, muito forte e praticamente perfeita: quanto maior o nÃºmero de presenÃ§as, maior tende a ser a nota.

**Resumo:**  
Os resultados mostram uma associaÃ§Ã£o positiva fortÃ­ssima e estatisticamente significativa entre presenÃ§as e notas, sugerindo que alunos que frequentam mais tendem a obter notas mais altas.

### Spearman
- H0: $\rho = 0$ (nÃ£o hÃ¡ correlaÃ§Ã£o entre as variÃ¡veis "x" e "y")
- H1: $\rho \neq 0$ (existe correlaÃ§Ã£o)
```{r spearman-test, warning=FALSE}
cor.test(presencas, notas, method = "spearman")
```

O teste de correlaÃ§Ã£o de Spearman realizado entre as variÃ¡veis `presencas` e `notas` apresentou os seguintes resultados:

- **S = 7.5293**:  
  Este Ã© o valor da estatÃ­stica de teste S, usada no cÃ¡lculo da correlaÃ§Ã£o de Spearman. Ele reflete as diferenÃ§as nas posiÃ§Ãµes (ranks) entre as duas variÃ¡veis analisadas.

- **p-value = 6.52e-16**:  
  O valor-p extremamente baixo indica que a probabilidade de observar uma correlaÃ§Ã£o tÃ£o alta por acaso, caso nÃ£o exista correlaÃ§Ã£o real, Ã© praticamente nula. Portanto, a correlaÃ§Ã£o encontrada Ã© estatisticamente significativa.

- **alternative hypothesis: true rho is not equal to 0**:  
  A hipÃ³tese alternativa do teste Ã© de que o coeficiente de Spearman ($\rho$) Ã© diferente de zero, ou seja, existe uma associaÃ§Ã£o monotÃ´nica entre as variÃ¡veis.

- **sample estimates: rho = 0.9922299**:  
  O coeficiente de correlaÃ§Ã£o de Spearman observado foi de 0,99, indicando uma relaÃ§Ã£o positiva, extremamente forte, entre `presencas` e `notas`. Isso significa que, Ã  medida que o nÃºmero de presenÃ§as aumenta, as notas tendem a aumentar de forma consistente, mesmo que a relaÃ§Ã£o nÃ£o seja perfeitamente linear.

**Resumo:**  
Os resultados demonstram uma associaÃ§Ã£o positiva e muito forte entre presenÃ§as e notas, estatisticamente significativa. Isso sugere que alunos com mais presenÃ§as tendem a obter notas mais altas, mesmo considerando possÃ­veis variaÃ§Ãµes nÃ£o lineares na relaÃ§Ã£o entre as variÃ¡veis.

### Kendall
- H0: $\tau = 0$ (nÃ£o hÃ¡ correlaÃ§Ã£o entre as variÃ¡veis "x" e "y")
- H1: $\tau \neq 0$ (existe correlaÃ§Ã£o)
```{r kendall-test, warning=FALSE }
cor.test(presencas, notas, method = "kendall")
```

O teste de correlaÃ§Ã£o de Kendall realizado entre as variÃ¡veis `presencas` e `notas` apresentou os seguintes resultados:

- **z = 5.3952**:  
  Este Ã© o valor da estatÃ­stica z calculado para o teste de Kendall. Valores de z elevados indicam forte evidÃªncia contra a hipÃ³tese nula de ausÃªncia de associaÃ§Ã£o entre as variÃ¡veis.

- **p-value = 6.844e-08**:  
  O valor-p extremamente baixo indica que a probabilidade de obter uma correlaÃ§Ã£o tÃ£o alta por acaso Ã© praticamente nula. Portanto, a associaÃ§Ã£o observada entre as variÃ¡veis Ã© estatisticamente significativa.

- **alternative hypothesis: true tau is not equal to 0**:  
  A hipÃ³tese alternativa do teste Ã© de que o coeficiente de Kendall ($\tau$) Ã© diferente de zero, ou seja, existe uma associaÃ§Ã£o monotÃ´nica entre as variÃ¡veis.

- **sample estimates: tau = 0.9599837**:  
  O coeficiente de correlaÃ§Ã£o de Kendall ($\tau$) encontrado foi de 0,96, indicando uma associaÃ§Ã£o positiva, muito forte, entre `presencas` e `notas`. Isso significa que, Ã  medida que o nÃºmero de presenÃ§as aumenta, as notas tambÃ©m tendem a aumentar de forma consistente, mesmo considerando possÃ­veis empates (valores iguais) entre as observaÃ§Ãµes.

**Resumo:**  
Os resultados mostram uma associaÃ§Ã£o positiva e extremamente forte entre presenÃ§as e notas, estatisticamente significativa. Isso sugere que alunos com mais presenÃ§as tendem a obter notas mais altas, mesmo considerando a ordem dos dados e possÃ­veis empates nas avaliaÃ§Ãµes.

## Tamanho do Efeito (Effect Size)

Em estudos de correlaÃ§Ã£o, o **tamanho do efeito** Ã© representado pelo valor absoluto do coeficiente de correlaÃ§Ã£o (por exemplo, Pearson, Spearman ou Kendall). Isso significa que consideramos apenas a intensidade da relaÃ§Ã£o entre as variÃ¡veis, independentemente de ser positiva ou negativa.

Por exemplo, tanto um coeficiente de +0,65 quanto de -0,65 indicam um tamanho de efeito de 0,65. Quanto mais prÃ³ximo de 1 (ou -1), mais forte Ã© a correlaÃ§Ã£o; quanto mais prÃ³ximo de 0, mais fraca.

## CÃ¡lculo do Tamanho da Amostra e Poder EstatÃ­stico

### Exemplo com `pwr`
Calcular o tamanho da amostra necessÃ¡rio para detectar uma correlaÃ§Ã£o de 0,4 com poder de 80% e Î± = 0,05:

```{r power-analysis, message=FALSE, warning=FALSE}
library(pwr)
pwr.r.test(r = 0.4, power = 0.8, sig.level = 0.05, alternative = "two.sided")
```

### Verificar o poder para uma amostra de tamanho 30:

```{r power-given-n}
pwr.r.test(n = 30, r = 0.4, sig.level = 0.05, alternative = "two.sided")
```

## Outros recursos 

```{r setup2, include=FALSE}
# Instalar pacotes, se necessÃ¡rio:
# install.packages(c("tidyverse", "GGally"))
library(tidyverse)
library(GGally)
```
Para explorar um pouco mais o estudo de correlaÃ§Ã£o, vamos usar o banco de dados `iris`, que jÃ¡ vem instalado por padrÃ£o no R.

O dataset `iris` Ã© um conjunto de dados clÃ¡ssico em estatÃ­stica e aprendizado de mÃ¡quina (*machine learning*). Ele contÃ©m 150 observaÃ§Ãµes de flores de Ã­ris de trÃªs espÃ©cies diferentes: *setosa*, *versicolor* e *virginica*. As variÃ¡veis numÃ©ricas sÃ£o:

- **Sepal.Length:** comprimento da sÃ©pala (em centÃ­metros), a sÃ©pala Ã© a parte externa da flor, que protege os botÃµes florais.

- **Sepal.Width:** largura da sÃ©pala (em centÃ­metros).

- **Petal.Length:** comprimento da pÃ©tala (em centÃ­metros), as pÃ©talas sÃ£o as partes geralmente coloridas da flor.

- **Petal.Width:** largura da pÃ©tala (em centÃ­metros).

Estas medidas sÃ£o Ãºteis para estudar relaÃ§Ãµes entre caracterÃ­sticas morfolÃ³gicas das flores.

### VisualizaÃ§Ã£o com `pairs()`

A funÃ§Ã£o `pairs()` mostra uma matriz de grÃ¡ficos de dispersÃ£o, Ãºtil para observar visualmente correlaÃ§Ãµes entre todas as variÃ¡veis numÃ©ricas.

```{r pairs-plot}
pairs(iris[, 1:4])
```

A funÃ§Ã£o `pairs` no R gera uma matriz de grÃ¡ficos de dispersÃ£o mostrando a relaÃ§Ã£o entre todas as variÃ¡veis numÃ©ricas de um conjunto de dados. Cada grÃ¡fico da matriz compara duas variÃ¡veis diferentes:

- Cada linha e cada coluna representam uma variÃ¡vel.
- Os grÃ¡ficos mostram como cada variÃ¡vel se relaciona com as outras: por exemplo, a relaÃ§Ã£o entre Sepal.Length e Petal.Length.
- Quando os pontos formam uma linha inclinada, isso indica uma correlaÃ§Ã£o (positiva ou negativa) entre as variÃ¡veis.
- Se os pontos estÃ£o espalhados, sem padrÃ£o, indica pouca ou nenhuma relaÃ§Ã£o.
- A diagonal mostra o nome de cada variÃ¡vel.

Assim, ao olhar para a matriz, vocÃª consegue visualizar rapidamente quais variÃ¡veis tÃªm relaÃ§Ã£o entre si e qual Ã© o tipo dessa relaÃ§Ã£o (mais forte, mais fraca, positiva ou negativa).

### Matriz de CorrelaÃ§Ã£o com `cor()`

A funÃ§Ã£o `cor()` calcula a matriz de correlaÃ§Ã£o entre variÃ¡veis numÃ©ricas. A seguir, uma matriz com correlaÃ§Ã£o de Pearson:

```{r cor-matrix}
# use o mÃ©todo adequado method = "pearson";  method = "spearman" ou method = "kendall"
cor(iris[, 1:4], method = "pearson")
```

A matriz de correlaÃ§Ã£o Ã© uma tabela que mostra os coeficientes de correlaÃ§Ã£o entre todas as combinaÃ§Ãµes possÃ­veis de variÃ¡veis numÃ©ricas em um conjunto de dados. Cada valor da matriz indica o grau de associaÃ§Ã£o linear entre um par de variÃ¡veis. A diagonal principal sempre apresenta o valor 1, pois cada variÃ¡vel Ã© perfeitamente correlacionada com ela mesma. Assim, a matriz de correlaÃ§Ã£o permite identificar rapidamente quais variÃ¡veis estÃ£o mais relacionadas entre si, facilitando a anÃ¡lise exploratÃ³ria dos dados. Observe que essa matriz Ã© simÃ©trica


### Matriz Visual com `GGally::ggcorr()`

O `ggcorr()` do pacote `GGally` mostra graficamente os coeficientes de correlaÃ§Ã£o, com intensidade e direÃ§Ã£o representadas por cor.

```{r ggcorr-matrix}
# Instale os pacotes se necessÃ¡rio:
# install.packages("GGally")
# install.packages("ggplot2")

# Matriz de correlaÃ§Ã£o tipo heatmap com valores destacados
ggcorr(
  data = iris[, 1:4],
  method = c("everything", "pearson"), # calcula todas as correlaÃ§Ãµes de Pearson
  label = TRUE,             # mostra os coeficientes nas cÃ©lulas
  label_round = 2,          # arredonda os valores para 2 casas decimais
  label_size = 5,           # tamanho do texto dos coeficientes
  hjust = 0.5,              # centraliza os rÃ³tulos nas cÃ©lulas
  layout.exp = 2,           # expande o tamanho das cÃ©lulas
  low = "#D73027",          # cor para correlaÃ§Ã£o negativa forte
  mid = "white",            # cor para correlaÃ§Ã£o nula
  high = "#3366CC"          # cor para correlaÃ§Ã£o positiva forte
) +
  ggtitle("Matriz de CorrelaÃ§Ã£o de Pearson - iris (Heatmap)") +
  theme_minimal(base_size = 14) + # visual minimalista e tamanho de fonte maior
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # centraliza e destaca o tÃ­tulo
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1) # gira rÃ³tulos do eixo x para melhor leitura
  )
```

A funÃ§Ã£o `ggpairs()` combina histogramas, correlaÃ§Ãµes e grÃ¡ficos de dispersÃ£o em uma visualizaÃ§Ã£o integrada.

Este comando cria uma matriz de grÃ¡ficos que facilita visualizar a distribuiÃ§Ã£o e a relaÃ§Ã£o entre as variÃ¡veis numÃ©ricas do conjunto. Ã‰ muito Ãºtil para identificar padrÃµes, tendÃªncias, outliers e possÃ­veis correlaÃ§Ãµes antes de uma anÃ¡lise estatÃ­stica mais aprofundada.

- **Considerando todos os dados:**
```{r ggpairs-plot0, message=FALSE, warning=FALSE}
GGally::ggpairs(iris, columns = 1:4)
```

- **Considerando as categorias de especies (variÃ¡vel Species)**
```{r ggpairs-plot, message=FALSE, warning=FALSE}
GGally::ggpairs(iris, columns = 1:4, aes(color = Species))
```

**O que a figura mostra?**

Esta figura Ã© uma **matriz de grÃ¡ficos de pares** (pairs) das variÃ¡veis numÃ©ricas do conjunto de dados, nesse caso, `Sepal.Length`, `Sepal.Width`, `Petal.Length` e `Petal.Width`.

- **Diagonal principal**: exibe a distribuiÃ§Ã£o de cada variÃ¡vel individualmente, usando histogramas ou curvas de densidade. Quando os dados estÃ£o divididos por categoria (como diferentes espÃ©cies no exemplo do iris), cada cor representa uma categoria distinta, permitindo visualizar e comparar facilmente como os valores da variÃ¡vel se distribuem em cada grupo.

- **Abaixo da diagonal**: mostra grÃ¡ficos de dispersÃ£o, permitindo observar visualmente as relaÃ§Ãµes entre os pares de variÃ¡veis para cada espÃ©cie.

- **Acima da diagonal**: apresenta os **coeficientes de correlaÃ§Ã£o** para cada par de variÃ¡veis:
  - O valor principal (exemplo: Corr: 0.872***) corresponde Ã  correlaÃ§Ã£o considerando todas as espÃ©cies juntas.
  - Abaixo, aparecem as correlaÃ§Ãµes **por espÃ©cie**:
    - setosa (vermelho)
    - versicolor (verde)
    - virginica (azul)
  - Os valores sÃ£o coloridos conforme a espÃ©cie correspondente.

- **Sobre os asteriscos**: os asteriscos apÃ³s os valores de correlaÃ§Ã£o indicam o **nÃ­vel de significÃ¢ncia estatÃ­stica** do coeficiente calculado, ou seja, quÃ£o provÃ¡vel Ã© que a correlaÃ§Ã£o observada seja diferente de zero apenas pelo acaso. A convenÃ§Ã£o usual Ã©:

- `*` : p < 0,05 
- `**` : p < 0,01 
- `***` : p < 0,001
- Sem asteriscos: correlaÃ§Ã£o **nÃ£o** significativa

<!--chapter:end:20-Correlacao.Rmd-->

# RegressÃ£o

A **regressÃ£o** Ã© uma tÃ©cnica estatÃ­stica usada para estudar a relaÃ§Ã£o entre uma variÃ¡vel de interesse (chamada de variÃ¡vel dependente ou resposta) e uma ou mais variÃ¡veis que podem influenciÃ¡-la (chamadas de variÃ¡veis independentes ou preditoras). O objetivo principal Ã© **prever** ou **explicar** o comportamento da variÃ¡vel resposta a partir das informaÃ§Ãµes das variÃ¡veis preditoras.

**RegressÃ£o Linear Simples:**  
Ã‰ o tipo mais bÃ¡sico de regressÃ£o, analisando a relaÃ§Ã£o entre duas variÃ¡veis: uma resposta (por exemplo, peso) e uma preditora (por exemplo, altura). A relaÃ§Ã£o Ã© representada por uma linha reta:  
\[
\text{Resposta} = a + b \times \text{Preditora}
\]  
Exemplo: Prever o peso de uma pessoa a partir de sua altura. O modelo estima qual seria o peso esperado para cada altura.

**RegressÃ£o Linear MÃºltipla:**  
Quando queremos analisar o efeito de duas ou mais variÃ¡veis preditoras sobre a variÃ¡vel resposta, usamos a regressÃ£o linear mÃºltipla. A equaÃ§Ã£o fica:  
\[
\text{Resposta} = a + b_1 \times \text{Preditora}_1 + b_2 \times \text{Preditora}_2 + \ldots
\]  
Exemplo: Prever o preÃ§o de uma casa considerando Ã¡rea, nÃºmero de quartos e localizaÃ§Ã£o.

**RegressÃ£o LogÃ­stica:**  
Ã‰ usada quando a resposta Ã© categÃ³rica, por exemplo: sim/nÃ£o, doente/sadio, aprovado/reprovado. Em vez de prever um nÃºmero, ela estima a probabilidade de um determinado evento ocorrer. Exemplo: Prever a chance de um paciente ter uma certa doenÃ§a com base em exames. O resultado Ã© sempre um valor entre 0 e 1 (uma probabilidade).

**Outros Modelos de RegressÃ£o:**  
AlÃ©m dos modelos acima, existem outros tipos de regressÃ£o para diferentes situaÃ§Ãµes, como:  
- RegressÃ£o de Poisson: para contagem de eventos (exemplo: nÃºmero de acidentes por mÃªs);
- RegressÃ£o de Prais-Winsten: utilizada em sÃ©ries temporais, especialmente quando os dados tÃªm dependÃªncia ao longo do tempo (como dados econÃ´micos mensais);
- RegressÃ£o polinomial: ajusta curvas em vez de retas, para relaÃ§Ãµes nÃ£o-lineares;
- RegressÃ£o robusta, Ridge, Lasso: abordam problemas especÃ­ficos como dados com valores extremos ou quando hÃ¡ muitas variÃ¡veis preditoras.

Em resumo, a regressÃ£o Ã© uma ferramenta poderosa e versÃ¡til, Ãºtil em diferentes Ã¡reas como saÃºde, economia, educaÃ§Ã£o e ciÃªncias sociais. Ela nos ajuda a compreender relaÃ§Ãµes, prever resultados e tomar decisÃµes baseadas em dados, mesmo sem precisar de conhecimentos avanÃ§ados em matemÃ¡tica.

## RegressÃ£o Linear Simples 

A correlaÃ§Ã£o responde Ã  pergunta: **"Existe relaÃ§Ã£o linear? Qual a forÃ§a e o sentido dessa relaÃ§Ã£o?"**

A **regressÃ£o linear simples** vai alÃ©m: alÃ©m de indicar se existe relaÃ§Ã£o, ela fornece uma equaÃ§Ã£o que **quantifica e permite prever** uma variÃ¡vel a partir da outra.  
A equaÃ§Ã£o tem a forma:

\[
Y = a + bX
\]

onde:
- **Y**: variÃ¡vel resposta (dependente)
- **X**: variÃ¡vel explicativa (independente)
- **a**: intercepto (valor esperado de Y quando X = 0)
- **b**: inclinaÃ§Ã£o (quanto Y varia, em mÃ©dia, a cada unidade de X)

A regressÃ£o responde Ã  pergunta: **"Como prever Y a partir de X?"**

Ã‰ comum estudar primeiro a correlaÃ§Ã£o, pois ela mostra se vale a pena tentar ajustar um modelo de regressÃ£o linear.


### RegressÃ£o Linear Simples no R

Como exemplo, vamos estudar a relaÃ§Ã£o entre a **frequÃªncia cardÃ­aca** (x, em batimentos por minuto - bpm) e o **comprimento do intervalo QT** (y, em milissegundos) de um eletrocardiograma (ECG). O intervalo QT representa o tempo que o coraÃ§Ã£o leva para se despolarizar e repolarizar, sendo um importante marcador clÃ­nico.

Vamos considerar a seguinte amostra: 

```{r}
# FrequÃªncia cardÃ­aca (bpm)
x <- c(60,75,62,68,84,97,66,65,86,78,93,75,88)
# Intervalo QT (ms)
y <- c(403,363,381,367,341,317,401,384,342,377,329,377,349)
```

Vamos, primeiro, verificar o comportamento das variÃ¡veis pelo grÃ¡fio de dispersÃ£o:

```{r}
plot(x, y, 
     xlab = "FrequÃªncia CardÃ­aca (bpm)", 
     ylab = "Intervalo QT (ms)", 
     pch = 19, col = "blue")
grid()
```

O teste de correlaÃ§Ã£o nos fornece:

```{r}
# antes, verifique a normalidade das variÃ¡veis 
cor.test(x, y) # Teste estatÃ­stico da correlaÃ§Ã£o
```

- **Coeficiente de correlaÃ§Ã£o (r):** -0,93
- **Valor de t:** -8,29
- **Graus de liberdade (df):** 11
- **Valor-p:** 0,0000046
- **Intervalo de confianÃ§a (95%):** de -0,98 a -0,77

O que isso significa?

- **ForÃ§a e direÃ§Ã£o:** O coeficiente de correlaÃ§Ã£o de Pearson (**r = -0,93**) indica uma **correlaÃ§Ã£o negativa muito forte** entre as variÃ¡veis x e y. Isso significa que, Ã  medida que uma variÃ¡vel aumenta, a outra tende a diminuir de forma bastante consistente.
- **SignificÃ¢ncia estatÃ­stica:** O valor-p (**p < 0,001**) mostra que essa correlaÃ§Ã£o Ã© **estatisticamente significativa**. Ou seja, Ã© extremamente improvÃ¡vel que essa relaÃ§Ã£o forte e negativa tenha ocorrido por acaso.
- **Intervalo de confianÃ§a:** O intervalo de -0,98 a -0,77 indica que, com 95% de confianÃ§a, a verdadeira correlaÃ§Ã£o na populaÃ§Ã£o estÃ¡ dentro desse intervalo â€” sempre indicando uma relaÃ§Ã£o negativa forte.
- **HipÃ³tese nula:** Como o valor-p Ã© muito pequeno, rejeitamos a hipÃ³tese nula de que nÃ£o existe correlaÃ§Ã£o linear entre x e y.

Como hÃ¡ uma correlaÃ§Ã£o linear forte e significativa, **faz sentido estudar um modelo de regressÃ£o linear** para quantificar e prever a relaÃ§Ã£o entre essas variÃ¡veis.


Para ajustarmos um modelo onde o intervalo QT Ã© explicado pela frequÃªncia cardÃ­aca no R, usamos a funÃ§Ã£o `lm()`, onde lm significa *linear model*.

```{r}
regressao <- lm(y ~ x)
regressao
```
O modelo ajustado de regressÃ£o linear simples foi:

\[
\text{Intervalo QT} = 520,67 - 2,04 \times \text{FrequÃªncia CardÃ­aca}
\]

**InterpretaÃ§Ã£o dos coeficientes:**

- **Intercepto (520,67):**  
  Este valor representa a estimativa do intervalo QT (em milissegundos) quando a frequÃªncia cardÃ­aca (x) Ã© zero. Embora uma frequÃªncia cardÃ­aca de zero nÃ£o faÃ§a sentido fisiolÃ³gico, o intercepto Ã© necessÃ¡rio para construir a reta de regressÃ£o e serve como referÃªncia matemÃ¡tica.

- **InclinaÃ§Ã£o (-2,04):**  
  Esse coeficiente indica que, para cada aumento de 1 batimento por minuto (bpm) na frequÃªncia cardÃ­aca, o intervalo QT diminui, em mÃ©dia, cerca de 2,04 milissegundos.  
  Ou seja, existe uma relaÃ§Ã£o negativa: quanto maior a frequÃªncia cardÃ­aca, menor tende a ser o intervalo QT.

O resumo da regressÃ£o Ã© obtido a partir da funÃ§Ã£o `summary()`

```{r}
summary(regressao)
```

- **Valor-p para ambos os coeficientes (p < 0,001):** Os dois coeficientes sÃ£o  significativos, ou seja, existe evidÃªncia estatÃ­stica muito forte de que ambos sÃ£o diferentes de zero.

- **RÂ² (Multiple R-squared): 0,86:** Aproximadamente 86% da variaÃ§Ã£o do intervalo QT Ã© explicada pela frequÃªncia cardÃ­aca. Ã‰ um valor alto, indicando que o modelo ajusta bem os dados.
- **RÂ² Ajustado (0,85):** Leva em conta o nÃºmero de variÃ¡veis e tamanho da amostra, e tambÃ©m Ã© alto.
- **Erro padrÃ£o residual (Residual standard error: 10,38):** Mede o desvio mÃ©dio dos pontos em relaÃ§Ã£o Ã  reta ajustada (quanto menor, melhor).

- **ResÃ­duos:** Representam a diferenÃ§a entre os valores observados e os previstos pelo modelo. Os valores mÃ­nimos e mÃ¡ximos indicam a dispersÃ£o dos erros.

- **F-statistic: 68,8, p-value: 4,6e-06:** Teste global do modelo, confirma que a relaÃ§Ã£o encontrada Ã© altamente significativa.

O modelo de regressÃ£o linear simples mostra que existe uma **forte relaÃ§Ã£o linear negativa** e estatisticamente significativa entre a frequÃªncia cardÃ­aca e o intervalo QT: quanto maior a frequÃªncia cardÃ­aca, menor tende a ser o intervalo QT. O modelo explica a maior parte da variaÃ§Ã£o dos dados, sendo Ãºtil para previsÃµes e interpretaÃ§Ãµes clÃ­nicas dessa relaÃ§Ã£o.

O intervalos de confianÃ§a para os coeficientes da reta Ã© dado por: 

```{r}
confint(regressao)
```

- **Intercepto (a):**  
  O intervalo de confianÃ§a de 95% para o intercepto vai de **478,59** a **562,74**. Isso significa que, com 95% de confianÃ§a, o verdadeiro valor do intercepto estÃ¡ dentro desse intervalo. O intercepto representa o valor estimado do intervalo QT quando a frequÃªncia cardÃ­aca Ã© zero (valor teÃ³rico/matemÃ¡tico).

- **InclinaÃ§Ã£o (b):**  
  O intervalo de confianÃ§a de 95% para a inclinaÃ§Ã£o vai de **-2,59** a **-1,50**. Como o intervalo Ã© totalmente negativo, reforÃ§a que a relaÃ§Ã£o entre frequÃªncia cardÃ­aca e intervalo QT Ã© negativa: a cada aumento de 1 bpm na frequÃªncia cardÃ­aca, o intervalo QT diminui, em mÃ©dia, entre 1,50 e 2,59 ms.
  

**LimitaÃ§Ãµes e Cuidados na RegressÃ£o Linear**

Apesar do modelo indicar uma associaÃ§Ã£o significativa, Ã© importante considerar algumas limitaÃ§Ãµes e pontos de atenÃ§Ã£o:

- **ExtrapolaÃ§Ã£o:** O modelo Ã© vÃ¡lido apenas para a faixa de dados observados. Prever valores de QT para frequÃªncias cardÃ­acas muito fora do intervalo observado pode gerar resultados sem sentido.
- **SuposiÃ§Ãµes do modelo:**  
  - **Linearidade:** A relaÃ§Ã£o entre as variÃ¡veis deve ser aproximadamente linear.
  - **Normalidade dos resÃ­duos:** Os resÃ­duos (erros) devem ser aproximadamente distribuÃ­dos normalmente.
  - **Homoscedasticidade:** A variÃ¢ncia dos resÃ­duos deve ser constante ao longo dos valores previstos.
  - **IndependÃªncia:** As observaÃ§Ãµes devem ser independentes entre si.
  Recomenda-se sempre checar essas suposiÃ§Ãµes usando grÃ¡ficos de resÃ­duos e testes estatÃ­sticos.
- **PossÃ­veis valores extremos (outliers):** Valores muito diferentes dos demais podem influenciar fortemente o ajuste, distorcendo os resultados.
- **CorrelaÃ§Ã£o nÃ£o implica causalidade:** A regressÃ£o mostra associaÃ§Ã£o, mas nÃ£o garante que uma variÃ¡vel causa a outra.

### O que deve ser checado ao ajustar uma regressÃ£o linear?

- **GrÃ¡fico de resÃ­duos:** Para avaliar linearidade, homoscedasticidade e detectar outliers.
- **Histograma/QQ-plot dos resÃ­duos:** Para verificar a normalidade dos resÃ­duos.
- **Verificar influÃªncias:** Avaliar se algum ponto influencia demais o resultado (diagnÃ³stico de outliers/influÃªncia).
- **Intervalos de confianÃ§a:** Analisar a precisÃ£o das estimativas dos parÃ¢metros.
- **RÂ² e RÂ² ajustado:** Avaliar o quanto do comportamento da variÃ¡vel resposta Ã© explicado pelo modelo.

## RegressÃ£o Linear MÃºltipla

Depois de entender a regressÃ£o linear simples, Ã© fÃ¡cil expandir para a **regressÃ£o linear mÃºltipla**, onde podemos incluir mais de uma variÃ¡vel preditora para explicar a variÃ¡vel resposta. No nosso exemplo, alÃ©m da **frequÃªncia cardÃ­aca (x)**, vamos acrescentar a **idade dos indivÃ­duos (z)**, que tambÃ©m pode influenciar o intervalo QT do eletrocardiograma (y).

Vamos supor os seguintes valores de idade para os mesmos indivÃ­duos:

```{r}
# FrequÃªncia cardÃ­aca (bpm)
x <- c(60,75,62,68,84,97,66,65,86,78,93,75,88)
# Intervalo QT (ms)
y <- c(403,363,381,367,341,317,401,384,342,377,329,377,349)
# Idade (anos) - exemplo hipotÃ©tico
z <- c(25,40,30,22,53,60,28,27,50,35,59,41,55)
```

Vamos ajustar agora um modelo que considera tanto a frequÃªncia cardÃ­aca quanto a idade como preditoras do intervalo QT:

- O modelo ajustado tem a forma:
  \[
  \text{QT} = a + b_1 \times \text{FrequÃªncia CardÃ­aca (x)} + b_2 \times \text{Idade (z)}
  \]

```{r}
regressao_multipla <- lm(y ~ x + z)
summary(regressao_multipla)
```

**Modelo ajustado:**  
\[
\text{QT} = 514,39 - 1,88 \times \text{FrequÃªncia CardÃ­aca (x)} - 0,15 \times \text{Idade (z)}
\]

- **Intercepto (514,39):**  
  Valor estimado do QT quando frequÃªncia cardÃ­aca e idade sÃ£o zero (valor teÃ³rico, apenas referÃªncia matemÃ¡tica).

- **FrequÃªncia CardÃ­aca (x):**  
  O coeficiente Ã© -1,88, ou seja, para cada aumento de 1 bpm, o QT diminui em mÃ©dia 1,88 ms, mantendo a idade constante.  
  O valor-p (0,0504) Ã© limÃ­trofe, indicando que a influÃªncia da frequÃªncia cardÃ­aca sobre o QT **ainda Ã© significativa**, mas no limite do nÃ­vel de significÃ¢ncia tradicional (5%).

- **Idade (z):**  
  O coeficiente Ã© -0,15, ou seja, para cada aumento de 1 ano de idade, o QT diminui, em mÃ©dia, 0,15 ms, mantendo a frequÃªncia cardÃ­aca constante.  
  No entanto, o valor-p (0,8457) mostra que essa associaÃ§Ã£o **nÃ£o Ã© estatisticamente significativa** â€” ou seja, nÃ£o hÃ¡ evidÃªncia de que a idade tenha efeito relevante sobre o QT neste conjunto de dados.

> Qualidade do ajuste

- **RÂ² (0,86):**  
  Aproximadamente 86% da variaÃ§Ã£o do QT Ã© explicada pelo modelo com as duas variÃ¡veis preditoras, indicando bom ajuste.
- **RÂ² ajustado (0,83):**  
  Leva em conta o nÃºmero de variÃ¡veis, tambÃ©m indicando bom ajuste.
- **Erro padrÃ£o residual (10,87):**  
  MÃ©dia dos desvios dos pontos em relaÃ§Ã£o Ã  reta ajustada, semelhante ao modelo simples.

> AnÃ¡lise dos resÃ­duos

- A distribuiÃ§Ã£o dos resÃ­duos sugere que o modelo estÃ¡ adequado, mas sempre Ã© recomendado visualizar os grÃ¡ficos de resÃ­duos para avaliar possÃ­veis violaÃ§Ãµes das suposiÃ§Ãµes.

> Teste F

- **F-statistic: 31,42, p-value: 4,88e-05:**  
  O modelo como um todo Ã© altamente significativo, ou seja, pelo menos uma das variÃ¡veis preditoras estÃ¡ relacionada ao QT.

> ConclusÃ£o

- O modelo de **regressÃ£o mÃºltipla** mostra que, **mantendo a idade constante**, a frequÃªncia cardÃ­aca segue sendo um preditor importante e significativo para o intervalo QT.
- A idade, por outro lado, **nÃ£o contribuiu de forma significativa** para explicar o QT nesse exemplo.
- O ajuste da regressÃ£o mÃºltipla no R Ã© simples e a interpretaÃ§Ã£o amplia a compreensÃ£o das relaÃ§Ãµes entre vÃ¡rias variÃ¡veis e a resposta.  
- **Importante:** Sempre verifique as suposiÃ§Ãµes do modelo e a significÃ¢ncia de cada preditor.

## No R Ã© fÃ¡cil

A sintaxe para ajustar a regressÃ£o mÃºltipla Ã© muito parecida com a da simples, basta acrescentar as variÃ¡veis ao modelo:

```r
lm(y ~ x + z, data = dados)
```
Se quiser incluir ainda mais variÃ¡veis, basta adicionÃ¡-las na fÃ³rmula, separadas por `+`.

> VisualizaÃ§Ã£o dos resÃ­duos

Ã‰ importante, como sempre, checar os resÃ­duos para garantir que as suposiÃ§Ãµes do modelo continuam vÃ¡lidas:

```{r}
plot(regressao_multipla)
```

> ResÃ­duos vs Valores Ajustados

- **Objetivo:** Avaliar linearidade e homocedasticidade (variÃ¢ncia constante dos resÃ­duos).
- **InterpretaÃ§Ã£o:** Os resÃ­duos estÃ£o distribuÃ­dos de forma aproximadamente aleatÃ³ria ao redor de zero, sem padrÃµes claros. Isso sugere que a relaÃ§Ã£o linear Ã© adequada e que a variÃ¢ncia dos resÃ­duos Ã© razoavelmente constante. NÃ£o hÃ¡ grandes evidÃªncias de problemas de ajuste, ainda que um ou outro ponto se afaste mais do centro (possÃ­veis outliers).

> Q-Q Plot dos ResÃ­duos

- **Objetivo:** Verificar se os resÃ­duos seguem uma distribuiÃ§Ã£o normal (suposiÃ§Ã£o importante para testes de hipÃ³teses na regressÃ£o).
- **InterpretaÃ§Ã£o:** Os pontos seguem bem a linha reta, indicando que a normalidade dos resÃ­duos Ã© atendida na maior parte dos casos. Pequenos desvios nas extremidades sÃ£o tolerÃ¡veis, especialmente com amostras pequenas, como neste exemplo.

> Scale-Location (Homocedasticidade)

- **Objetivo:** Avaliar se a variÃ¢ncia dos resÃ­duos Ã© constante para todos os valores ajustados (homocedasticidade).
- **InterpretaÃ§Ã£o:** Os pontos estÃ£o relativamente dispersos de forma homogÃªnea ao longo do eixo dos valores ajustados, sem formar um funil ou padrÃ£o crescente/decrescente marcante. Isso reforÃ§a que a suposiÃ§Ã£o de homocedasticidade estÃ¡ sendo atendida.

> ResÃ­duos Padronizados vs Leverage

- **Objetivo:** Identificar pontos com alto potencial de influÃªncia no modelo (outliers ou observaÃ§Ãµes influentes).
- **InterpretaÃ§Ã£o:** A maioria dos pontos estÃ¡ dentro dos limites aceitÃ¡veis de leverage e resÃ­duos. Apenas um ou dois pontos apresentam valores de leverage mais altos, mas sem exceder drasticamente os limites de distÃ¢ncia de Cook. Isso sugere que nÃ£o hÃ¡ observaÃ§Ãµes extremamente influentes comprometendo o modelo.

Os diagnÃ³sticos grÃ¡ficos indicam que:
- **As suposiÃ§Ãµes do modelo de regressÃ£o mÃºltipla estÃ£o razoavelmente bem atendidas:** linearidade, normalidade dos resÃ­duos, homocedasticidade e ausÃªncia de pontos influentes extremos.
- **O modelo Ã© adequado para os dados analisados**, com apenas leves indÃ­cios de possÃ­veis outliers, mas sem comprometer as conclusÃµes.

## ExercÃ­cio

O exercÃ­cio "nutrientes em cereais matinais" foi retirado do livro EstatÃ­stica BÃ¡sica de Larson & Farber. 

A *U.S. Food and Drug Administration* (FDA) exige a rotulagem nutricional para a maioria dos alimentos. Sob os regulamentos da FDA, os produtores sÃ£o obrigados a listar as quantidades de certos nutrientes em seus alimentos, tais como: calorias, aÃ§Ãºcar, gordura e carboidratos. Essa informaÃ§Ã£o nutricional Ã© exibida em uma tabela na embalagem do alimento.

A Tabela mostra o teor nutricional para uma xÃ­cara de 21 cereais matinais diferentes.

*C* = calorias  
*S* = aÃ§Ãºcar em gramas  
*F* = gordura em gramas  
*R* = carboidratos em gramas  

| C   | S  | F   | R  |
|-----:|:----:|:-----:|:----|
| 100 | 12 | 0.5 | 25 |
| 130 | 11 | 1.5 | 29 |
| 110 | 10 | 1.0 | 29 |
| 130 | 15 | 2.0 | 31 |
| 130 | 13 | 1.5 | 29 |
| 120 |  3 | 0.5 | 26 |
| 100 |  2 | 0.0 | 24 |
| 120 |  0 | 0.0 | 29 |
| 150 | 16 | 1.5 | 31 |
| 110 |  4 | 0.0 | 25 |
| 110 | 12 | 1.0 | 23 |
| 160 | 15 | 1.5 | 35 |
| 150 | 12 | 2.0 | 36 |
| 150 | 15 | 1.5 | 29 |
| 110 | 15 | 0.0 | 29 |
| 190 | 13 | 1.5 | 45 |
| 100 |  3 | 0.0 | 23 |
| 120 |  4 | 0.5 | 23 |
| 120 | 11 | 1.5 | 28 |
| 120 | 11 | 1.0 | 29 |
| 130 |  5 | 0.5 | 29 |


**1.** Use o R para obter um diagrama de dispersÃ£o dos seguintes pares \((x, y)\) no conjunto de dados.

(a) (Calorias, aÃ§Ãºcar.)  
(b) (Calorias, gordura.)  
(c) (Calorias, carboidratos.)  
(d) (AÃ§Ãºcar, gordura.)  
(e) (AÃ§Ãºcar, carboidratos.)  
(f) (Gordura, carboidratos.)


**2.** Dos diagramas de dispersÃ£o no ExercÃ­cio 1, quais pares de variÃ¡veis parecem ter uma correlaÃ§Ã£o linear forte?


**3.** Use o R para encontrar o coeficiente de correlaÃ§Ã£o para cada par de variÃ¡veis no ExercÃ­cio 1. Qual tem a correlaÃ§Ã£o linear mais forte?


**4.** Use tecnologia para encontrar a equaÃ§Ã£o de uma reta de regressÃ£o para os seguintes pares de variÃ¡veis.

(a) (Calorias, aÃ§Ãºcar.)  
(b) (Calorias, carboidratos.)


**5.** Use os resultados do ExercÃ­cio 4 para prever o seguinte:

(a) O teor de aÃ§Ãºcar de uma xÃ­cara de cereal que tem 120 calorias.  
(b) O teor de carboidrato de uma xÃ­cara de cereal que tem 120 calorias.


**6.** Use tecnologia para encontrar as equaÃ§Ãµes de regressÃ£o mÃºltipla dos seguintes modelos:

(a) \( C = b + m_1S + m_2F + m_3R \)  
(b) \( C = b + m_1S + m_2R \)


**7.** Use as equaÃ§Ãµes do ExercÃ­cio 6 para prever as calorias em 1 xÃ­cara de cereal que tem 7 gramas de aÃ§Ãºcar; 0,5 grama de gordura e 31 gramas de carboidratos.

<!--chapter:end:21-Regressao.Rmd-->

```{r setup, include=FALSE}
# Instale os pacotes se necessÃ¡rio:
# install.packages(c("tidyverse", "pwr", "epitools"))

library(tidyverse)
library(pwr)
library(epitools)
```

# AssociaÃ§Ã£o entre variÃ¡veis

Testes de associaÃ§Ã£o sÃ£o usados para verificar se existe uma relaÃ§Ã£o estatisticamente significativa entre duas variÃ¡veis categÃ³ricas. A escolha do teste depende do tipo de variÃ¡vel e do tamanho da amostra.

A aplicaÃ§Ã£o desses testes Ã© fundamental em diversas Ã¡reas do conhecimento. 

## Tipos de VariÃ¡veis Envolvidas

Os testes de associaÃ§Ã£o sÃ£o aplicados principalmente a **variÃ¡veis qualitativas nominais**, como:

- Sexo (Masculino, Feminino)
- PresenÃ§a de DoenÃ§a (Sim, NÃ£o)

## Tabela de ContingÃªncia

Uma **tabela de contingÃªncia** Ã© uma ferramenta estatÃ­stica utilizada para organizar e analisar a relaÃ§Ã£o entre duas (ou mais) variÃ¡veis categÃ³ricas. Ela apresenta a distribuiÃ§Ã£o conjunta das frequÃªncias observadas de cada combinaÃ§Ã£o possÃ­vel dos nÃ­veis das variÃ¡veis, facilitando a identificaÃ§Ã£o de possÃ­veis associaÃ§Ãµes entre elas.

**Exemplo:**

Considere uma pesquisa em que se investiga a associaÃ§Ã£o entre sexo e presenÃ§a de uma determinada doenÃ§a em uma amostra de pessoas:

|              | DoenÃ§a: Sim | DoenÃ§a: NÃ£o | Total |
|--------------|:-------------:|:-------------:|:-------:|
| Masculino    |      8      |      7      |  15   |
| Feminino     |      5      |     10      |  15   |
| **Total**    |     13      |     17      |  30   |

Cada cÃ©lula da tabela mostra o nÃºmero de pessoas de cada sexo que tÃªm ou nÃ£o tÃªm a doenÃ§a, permitindo analisar se existe associaÃ§Ã£o entre essas variÃ¡veis.

### CÃ¡lculo das FrequÃªncias Esperadas

As **frequÃªncias esperadas** sÃ£o valores teÃ³ricos que indicam quantas ocorrÃªncias seriam esperadas em cada cÃ©lula de uma tabela de contingÃªncia caso nÃ£o houvesse associaÃ§Ã£o entre as variÃ¡veis (ou seja, se fossem independentes). Elas sÃ£o fundamentais para a realizaÃ§Ã£o do teste qui-quadrado de independÃªncia.

**Como calcular?**

Para cada cÃ©lula da tabela de contigÃªncia (frequÃªncias observadas), usamos a seguinte conta:

\[
\text{FrequÃªncia Esperada} = \frac{\text{Total da Linha} \times \text{Total da Coluna}}{\text{Total Geral}}
\]


- O â€œTotal da Linhaâ€ Ã© o total de pessoas daquela linha (por exemplo, todos os homens).

- O â€œTotal da Colunaâ€ Ã© o total de pessoas daquela coluna (por exemplo, todos que tÃªm a doenÃ§a).

- O â€œTotal Geralâ€ Ã© o total de pessoas da tabela toda.


**Da tabela de contigÃªncia do exemplo anterior, podemos efetuar os cÃ¡lculos**

1. **Masculino, DoenÃ§a: Sim**
   \[
   \frac{15 \times 13}{30} = \frac{195}{30} = 6,5
   \]

2. **Masculino, DoenÃ§a: NÃ£o**
   \[
   \frac{15 \times 17}{30} = \frac{255}{30} = 8,5
   \]

3. **Feminino, DoenÃ§a: Sim**
   \[
   \frac{15 \times 13}{30} = 6,5
   \]

4. **Feminino, DoenÃ§a: NÃ£o**
   \[
   \frac{15 \times 17}{30} = 8,5
   \]

EntÃ£o, nesse caso a tabela de frequÃªncias esperadas Ã© dada por:

|              | DoenÃ§a: Sim | DoenÃ§a: NÃ£o | Total da linha |
|--------------|:-------------:|:-------------:|:---------------:|
| Masculino    |     6,5     |     8,5     |      15       |
| Feminino     |     6,5     |     8,5     |      15       |
| **Total da coluna** |   13       |    17       |      30       |

A tabela acima mostra as frequÃªncias que seriam esperadas em cada cÃ©lula caso nÃ£o existisse associaÃ§Ã£o entre sexo e presenÃ§a de doenÃ§a.

A essÃªncia dos testes de associaÃ§Ã£o Ã© comparar a tabela de frequÃªncias observadas (com os dados reais coletados) com a tabela de frequÃªncias esperadas (calculada considerando que nÃ£o exista relaÃ§Ã£o entre as variÃ¡veis, ou seja, que sejam independentes). A tabela observada mostra quantas vezes cada combinaÃ§Ã£o de categorias realmente aconteceu, enquanto a tabela esperada mostra quantas vezes cada combinaÃ§Ã£o seria esperada ao acaso. O teste avalia se as diferenÃ§as entre o que foi observado e o que seria esperado sÃ£o grandes o suficiente para indicar uma associaÃ§Ã£o entre as variÃ¡veis. Portanto, a comparaÃ§Ã£o entre essas duas tabelas estÃ¡ no centro da anÃ¡lise para determinar se existe ou nÃ£o uma relaÃ§Ã£o significativa entre as variÃ¡veis estudadas.

Na prÃ¡tica, todos esses cÃ¡lculos acontecem nos bastidores, pois utilizamos ferramentas computacionais que realizam automaticamente tanto o cÃ¡lculo das frequÃªncias esperadas quanto a comparaÃ§Ã£o com os valores observados. Assim, normalmente nÃ£o precisamos calcular manualmente cada valor esperado ou montar todas as tabelas. No entanto, Ã© fundamental compreender o conceito central dos testes de associaÃ§Ã£o: eles servem para comparar o que foi realmente observado com o que seria esperado caso nÃ£o houvesse relaÃ§Ã£o entre as variÃ¡veis, ajudando a identificar se existe ou nÃ£o uma associaÃ§Ã£o significativa entre elas.


## Principais Testes de AssociaÃ§Ã£o

Ã‰ importante destacar que existem diversos mÃ©todos estatÃ­sticos para analisar a associaÃ§Ã£o entre variÃ¡veis categÃ³ricas, dependendo do tipo de dados e da estrutura da tabela de contingÃªncia.

AlÃ©m dos tradicionais teste qui-quadrado e teste exato de Fisher, hÃ¡ outros mÃ©todos que podem ser aplicados conforme a situaÃ§Ã£o:  
- O **teste G** (ou teste da razÃ£o de verossimilhanÃ§a) Ã© uma alternativa ao qui-quadrado, baseado em outra abordagem matemÃ¡tica, mas com objetivo semelhante.  
- O **teste de McNemar** Ã© indicado para tabelas 2x2 com dados pareados, como em estudos antes e depois.  
- O **teste de Mantel-Haenszel** avalia a associaÃ§Ã£o entre variÃ¡veis, controlando possÃ­veis fatores de confusÃ£o por meio da estratificaÃ§Ã£o, sendo muito usado em estudos epidemiolÃ³gicos.  
- O **teste de tendÃªncia linear de Cochran-Armitage** Ã© recomendado quando as categorias possuem uma ordem natural e se deseja avaliar a existÃªncia de tendÃªncia linear entre elas.  
- Existem ainda o **teste de concordÃ¢ncia Kappa de Cohen**, que mede o grau de concordÃ¢ncia entre avaliadores, e o **teste exato de Barnard**, alternativa ao teste de Fisher em tabelas 2x2.

A escolha do teste adequado depende do tamanho da amostra, da distribuiÃ§Ã£o dos dados, do tipo de variÃ¡vel (nominal ou ordinal), da estrutura dos dados (independentes ou pareados) e do objetivo da anÃ¡lise.


### Exemplos 

**Exemplo na Medicina:**  

Investigar se hÃ¡ associaÃ§Ã£o entre o sexo do paciente (masculino/feminino) e a presenÃ§a de hipertensÃ£o (sim/nÃ£o).  

- **VariÃ¡veis:** Sexo (masculino, feminino) e hipertensÃ£o (sim, nÃ£o)  

- **AplicaÃ§Ã£o:** Monta-se uma tabela de contingÃªncia 2x2 e aplica-se o teste de associaÃ§Ã£o para verificar se a proporÃ§Ã£o de hipertensos difere entre os sexos.


**Exemplos na Psicologia**

Verificar se existe associaÃ§Ã£o entre tipo de terapia utilizada (cognitivo-comportamental, psicanalÃ­tica, humanista) e desfecho do tratamento (melhorou/nÃ£o melhorou) em pacientes.  

- **VariÃ¡veis:** Tipo de terapia (trÃªs categorias) e desfecho (melhorou, nÃ£o melhorou)  

- **AplicaÃ§Ã£o:** Monta-se uma tabela de contingÃªncia 3x2 e aplica-se o teste associaÃ§Ã£o para analisar se o tipo de terapia estÃ¡ associado ao desfecho.


**Exemplo na EducaÃ§Ã£o FÃ­sica** 

Analisar se hÃ¡ associaÃ§Ã£o entre a participaÃ§Ã£o em atividades extracurriculares (sim/nÃ£o) e o nÃ­vel de aptidÃ£o fÃ­sica (baixo/mÃ©dio/alto) em estudantes do ensino mÃ©dio.  

- **VariÃ¡veis:** ParticipaÃ§Ã£o em atividades (sim, nÃ£o) e aptidÃ£o fÃ­sica (baixo, mÃ©dio, alto)  

- **AplicaÃ§Ã£o:** Cria-se uma tabela de contingÃªncia 2x3 e utiliza-se o teste de associaÃ§Ã£o para verificar se a aptidÃ£o fÃ­sica difere conforme a participaÃ§Ã£o em atividades extracurriculares.


### Teste Qui-Quadrado

O teste **qui-quadrado** ($\chi^2$) Ã© um dos mÃ©todos mais utilizados para avaliar se existe associaÃ§Ã£o entre duas variÃ¡veis categÃ³ricas. Ele funciona comparando as frequÃªncias observadas nas cÃ©lulas de uma tabela de contingÃªncia com as frequÃªncias que seriam esperadas caso nÃ£o houvesse relaÃ§Ã£o entre as variÃ¡veis.

- **HipÃ³tese nula ($H_0$):** NÃ£o existe associaÃ§Ã£o entre as variÃ¡veis â€œxâ€ e â€œyâ€, ou seja, elas sÃ£o independentes.
- **HipÃ³tese alternativa ($H_1$):** Existe associaÃ§Ã£o entre as variÃ¡veis.

**Principais requisitos:**

- A amostra deve ser aleatÃ³ria.

- Pelo menos 80% das cÃ©lulas da tabela devem ter frequÃªncia esperada igual ou superior a 5.

- Nenhuma cÃ©lula deve ter frequÃªncia esperada igual a zero.

> **ObservaÃ§Ã£o:** Nenhuma cÃ©lula deve ter frequÃªncia esperada igual a zero porque, no teste qui-quadrado, a fÃ³rmula envolve dividir pela frequÃªncia esperada. Se algum valor esperado for zero, nÃ£o Ã© possÃ­vel fazer a divisÃ£o, pois divisÃ£o por zero Ã© indefinida. AlÃ©m disso, uma frequÃªncia esperada igual a zero indica que, teoricamente, aquela combinaÃ§Ã£o de categorias nÃ£o deveria ocorrer nunca, o que torna os cÃ¡lculos e os resultados do teste estatÃ­stico invÃ¡lidos ou sem sentido. Por isso, Ã© importante garantir que todas as cÃ©lulas tenham valores esperados maiores que zero para que o teste seja matematicamente correto e confiÃ¡vel.

O teste qui-quadrado pode ser aplicado em tabelas maiores que 2x2.

### Teste Exato de Fisher

O **teste exato de Fisher** Ã© recomendado quando os tamanhos das amostras sÃ£o pequenos ou quando as frequÃªncias esperadas em alguma cÃ©lula da tabela sÃ£o menores que 5, situaÃ§Ã£o em que o teste qui-quadrado pode nÃ£o ser confiÃ¡vel.

- **HipÃ³tese nula ($H_0$):** NÃ£o existe associaÃ§Ã£o entre as variÃ¡veis â€œxâ€ e â€œyâ€, ou seja, elas sÃ£o independentes.
- **HipÃ³tese alternativa ($H_1$):** Existe associaÃ§Ã£o entre as variÃ¡veis.

- Ã‰ mais conservador do que o qui-quadrado, pois calcula a probabilidade exata de ocorrÃªncia das frequÃªncias observadas.

- Tradicionalmente, Ã© utilizado para tabelas 2x2 (dois grupos e duas categorias), mas pode ser estendido a tabelas maiores com recursos computacionais.

- NÃ£o depende das condiÃ§Ãµes de frequÃªncia esperada mÃ­nima.

### Exemplo no R

Vamos analisar se hÃ¡ associaÃ§Ã£o entre sexo (Masculino/Feminino) e presenÃ§a de doenÃ§a (Sim/NÃ£o) com os seguintes dados, da tabela de contingÃªncia que foi mencionada anteriormente:

|              | DoenÃ§a: Sim | DoenÃ§a: NÃ£o |  
|--------------|:-----------:|:-----------:|  
| Masculino    |      8      |      7      |  
| Feminino     |      5      |     10      |  


Essa tabela pode ser repassada diretamente para o R:

```{r}
# Crie a matriz de dados
tabela <- matrix(c(8, 7,       # observe o uso de matrix() e c()
                   5, 10),     # observe os parentes  
                 nrow = 2,     # numero de linhas 
                 byrow = TRUE) # vocÃª estÃ¡ informando por linhas (by row)
                 
# Ã© opcional, mas ficarÃ¡ mais claro que se vocÃª nomear 
# as linhas (row) e colunas (col) da sua tabela
colnames(tabela) <- c("DoenÃ§a: Sim", "DoenÃ§a: NÃ£o")
rownames(tabela) <- c("Masculino", "Feminino")

# Veja como ficou a tabela
tabela
```

Para fazer o teste Qui-quadrado no R usamos `chisq.test()`:

```{r}
# Aplicando o teste qui-quadrado
resultado <- chisq.test(tabela)

# Veja o resultado
resultado
```

O resultado apresentado refere-se ao teste qui-quadrado de Pearson com a correÃ§Ã£o de continuidade de Yates, usada para tabelas 2x2:

A **correÃ§Ã£o de continuidade de Yates** Ã© um ajuste aplicado ao teste qui-quadrado em tabelas 2x2 para evitar superestimaÃ§Ã£o da significÃ¢ncia estatÃ­stica, especialmente em amostras pequenas. Ela consiste em diminuir a diferenÃ§a entre os valores observados e esperados antes de calcular o qui-quadrado, tornando o teste mais conservador.

- **X-squared**: Valor do qui-quadrado calculado $\chi^2 = 0,543$.  
- **df**: Graus de liberdade (1), determinado pelo nÃºmero de linhas e colunas da tabela.  O cÃ¡lculo Ã© feito pela fÃ³rmula:  
  **df = (nÃºmero de linhas â€“ 1) Ã— (nÃºmero de colunas â€“ 1)**.  
  No exemplo, temos 2 linhas e 2 colunas: (2â€“1) Ã— (2â€“1) = 1.
- **p-value**: Valor de p (0,4612)

Como o valor de p Ã© 0,4612 (maior do que o nÃ­vel de significÃ¢ncia de 0,05), **nÃ£o hÃ¡ evidÃªncias suficientes para rejeitar a hipÃ³tese nula**. Portanto, nÃ£o foi encontrada associaÃ§Ã£o estatisticamente significativa entre sexo e presenÃ§a de doenÃ§a nessa amostra.


E, caso queira vizualizar as tabelas de valores observados e esperados basta fazer o seguinte: 

```{r}
# Exibir os valores observados
resultado$observed

# Exibir os valores esperados
resultado$expected
```

> **ObservaÃ§Ã£o:** Se alguma frequÃªncia esperada for menor que 5, o R emitirÃ¡ um alerta. Nesses casos, considere usar o teste exato de Fisher:
>
> ```r
> fisher.test(tabela)
> ```

Por, exemplos se substituirmos o 7 por 1, teremos
```{r, echo=FALSE, message=FALSE, warning=TRUE}
# Crie a matriz de dados
tabela2 <- matrix(c(8, 1,       # observe o uso de matrix() e c()
                   5, 10),     # observe os parentes  
                 nrow = 2,     # numero de linhas 
                 byrow = TRUE) # vocÃª estÃ¡ informando por linhas (by row)
                 
# Ã© opcional, mas ficarÃ¡ mais claro que se vocÃª nomear 
# as linhas (row) e colunas (col) da sua tabela
colnames(tabela2) <- c("DoenÃ§a: Sim", "DoenÃ§a: NÃ£o")
rownames(tabela2) <- c("Masculino", "Feminino")

# Veja como ficou a tabela
tabela2

# Aplicando o teste qui-quadrado
resultado <- chisq.test(tabela2)

# Veja o resultado
resultado

# trocando por teste de Fisher 
fisher.test(tabela2)
```
- **p-value = 0.01306:** O valor de p Ã© menor que 0,05, indicando que existe uma associaÃ§Ã£o estatisticamente significativa entre as duas variÃ¡veis analisadas. Isso significa que a chance de observarmos essa diferenÃ§a (ou uma diferenÃ§a maior) apenas por acaso Ã© de aproximadamente 1,3%.

- **Odds ratio = 14.07:** A razÃ£o de chances estimada Ã© 14 vezes maior em um grupo do que no outro, sugerindo uma associaÃ§Ã£o forte entre as categorias das variÃ¡veis.

- **Intervalo de confianÃ§a (1,30 a 774,69):** O intervalo de confianÃ§a de 95% mostra que a razÃ£o de chances verdadeira, na populaÃ§Ã£o, pode variar de cerca de 1,3 atÃ© 774,7. Como esse intervalo nÃ£o inclui o valor 1, reforÃ§a-se a evidÃªncia de associaÃ§Ã£o.

### ObservaÃ§Ã£o sobre tabelas de contingÃªncia em artigos cientÃ­ficos

Quando lemos um artigo que apresenta uma **tabela de contingÃªncia** (por exemplo, uma tabela cruzando sexo e presenÃ§a de doenÃ§a), estamos vendo exatamente a amostra utilizada pelo autor, com a distribuiÃ§Ã£o real dos indivÃ­duos nos diferentes grupos. Isso Ã© diferente do que ocorre em testes de comparaÃ§Ã£o de mÃ©dias (como t-teste) ou correlaÃ§Ã£o, onde geralmente temos acesso apenas a medidas-resumo (como mÃ©dia, desvio-padrÃ£o, coeficiente de correlaÃ§Ã£o), e nÃ£o aos dados individuais.

Nesse sentido, **ter a tabela de contingÃªncia Ã© praticamente o mesmo que ter os dados brutos** dos autores, pois conhecemos exatamente a quantidade de participantes em cada combinaÃ§Ã£o de categorias. Isso possibilita que qualquer leitor possa refazer os cÃ¡lculos dos testes estatÃ­sticos (como o qui-quadrado ou Fisher) e, inclusive, explorar outras anÃ¡lises categÃ³ricas de interesse.

Em resumo, a tabela de contingÃªncia oferece um grau de transparÃªncia e reprodutibilidade muito maior do que apenas apresentar medidas-resumo, pois expÃµe toda a estrutura dos dados da amostra analisada.


## Tamanho do Efeito: Medidas de AssociaÃ§Ã£o

Ao realizar testes de independÃªncia como o Qui-Quadrado ou o teste exato de Fisher para tabelas de contingÃªncia, Ã© importante nÃ£o apenas analisar o p-valor, mas tambÃ©m quantificar o tamanho do efeito, ou seja, a forÃ§a da associaÃ§Ã£o entre as variÃ¡veis categÃ³ricas.

A seguir sÃ£o mostradas as principais medidas de tamanho de efeito. 

### V de Cramer

- **DescriÃ§Ã£o**: mede a intensidade da associaÃ§Ã£o entre duas variÃ¡veis categÃ³ricas. Varia de 0 (nenhuma associaÃ§Ã£o) a 1 (associaÃ§Ã£o perfeita).
- **Uso**: Indicado para tabelas de contingÃªncia de qualquer dimensÃ£o.

**FÃ³rmula:**
\[
V = \sqrt{\frac{\chi^2}{n(k-1)}}
\]

- \(\chi^2\) = valor do teste Qui-Quadrado

- \(n\) = total de observaÃ§Ãµes

- \(k\) = menor nÃºmero entre linhas ou colunas

**No R:**
```{r, message=FALSE, warning=FALSE}
library(rcompanion)
cramerV(tabela)
```
ou
```{r, message=FALSE, warning=FALSE}
library(DescTools)
CramerV(tabela)
```

###  Phi de Pearson $(\phi)$

- **DescriÃ§Ã£o**: Medida de associaÃ§Ã£o para tabelas 2x2. Varia de 0 a 1.
- **Uso**: Exclusivo para tabelas 2x2.

**FÃ³rmula:**
\[
\phi = \sqrt{\frac{\chi^2}{n}}
\]

**No R:**
```{r, message=FALSE, warning=FALSE}
library(DescTools)
Phi(tabela)
```

InterpretaÃ§Ã£o dos valores:

- **V de Cramer**:
  - Pequeno: ~ 0,1
  - Moderado: ~ 0,3
  - Forte: ~ 0,5 ou mais

- **Phi**: InterpretaÃ§Ã£o semelhante ao V de Cramer para 2x2.

No exemplo, o valor obtido para o **V de Cramer** ou **Phi** foi de **0,20**. De acordo com os critÃ©rios usuais para essa medida, valores em torno de 0,1 indicam associaÃ§Ã£o pequena, valores prÃ³ximos de 0,3 associaÃ§Ã£o moderada e valores a partir de 0,5 associaÃ§Ã£o forte entre as variÃ¡veis analisadas.

AlÃ©m disso, como o teste estatÃ­stico realizado (por exemplo, Qui-Quadrado ou Fisher) indicou que **nÃ£o hÃ¡ associaÃ§Ã£o significativa** entre as variÃ¡veis (p>0,05), o resultado do V de Cramer reforÃ§a essa conclusÃ£o. Um valor de 0,20 sugere uma associaÃ§Ã£o fraca, e como nÃ£o hÃ¡ significÃ¢ncia estatÃ­stica, nÃ£o se pode afirmar que exista uma relaÃ§Ã£o relevante entre as variÃ¡veis na populaÃ§Ã£o estudada.

### Odds Ratio (RazÃ£o de Chances)

- **DescriÃ§Ã£o**: O Odds Ratio (OR) mede a forÃ§a da associaÃ§Ã£o entre dois eventos em tabelas 2x2, comparando as chances (odds) de um evento ocorrer em dois grupos diferentes. Ele indica se a ocorrÃªncia do evento em um grupo Ã© mais, menos ou igualmente provÃ¡vel em relaÃ§Ã£o ao outro grupo.

- **Uso**: Teste de Fisher e tabelas 2x2.

Considere a estrutura da tabela 2x2:

|                   | Evento Presente | Evento Ausente |
|-------------------|:-----------------:|:---------------:|
| **Grupo 1**       | a               | b             |
| **Grupo 2**       | c               | d             |

EntÃ£o odds ratio (OR), pode ser facilmente calculado: 

\[
OR = \frac{a \times d}{b \times c}
\]

Onde:

- **a** = nÃºmero de casos com o evento presente no Grupo 1  
- **b** = nÃºmero de casos com o evento ausente no Grupo 1  
- **c** = nÃºmero de casos com o evento presente no Grupo 2  
- **d** = nÃºmero de casos com o evento ausente no Grupo 2  

A interpretaÃ§Ã£o do OR Ã© a seguinte:

- **OR = 1:**  
  NÃ£o hÃ¡ diferenÃ§a entre os grupos. O evento tem a mesma chance de acontecer no Grupo 1 e no Grupo 2.  
  **Exemplo:** Se o OR for 1, os dois grupos tÃªm risco igual para o evento.

- **OR > 1:**  
  O evento Ã© mais provÃ¡vel no **Grupo 1** do que no Grupo 2.  
  **Exemplo:** Se o OR for 2, o Grupo 1 tem o dobro de chance do evento comparado ao Grupo 2.

- **OR < 1:**  
  O evento Ã© menos provÃ¡vel no **Grupo 1** do que no Grupo 2.  
  **Exemplo:** Se o OR for 0,5, o Grupo 1 tem metade da chance do evento comparado ao Grupo 2.

  
**No R:**
```{r} 
fisher.test(tabela)$estimate
```


O **odds ratio (OR)** calculado foi de **2,22**.

- O OR compara as chances de ocorrÃªncia da doenÃ§a entre os grupos "Masculino" e "Feminino".

- **OR = 2,22** indica que as chances de um indivÃ­duo do sexo masculino ter a doenÃ§a sÃ£o aproximadamente **2,2 vezes maiores** do que as chances de um indivÃ­duo do sexo feminino.

- Em outras palavras, a doenÃ§a Ã© mais provÃ¡vel entre os homens do que entre as mulheres neste conjunto de dados.


Ou usando o pacote `epitools`:
```{r} 
# install.packages("epitools")
library(epitools)
oddsratio(tabela)
```


- O odds ratio (OR) indica que as chances de "DoenÃ§a: Sim" sÃ£o cerca de 2,2 vezes maiores no grupo **Masculino** em relaÃ§Ã£o ao grupo **Feminino**.

- O intervalo de confianÃ§a (IC) de 95% para o OR do grupo Feminino Ã© de 0,50 a 10,61, o que inclui o valor 1. Isso sugere que esta diferenÃ§a **nÃ£o Ã© estatisticamente significativa**.

- Valores de p

| Grupo     | midp.exact | fisher.exact | chi.square |
|-----------|:------------:|:--------------:|:------------:|
| Feminino  |  0,3008    |   0,4621     |  0,2690    |

- Todos os valores de p sÃ£o **maiores do que 0,05**, indicando que nÃ£o hÃ¡ associaÃ§Ã£o estatisticamente significativa entre sexo e presenÃ§a de doenÃ§a nesta amostra.

- O uso da funÃ§Ã£o `oddsratio()` do pacote `epitools` mostrou um OR de 2,2 para o grupo masculino, mas essa diferenÃ§a (entre os grupos feminino e masculino) nÃ£o Ã© estatisticamente significativa. Isso significa que, com base nesses dados, nÃ£o se pode concluir que hÃ¡ uma associaÃ§Ã£o real entre sexo e presenÃ§a de doenÃ§a.

## CÃ¡lculo do Poder EstatÃ­stico

O poder estatÃ­stico pode ser estimado usando o pacote `pwr`, Ãºtil para calcular tamanho de efeito ou tamanho de amostra necessÃ¡rio.

```{r poder-estatistico}
# Exemplo para efeito 0,2, alfa = 0.05 e N = 30 (OBSERVE o N em MAIÃšSCULO, tamanho da amostra)
pwr.chisq.test(w = 0.2, df = 1, N = 30, sig.level = 0.05)
```

- **w (tamanho do efeito):**
  - Representa o tamanho do efeito, w Ã© igual ao V de Cramer

- **df (graus de liberdade):**
  - Indica o nÃºmero de graus de liberdade do teste.
  - Em uma tabela de contingÃªncia, Ã© calculado como:  
    (nÃºmero de linhas â€“ 1) Ã— (nÃºmero de colunas â€“ 1)
  - Exemplo: Para uma tabela 2x2, df = (2-1) Ã— (2-1) = 1

Com uma amostra de 30 indivÃ­duos, tentando detectar um efeito pequeno (w = 0,2) em um teste do qui-quadrado com 1 grau de liberdade e nÃ­vel de significÃ¢ncia de 5%, o poder do teste Ã© de apenas cerca de **19,5%**.

Isso significa que, se realmente existir uma associaÃ§Ã£o do tamanho especificado entre as variÃ¡veis, o teste sÃ³ terÃ¡ cerca de 19,5% de chance de detectar essa associaÃ§Ã£o (ou seja, rejeitar a hipÃ³tese nula corretamente).

**Em geral, recomenda-se um poder estatÃ­stico de pelo menos 80%** (0,8) para que o teste tenha boa chance de detectar uma associaÃ§Ã£o real. Portanto, **com essa configuraÃ§Ã£o, o teste estÃ¡ subdimensionado (pouco poder)** para detectar efeitos pequenos.

<!--chapter:end:22-Associacao.Rmd-->

`r if (knitr:::is_html_output()) '
# ReferÃªncias {-}
'`

<script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
<lottie-player src="https://assets8.lottiefiles.com/private_files/lf30_rklapo5f.json"  background="transparent"  speed="1"  style="width: 300px; height: 300px;"  loop  autoplay></lottie-player>



- **Cohen, J. (1988).** Statistical Power Analysis for the Behavioral Sciences (2nd ed.). Lawrence Erlbaum Associates.

- **Field, A. (2013).** Discovering Statistics Using IBM SPSS Statistics (4th ed.). Sage.

- **Romano, J., Kromrey, J. D., Coraggio, J., & Skowronek, J. (2006).** Appropriate statistics for ordinal level data: Should we really be using t-test and Cohenâ€™s d for evaluating group differences on the NSSE and other surveys? *Annual Meeting of the Florida Association of Institutional Research*, Jacksonville, FL, USA.

- **Cliff, N. (1993).** Dominance statistics: Ordinal analyses to answer ordinal questions. *Psychological Bulletin, 114*(3), 494-509. https://doi.org/10.1037/0033-2909.114.3.494

<!--chapter:end:23-Referencias.Rmd-->

